{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLOYOO10iA2h",
        "outputId": "e4179a5d-b859-4095-de6a-8fe1631e1e7c"
      },
      "id": "dLOYOO10iA2h",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_columns', 200)"
      ],
      "metadata": {
        "id": "Oyd7hRnAmnOh"
      },
      "id": "Oyd7hRnAmnOh",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/AutoGluon_dataset/ieee-fraud-detection.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQEE4yP4XXU6",
        "outputId": "9be1cea9-de52-4ae7-8ad8-bb275e8c60a4"
      },
      "id": "xQEE4yP4XXU6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/AutoGluon_dataset/ieee-fraud-detection.zip\n",
            "  inflating: /content/sample_submission.csv  \n",
            "  inflating: /content/test_identity.csv  \n",
            "  inflating: /content/test_transaction.csv  \n",
            "  inflating: /content/train_identity.csv  \n",
            "  inflating: /content/train_transaction.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4FFNUZSXiGM",
        "outputId": "2fc544e1-cb0c-4133-ffd2-0e03eb099649"
      },
      "id": "r4FFNUZSXiGM",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = '/content/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "KLaNxkUWXfTA"
      },
      "id": "KLaNxkUWXfTA",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "Xj-iOEArZ6iQ"
      },
      "id": "Xj-iOEArZ6iQ",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['isFraud'].value_counts()"
      ],
      "metadata": {
        "id": "DvvGLdMgxZqR",
        "outputId": "299cfe1e-2ba2-46bc-cee0-f142fcd539ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "id": "DvvGLdMgxZqR",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isFraud\n",
              "0    569877\n",
              "1     20663\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>569877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(train_data, test_size=0.2, random_state=42,stratify=train_data['isFraud'])\n",
        "test_data, val_data = train_test_split(temp_data, test_size=0.5, random_state=42,stratify=temp_data['isFraud'])"
      ],
      "metadata": {
        "id": "PkN7w2qMl6Tj"
      },
      "id": "PkN7w2qMl6Tj",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "feunXiRHmF2U",
        "outputId": "1025732d-2028-4b40-fca6-3b3ac3d4e872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "id": "feunXiRHmF2U",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
              "40809         3027809        0        1008491          100.00         R   \n",
              "285886        3272886        0        7008212           29.99         W   \n",
              "104256        3091256        0        2071522          107.95         W   \n",
              "507860        3494860        0       13299752          241.95         W   \n",
              "196382        3183382        0        4412283          117.00         W   \n",
              "\n",
              "        card1  card2  card3             card4  card5   card6  addr1  addr2  \\\n",
              "40809    6177  399.0  150.0  american express  150.0  credit  264.0   87.0   \n",
              "285886   7900  345.0  150.0        mastercard  224.0   debit  143.0   87.0   \n",
              "104256  11690  111.0  150.0              visa  226.0  credit  191.0   87.0   \n",
              "507860   2616  327.0  150.0          discover  102.0  credit  330.0   87.0   \n",
              "196382  13780  298.0  150.0              visa  226.0   debit  441.0   87.0   \n",
              "\n",
              "        dist1  dist2  P_emaildomain  R_emaildomain   C1   C2   C3   C4   C5  \\\n",
              "40809     NaN    1.0  anonymous.com  anonymous.com  1.0  1.0  0.0  2.0  0.0   \n",
              "285886    4.0    NaN      gmail.com            NaN  1.0  1.0  0.0  0.0  0.0   \n",
              "104256    NaN    NaN    comcast.net            NaN  1.0  1.0  0.0  0.0  1.0   \n",
              "507860    3.0    NaN            NaN            NaN  1.0  2.0  0.0  0.0  1.0   \n",
              "196382    5.0    NaN            NaN            NaN  1.0  1.0  0.0  0.0  0.0   \n",
              "\n",
              "         C6   C7   C8   C9  C10  C11  C12   C13  C14     D1     D2    D3  \\\n",
              "40809   1.0  0.0  2.0  0.0  2.0  1.0  0.0   2.0  1.0  609.0  609.0   NaN   \n",
              "285886  1.0  0.0  0.0  1.0  0.0  1.0  0.0   0.0  0.0    0.0    NaN   NaN   \n",
              "104256  1.0  0.0  0.0  1.0  0.0  1.0  0.0  15.0  1.0  501.0  501.0  18.0   \n",
              "507860  1.0  0.0  0.0  1.0  0.0  1.0  0.0   4.0  1.0  177.0  177.0  86.0   \n",
              "196382  0.0  0.0  0.0  1.0  0.0  1.0  0.0   2.0  1.0    0.0    0.0   0.0   \n",
              "\n",
              "           D4    D5  D6  D7          D8        D9    D10    D11  D12  D13  \\\n",
              "40809     NaN   NaN NaN NaN  609.666687  0.666666    NaN    NaN  NaN  NaN   \n",
              "285886    0.0   NaN NaN NaN         NaN       NaN    0.0    0.0  NaN  NaN   \n",
              "104256  502.0  18.0 NaN NaN         NaN       NaN  502.0    NaN  NaN  NaN   \n",
              "507860    NaN   NaN NaN NaN         NaN       NaN  177.0  177.0  NaN  NaN   \n",
              "196382    NaN   NaN NaN NaN         NaN       NaN    0.0    0.0  NaN  NaN   \n",
              "\n",
              "        D14    D15   M1   M2   M3   M4   M5   M6   M7   M8   M9   V1   V2  \\\n",
              "40809   NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  NaN    0.0    T    T    T   M0    T    F    F    F    T  1.0  1.0   \n",
              "104256  NaN  502.0  NaN  NaN  NaN  NaN  NaN    T  NaN  NaN  NaN  NaN  NaN   \n",
              "507860  NaN  177.0    T    T    F  NaN  NaN    T    F    F    T  1.0  1.0   \n",
              "196382  NaN    0.0    T    T    T   M0    T    F  NaN  NaN  NaN  1.0  1.0   \n",
              "\n",
              "         V3   V4   V5   V6   V7   V8   V9  V10  V11  V12  V13  V14  V15  V16  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
              "104256  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  1.0  1.0  0.0  0.0   \n",
              "507860  1.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0   \n",
              "196382  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
              "\n",
              "        V17  V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
              "104256  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0   \n",
              "507860  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0   \n",
              "196382  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "        V31  V32  V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "104256  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "507860  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "196382  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "\n",
              "        V45  ...  V280  V281  V282  V283  V284  V285  V286  V287  V288  V289  \\\n",
              "40809   NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886  1.0  ...   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256  1.0  ...   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
              "507860  NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382  NaN  ...   1.0   1.0   2.0   2.0   1.0   1.0   1.0   1.0   1.0   1.0   \n",
              "\n",
              "        V290  V291  V292  V293  V294  V295  V296  V297  V298  V299  V300  \\\n",
              "40809    1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "507860   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "        V301  V302  V303  V304  V305   V306   V307   V308   V309   V310  \\\n",
              "40809    0.0   1.0   1.0   1.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "285886   0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "104256   0.0   0.0   0.0   0.0   1.0    0.0  200.0    0.0    0.0  200.0   \n",
              "507860   0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "196382   0.0   0.0   0.0   0.0   1.0  117.0  117.0  117.0  117.0  117.0   \n",
              "\n",
              "         V311   V312   V313   V314   V315  V316  V317  V318  V319  V320  V321  \\\n",
              "40809     0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "507860    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382  117.0  117.0  117.0  117.0  117.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "        V322  V323  V324  V325  V326  V327  V328  V329  V330  V331  V332  \\\n",
              "40809    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "104256   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "507860   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "196382   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "\n",
              "        V333  V334  V335  V336  V337  V338  V339  id_01    id_02  id_03  \\\n",
              "40809    0.0   0.0   0.0   0.0   0.0   0.0   0.0   -5.0  58410.0    0.0   \n",
              "285886   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "104256   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "507860   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "196382   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "\n",
              "        id_04  id_05  id_06  id_07  id_08  id_09  id_10  id_11     id_12  \\\n",
              "40809     0.0    0.0    0.0    NaN    NaN    0.0    0.0  100.0  NotFound   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "\n",
              "        id_13  id_14  id_15  id_16  id_17  id_18  id_19  id_20  id_21  id_22  \\\n",
              "40809    52.0 -360.0  Found  Found  166.0    NaN  300.0  214.0    NaN    NaN   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "        id_23  id_24  id_25  id_26  id_27  id_28  id_29      id_30  \\\n",
              "40809     NaN    NaN    NaN    NaN    NaN  Found  Found  Windows 7   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "\n",
              "                      id_31  id_32      id_33           id_34  id_35  id_36  \\\n",
              "40809   ie 11.0 for desktop   24.0  1920x1080  match_status:2      T      F   \n",
              "285886                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "104256                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "507860                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "196382                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "\n",
              "        id_37  id_38  DeviceType   DeviceInfo  \n",
              "40809       T      T     desktop  Trident/7.0  \n",
              "285886    NaN    NaN         NaN          NaN  \n",
              "104256    NaN    NaN         NaN          NaN  \n",
              "507860    NaN    NaN         NaN          NaN  \n",
              "196382    NaN    NaN         NaN          NaN  \n",
              "\n",
              "[5 rows x 434 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84cd6b63-d9e3-4884-9cea-fe295b956b0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>M1</th>\n",
              "      <th>M2</th>\n",
              "      <th>M3</th>\n",
              "      <th>M4</th>\n",
              "      <th>M5</th>\n",
              "      <th>M6</th>\n",
              "      <th>M7</th>\n",
              "      <th>M8</th>\n",
              "      <th>M9</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>...</th>\n",
              "      <th>V280</th>\n",
              "      <th>V281</th>\n",
              "      <th>V282</th>\n",
              "      <th>V283</th>\n",
              "      <th>V284</th>\n",
              "      <th>V285</th>\n",
              "      <th>V286</th>\n",
              "      <th>V287</th>\n",
              "      <th>V288</th>\n",
              "      <th>V289</th>\n",
              "      <th>V290</th>\n",
              "      <th>V291</th>\n",
              "      <th>V292</th>\n",
              "      <th>V293</th>\n",
              "      <th>V294</th>\n",
              "      <th>V295</th>\n",
              "      <th>V296</th>\n",
              "      <th>V297</th>\n",
              "      <th>V298</th>\n",
              "      <th>V299</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40809</th>\n",
              "      <td>3027809</td>\n",
              "      <td>0</td>\n",
              "      <td>1008491</td>\n",
              "      <td>100.00</td>\n",
              "      <td>R</td>\n",
              "      <td>6177</td>\n",
              "      <td>399.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>american express</td>\n",
              "      <td>150.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>264.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>anonymous.com</td>\n",
              "      <td>anonymous.com</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>609.666687</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>58410.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>300.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Windows 7</td>\n",
              "      <td>ie 11.0 for desktop</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285886</th>\n",
              "      <td>3272886</td>\n",
              "      <td>0</td>\n",
              "      <td>7008212</td>\n",
              "      <td>29.99</td>\n",
              "      <td>W</td>\n",
              "      <td>7900</td>\n",
              "      <td>345.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>143.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>M0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104256</th>\n",
              "      <td>3091256</td>\n",
              "      <td>0</td>\n",
              "      <td>2071522</td>\n",
              "      <td>107.95</td>\n",
              "      <td>W</td>\n",
              "      <td>11690</td>\n",
              "      <td>111.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>191.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>comcast.net</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>502.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>502.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507860</th>\n",
              "      <td>3494860</td>\n",
              "      <td>0</td>\n",
              "      <td>13299752</td>\n",
              "      <td>241.95</td>\n",
              "      <td>W</td>\n",
              "      <td>2616</td>\n",
              "      <td>327.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>177.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>177.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196382</th>\n",
              "      <td>3183382</td>\n",
              "      <td>0</td>\n",
              "      <td>4412283</td>\n",
              "      <td>117.00</td>\n",
              "      <td>W</td>\n",
              "      <td>13780</td>\n",
              "      <td>298.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>441.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>M0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 434 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84cd6b63-d9e3-4884-9cea-fe295b956b0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84cd6b63-d9e3-4884-9cea-fe295b956b0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84cd6b63-d9e3-4884-9cea-fe295b956b0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ce7fd930-c61c-41d7-8e7b-8c2cb7c5fb38\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce7fd930-c61c-41d7-8e7b-8c2cb7c5fb38')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ce7fd930-c61c-41d7-8e7b-8c2cb7c5fb38 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "ELMPJ2u6m3pH",
        "outputId": "e040daf7-7be0-4df2-93e6-1f74b41c1a52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ELMPJ2u6m3pH",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(472432, 434)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "id": "01MxaCIRm5jY",
        "outputId": "31e4a6fb-c504-414c-cc12-c4fb38587aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "01MxaCIRm5jY",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 472432 entries, 40809 to 337290\n",
            "Columns: 434 entries, TransactionID to DeviceInfo\n",
            "dtypes: float64(399), int64(4), object(31)\n",
            "memory usage: 1.5+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data.isna().sum()/train_data.shape[0]).sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "kw_UTytum-ho",
        "outputId": "42c0b49a-b56f-4e40-f4da-2683566560f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "id": "kw_UTytum-ho",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id_24             0.991971\n",
              "id_25             0.991317\n",
              "id_07             0.991292\n",
              "id_08             0.991292\n",
              "id_21             0.991281\n",
              "                    ...   \n",
              "ProductCD         0.000000\n",
              "TransactionAmt    0.000000\n",
              "TransactionDT     0.000000\n",
              "isFraud           0.000000\n",
              "TransactionID     0.000000\n",
              "Length: 434, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id_24</th>\n",
              "      <td>0.991971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_25</th>\n",
              "      <td>0.991317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_07</th>\n",
              "      <td>0.991292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_08</th>\n",
              "      <td>0.991292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_21</th>\n",
              "      <td>0.991281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ProductCD</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionAmt</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionDT</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>434 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['id_14'].isna().sum()"
      ],
      "metadata": {
        "id": "o_4NwgfQtj6k",
        "outputId": "c62e0370-56a2-4ac8-ead2-07a89b496d75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "o_4NwgfQtj6k",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(408534)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import time\n",
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='medium',tuning_data=val_data, time_limit=6000,ag_args_fit={'max_time_limit': 600,\"num_gpus\": 1}\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWRUVCjpax8u",
        "outputId": "f0dcdab4-5ccc-47c9-d93d-2a570e823165"
      },
      "id": "FWRUVCjpax8u",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/AutoGluonModels/\"\n",
            "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Sep  6 09:54:41 UTC 2025\n",
            "CPU Count:          8\n",
            "GPU Count:          1\n",
            "Memory Avail:       32.87 GB / 50.99 GB (64.5%)\n",
            "Disk Space Avail:   187.08 GB / 235.68 GB (79.4%)\n",
            "===================================================\n",
            "Presets specified: ['medium']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}, 'auto_stack': False}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1},\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 6000s\n",
            "AutoGluon will save models to \"/content/AutoGluonModels\"\n",
            "Train Data Rows:    472432\n",
            "Train Data Columns: 433\n",
            "Tuning Data Rows:    59054\n",
            "Tuning Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    32752.28 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2258.77 MB (6.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 6.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t2.0s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.1s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.3s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t3.5s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t3 duplicate columns removed: ['V16', 'V119', 'V195']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t4.8s = Fit runtime\n",
            "\t\t\t430 features in original data used to generate 430 features in processed data.\n",
            "\tUnused Original Features (Count: 3): ['V16', 'V119', 'V195']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 3 | ['V16', 'V119', 'V195']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t25.3s = Fit runtime\n",
            "\t430 features in original data used to generate 430 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1634.65 MB (5.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 29.54s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Saving /content/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/X_val.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "\tLightGBM: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "\tRandomForestGini: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "\tExtraTreesGini: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "\tXGBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "\tNeuralNetTorch: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "\tLightGBMLarge: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'max_time_limit': 600, 'num_gpus': 1}}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 5970.46s of the 5970.45s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 5970.46s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting LightGBMXT with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=7.9/32.9 GB\n",
            "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0967706\n",
            "[100]\tvalid_set's binary_logloss: 0.0882523\n",
            "[150]\tvalid_set's binary_logloss: 0.0834381\n",
            "[200]\tvalid_set's binary_logloss: 0.0799868\n",
            "[250]\tvalid_set's binary_logloss: 0.0772956\n",
            "[300]\tvalid_set's binary_logloss: 0.075011\n",
            "[350]\tvalid_set's binary_logloss: 0.0732849\n",
            "[400]\tvalid_set's binary_logloss: 0.0718255\n",
            "[450]\tvalid_set's binary_logloss: 0.0705141\n",
            "[500]\tvalid_set's binary_logloss: 0.069425\n",
            "[550]\tvalid_set's binary_logloss: 0.0682712\n",
            "[600]\tvalid_set's binary_logloss: 0.0673211\n",
            "[650]\tvalid_set's binary_logloss: 0.0664111\n",
            "[700]\tvalid_set's binary_logloss: 0.065752\n",
            "[750]\tvalid_set's binary_logloss: 0.0649913\n",
            "[800]\tvalid_set's binary_logloss: 0.0643962\n",
            "[850]\tvalid_set's binary_logloss: 0.0636846\n",
            "[900]\tvalid_set's binary_logloss: 0.0629769\n",
            "[950]\tvalid_set's binary_logloss: 0.0623724\n",
            "[1000]\tvalid_set's binary_logloss: 0.0618711\n",
            "[1050]\tvalid_set's binary_logloss: 0.061316\n",
            "[1100]\tvalid_set's binary_logloss: 0.0608429\n",
            "[1150]\tvalid_set's binary_logloss: 0.060362\n",
            "[1200]\tvalid_set's binary_logloss: 0.0598714\n",
            "[1250]\tvalid_set's binary_logloss: 0.0593781\n",
            "[1300]\tvalid_set's binary_logloss: 0.0589276\n",
            "[1350]\tvalid_set's binary_logloss: 0.0585475\n",
            "[1400]\tvalid_set's binary_logloss: 0.058224\n",
            "[1450]\tvalid_set's binary_logloss: 0.057763\n",
            "[1500]\tvalid_set's binary_logloss: 0.0574388\n",
            "[1550]\tvalid_set's binary_logloss: 0.057125\n",
            "[1600]\tvalid_set's binary_logloss: 0.0567711\n",
            "[1650]\tvalid_set's binary_logloss: 0.0564341\n",
            "[1700]\tvalid_set's binary_logloss: 0.0561679\n",
            "[1750]\tvalid_set's binary_logloss: 0.0558714\n",
            "[1800]\tvalid_set's binary_logloss: 0.0555227\n",
            "[1850]\tvalid_set's binary_logloss: 0.0552589\n",
            "[1900]\tvalid_set's binary_logloss: 0.0549604\n",
            "[1950]\tvalid_set's binary_logloss: 0.0546878\n",
            "[2000]\tvalid_set's binary_logloss: 0.0544493\n",
            "[2050]\tvalid_set's binary_logloss: 0.0542164\n",
            "[2100]\tvalid_set's binary_logloss: 0.0540273\n",
            "[2150]\tvalid_set's binary_logloss: 0.0537991\n",
            "[2200]\tvalid_set's binary_logloss: 0.0535751\n",
            "[2250]\tvalid_set's binary_logloss: 0.0533529\n",
            "[2300]\tvalid_set's binary_logloss: 0.0531198\n",
            "[2350]\tvalid_set's binary_logloss: 0.0528886\n",
            "[2400]\tvalid_set's binary_logloss: 0.0526972\n",
            "[2450]\tvalid_set's binary_logloss: 0.0525403\n",
            "[2500]\tvalid_set's binary_logloss: 0.0522773\n",
            "[2550]\tvalid_set's binary_logloss: 0.0521211\n",
            "[2600]\tvalid_set's binary_logloss: 0.051992\n",
            "[2650]\tvalid_set's binary_logloss: 0.051863\n",
            "[2700]\tvalid_set's binary_logloss: 0.0517155\n",
            "[2750]\tvalid_set's binary_logloss: 0.051552\n",
            "[2800]\tvalid_set's binary_logloss: 0.0514005\n",
            "[2850]\tvalid_set's binary_logloss: 0.0512425\n",
            "[2900]\tvalid_set's binary_logloss: 0.0510831\n",
            "[2950]\tvalid_set's binary_logloss: 0.0509326\n",
            "[3000]\tvalid_set's binary_logloss: 0.0508231\n",
            "[3050]\tvalid_set's binary_logloss: 0.0507148\n",
            "[3100]\tvalid_set's binary_logloss: 0.0505842\n",
            "[3150]\tvalid_set's binary_logloss: 0.0504469\n",
            "[3200]\tvalid_set's binary_logloss: 0.050263\n",
            "[3250]\tvalid_set's binary_logloss: 0.0501401\n",
            "[3300]\tvalid_set's binary_logloss: 0.0499918\n",
            "[3350]\tvalid_set's binary_logloss: 0.0498532\n",
            "[3400]\tvalid_set's binary_logloss: 0.0497007\n",
            "[3450]\tvalid_set's binary_logloss: 0.0495797\n",
            "[3500]\tvalid_set's binary_logloss: 0.0494312\n",
            "[3550]\tvalid_set's binary_logloss: 0.0493046\n",
            "[3600]\tvalid_set's binary_logloss: 0.0491936\n",
            "[3650]\tvalid_set's binary_logloss: 0.0490916\n",
            "[3700]\tvalid_set's binary_logloss: 0.048982\n",
            "[3750]\tvalid_set's binary_logloss: 0.0488663\n",
            "[3800]\tvalid_set's binary_logloss: 0.0487694\n",
            "[3850]\tvalid_set's binary_logloss: 0.048697\n",
            "[3900]\tvalid_set's binary_logloss: 0.0486007\n",
            "[3950]\tvalid_set's binary_logloss: 0.0485002\n",
            "[4000]\tvalid_set's binary_logloss: 0.0484366\n",
            "[4050]\tvalid_set's binary_logloss: 0.0483427\n",
            "[4100]\tvalid_set's binary_logloss: 0.0482728\n",
            "[4150]\tvalid_set's binary_logloss: 0.0482039\n",
            "[4200]\tvalid_set's binary_logloss: 0.048147\n",
            "[4250]\tvalid_set's binary_logloss: 0.0480769\n",
            "[4300]\tvalid_set's binary_logloss: 0.0479977\n",
            "[4350]\tvalid_set's binary_logloss: 0.0479358\n",
            "[4400]\tvalid_set's binary_logloss: 0.0478209\n",
            "[4450]\tvalid_set's binary_logloss: 0.0477606\n",
            "[4500]\tvalid_set's binary_logloss: 0.0477206\n",
            "[4550]\tvalid_set's binary_logloss: 0.0476932\n",
            "[4600]\tvalid_set's binary_logloss: 0.0476196\n",
            "[4650]\tvalid_set's binary_logloss: 0.0475639\n",
            "[4700]\tvalid_set's binary_logloss: 0.0474931\n",
            "[4750]\tvalid_set's binary_logloss: 0.0474784\n",
            "[4800]\tvalid_set's binary_logloss: 0.0474327\n",
            "[4850]\tvalid_set's binary_logloss: 0.0473959\n",
            "[4900]\tvalid_set's binary_logloss: 0.0473334\n",
            "[4950]\tvalid_set's binary_logloss: 0.0473064\n",
            "[5000]\tvalid_set's binary_logloss: 0.0472276\n",
            "[5050]\tvalid_set's binary_logloss: 0.0471673\n",
            "[5100]\tvalid_set's binary_logloss: 0.0471079\n",
            "[5150]\tvalid_set's binary_logloss: 0.0470437\n",
            "[5200]\tvalid_set's binary_logloss: 0.0470179\n",
            "[5250]\tvalid_set's binary_logloss: 0.0469589\n",
            "[5300]\tvalid_set's binary_logloss: 0.0469127\n",
            "[5350]\tvalid_set's binary_logloss: 0.0468676\n",
            "[5400]\tvalid_set's binary_logloss: 0.0468554\n",
            "[5450]\tvalid_set's binary_logloss: 0.0468389\n",
            "[5500]\tvalid_set's binary_logloss: 0.0468\n",
            "[5550]\tvalid_set's binary_logloss: 0.0467553\n",
            "[5600]\tvalid_set's binary_logloss: 0.0466913\n",
            "[5650]\tvalid_set's binary_logloss: 0.0466782\n",
            "[5700]\tvalid_set's binary_logloss: 0.0466458\n",
            "[5750]\tvalid_set's binary_logloss: 0.0466018\n",
            "[5800]\tvalid_set's binary_logloss: 0.0465597\n",
            "[5850]\tvalid_set's binary_logloss: 0.0465477\n",
            "[5900]\tvalid_set's binary_logloss: 0.0465309\n",
            "[5950]\tvalid_set's binary_logloss: 0.0465437\n",
            "[6000]\tvalid_set's binary_logloss: 0.0465328\n",
            "[6050]\tvalid_set's binary_logloss: 0.0465541\n",
            "[6100]\tvalid_set's binary_logloss: 0.0465371\n",
            "[6150]\tvalid_set's binary_logloss: 0.0465089\n",
            "[6200]\tvalid_set's binary_logloss: 0.0465068\n",
            "[6250]\tvalid_set's binary_logloss: 0.0464891\n",
            "[6300]\tvalid_set's binary_logloss: 0.0464772\n",
            "[6350]\tvalid_set's binary_logloss: 0.046468\n",
            "[6400]\tvalid_set's binary_logloss: 0.0464735\n",
            "[6450]\tvalid_set's binary_logloss: 0.0464382\n",
            "[6500]\tvalid_set's binary_logloss: 0.046439\n",
            "[6550]\tvalid_set's binary_logloss: 0.0464229\n",
            "[6600]\tvalid_set's binary_logloss: 0.0464007\n",
            "[6650]\tvalid_set's binary_logloss: 0.0463877\n",
            "[6700]\tvalid_set's binary_logloss: 0.0463742\n",
            "[6750]\tvalid_set's binary_logloss: 0.0463711\n",
            "[6800]\tvalid_set's binary_logloss: 0.0463386\n",
            "[6850]\tvalid_set's binary_logloss: 0.0463693\n",
            "[6900]\tvalid_set's binary_logloss: 0.0463578\n",
            "[6950]\tvalid_set's binary_logloss: 0.0463526\n",
            "[7000]\tvalid_set's binary_logloss: 0.0463523\n",
            "[7050]\tvalid_set's binary_logloss: 0.0463304\n",
            "[7100]\tvalid_set's binary_logloss: 0.0462999\n",
            "[7150]\tvalid_set's binary_logloss: 0.0463021\n",
            "[7200]\tvalid_set's binary_logloss: 0.0462951\n",
            "[7250]\tvalid_set's binary_logloss: 0.0462724\n",
            "[7300]\tvalid_set's binary_logloss: 0.0463\n",
            "[7350]\tvalid_set's binary_logloss: 0.0463185\n",
            "[7400]\tvalid_set's binary_logloss: 0.0463176\n",
            "[7450]\tvalid_set's binary_logloss: 0.0463046\n",
            "[7500]\tvalid_set's binary_logloss: 0.0462966\n",
            "[7550]\tvalid_set's binary_logloss: 0.046279\n",
            "[7600]\tvalid_set's binary_logloss: 0.0463037\n",
            "[7650]\tvalid_set's binary_logloss: 0.0462917\n",
            "[7700]\tvalid_set's binary_logloss: 0.0463147\n",
            "[7750]\tvalid_set's binary_logloss: 0.0463261\n",
            "[7800]\tvalid_set's binary_logloss: 0.046306\n",
            "[7850]\tvalid_set's binary_logloss: 0.0463083\n",
            "[7900]\tvalid_set's binary_logloss: 0.0463537\n",
            "[7950]\tvalid_set's binary_logloss: 0.0463513\n",
            "[8000]\tvalid_set's binary_logloss: 0.0463402\n",
            "[8050]\tvalid_set's binary_logloss: 0.0463532\n",
            "[8100]\tvalid_set's binary_logloss: 0.046364\n",
            "[8150]\tvalid_set's binary_logloss: 0.0463932\n",
            "[8200]\tvalid_set's binary_logloss: 0.0463884\n",
            "[8250]\tvalid_set's binary_logloss: 0.0463906\n",
            "[8300]\tvalid_set's binary_logloss: 0.0464199\n",
            "[8350]\tvalid_set's binary_logloss: 0.0464351\n",
            "[8400]\tvalid_set's binary_logloss: 0.046468\n",
            "[8450]\tvalid_set's binary_logloss: 0.0464977\n",
            "[8500]\tvalid_set's binary_logloss: 0.0465363\n",
            "[8550]\tvalid_set's binary_logloss: 0.0465158\n",
            "[8600]\tvalid_set's binary_logloss: 0.0465269\n",
            "[8650]\tvalid_set's binary_logloss: 0.0465212\n",
            "[8700]\tvalid_set's binary_logloss: 0.0465211\n",
            "[8750]\tvalid_set's binary_logloss: 0.0465393\n",
            "[8800]\tvalid_set's binary_logloss: 0.0465679\n",
            "[8850]\tvalid_set's binary_logloss: 0.0465703\n",
            "[8900]\tvalid_set's binary_logloss: 0.0465928\n",
            "[8950]\tvalid_set's binary_logloss: 0.0465851\n",
            "[9000]\tvalid_set's binary_logloss: 0.0465816\n",
            "[9050]\tvalid_set's binary_logloss: 0.0465826\n",
            "[9100]\tvalid_set's binary_logloss: 0.0465877\n",
            "[9150]\tvalid_set's binary_logloss: 0.0465979\n",
            "[9200]\tvalid_set's binary_logloss: 0.046629\n",
            "[9250]\tvalid_set's binary_logloss: 0.0466495\n",
            "[9300]\tvalid_set's binary_logloss: 0.0466331\n",
            "[9350]\tvalid_set's binary_logloss: 0.0466644\n",
            "[9400]\tvalid_set's binary_logloss: 0.046678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "\t0.9705\t = Validation score   (roc_auc)\n",
            "\t352.23s\t = Training   runtime\n",
            "\t14.81s\t = Validation runtime\n",
            "\t3987.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM ... Training model for up to 5603.05s of the 5603.04s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 5603.05s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting LightGBM with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=7.9/32.8 GB\n",
            "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0914899\n",
            "[100]\tvalid_set's binary_logloss: 0.0824863\n",
            "[150]\tvalid_set's binary_logloss: 0.0772036\n",
            "[200]\tvalid_set's binary_logloss: 0.0740609\n",
            "[250]\tvalid_set's binary_logloss: 0.0716276\n",
            "[300]\tvalid_set's binary_logloss: 0.0697851\n",
            "[350]\tvalid_set's binary_logloss: 0.0683369\n",
            "[400]\tvalid_set's binary_logloss: 0.0668389\n",
            "[450]\tvalid_set's binary_logloss: 0.0655911\n",
            "[500]\tvalid_set's binary_logloss: 0.0643292\n",
            "[550]\tvalid_set's binary_logloss: 0.063255\n",
            "[600]\tvalid_set's binary_logloss: 0.0622275\n",
            "[650]\tvalid_set's binary_logloss: 0.0613943\n",
            "[700]\tvalid_set's binary_logloss: 0.0606073\n",
            "[750]\tvalid_set's binary_logloss: 0.0598897\n",
            "[800]\tvalid_set's binary_logloss: 0.0591291\n",
            "[850]\tvalid_set's binary_logloss: 0.0584438\n",
            "[900]\tvalid_set's binary_logloss: 0.0578194\n",
            "[950]\tvalid_set's binary_logloss: 0.0573024\n",
            "[1000]\tvalid_set's binary_logloss: 0.056875\n",
            "[1050]\tvalid_set's binary_logloss: 0.0562926\n",
            "[1100]\tvalid_set's binary_logloss: 0.0557597\n",
            "[1150]\tvalid_set's binary_logloss: 0.0553132\n",
            "[1200]\tvalid_set's binary_logloss: 0.0548124\n",
            "[1250]\tvalid_set's binary_logloss: 0.0543725\n",
            "[1300]\tvalid_set's binary_logloss: 0.0538776\n",
            "[1350]\tvalid_set's binary_logloss: 0.0534749\n",
            "[1400]\tvalid_set's binary_logloss: 0.0530891\n",
            "[1450]\tvalid_set's binary_logloss: 0.0527164\n",
            "[1500]\tvalid_set's binary_logloss: 0.052317\n",
            "[1550]\tvalid_set's binary_logloss: 0.0519667\n",
            "[1600]\tvalid_set's binary_logloss: 0.0516858\n",
            "[1650]\tvalid_set's binary_logloss: 0.0513884\n",
            "[1700]\tvalid_set's binary_logloss: 0.0511174\n",
            "[1750]\tvalid_set's binary_logloss: 0.0508428\n",
            "[1800]\tvalid_set's binary_logloss: 0.0505479\n",
            "[1850]\tvalid_set's binary_logloss: 0.050283\n",
            "[1900]\tvalid_set's binary_logloss: 0.0500809\n",
            "[1950]\tvalid_set's binary_logloss: 0.0497156\n",
            "[2000]\tvalid_set's binary_logloss: 0.0494391\n",
            "[2050]\tvalid_set's binary_logloss: 0.0492298\n",
            "[2100]\tvalid_set's binary_logloss: 0.0489724\n",
            "[2150]\tvalid_set's binary_logloss: 0.0488028\n",
            "[2200]\tvalid_set's binary_logloss: 0.0485863\n",
            "[2250]\tvalid_set's binary_logloss: 0.0484644\n",
            "[2300]\tvalid_set's binary_logloss: 0.0482867\n",
            "[2350]\tvalid_set's binary_logloss: 0.0481196\n",
            "[2400]\tvalid_set's binary_logloss: 0.0479342\n",
            "[2450]\tvalid_set's binary_logloss: 0.0477273\n",
            "[2500]\tvalid_set's binary_logloss: 0.0475707\n",
            "[2550]\tvalid_set's binary_logloss: 0.0474107\n",
            "[2600]\tvalid_set's binary_logloss: 0.0472606\n",
            "[2650]\tvalid_set's binary_logloss: 0.0471563\n",
            "[2700]\tvalid_set's binary_logloss: 0.0469836\n",
            "[2750]\tvalid_set's binary_logloss: 0.0468087\n",
            "[2800]\tvalid_set's binary_logloss: 0.0466582\n",
            "[2850]\tvalid_set's binary_logloss: 0.0465257\n",
            "[2900]\tvalid_set's binary_logloss: 0.0464217\n",
            "[2950]\tvalid_set's binary_logloss: 0.0463313\n",
            "[3000]\tvalid_set's binary_logloss: 0.0462169\n",
            "[3050]\tvalid_set's binary_logloss: 0.0461164\n",
            "[3100]\tvalid_set's binary_logloss: 0.0460266\n",
            "[3150]\tvalid_set's binary_logloss: 0.0459339\n",
            "[3200]\tvalid_set's binary_logloss: 0.0458358\n",
            "[3250]\tvalid_set's binary_logloss: 0.0456902\n",
            "[3300]\tvalid_set's binary_logloss: 0.0455905\n",
            "[3350]\tvalid_set's binary_logloss: 0.0454694\n",
            "[3400]\tvalid_set's binary_logloss: 0.0453594\n",
            "[3450]\tvalid_set's binary_logloss: 0.0452964\n",
            "[3500]\tvalid_set's binary_logloss: 0.0452377\n",
            "[3550]\tvalid_set's binary_logloss: 0.045138\n",
            "[3600]\tvalid_set's binary_logloss: 0.0450844\n",
            "[3650]\tvalid_set's binary_logloss: 0.0449926\n",
            "[3700]\tvalid_set's binary_logloss: 0.0448688\n",
            "[3750]\tvalid_set's binary_logloss: 0.0447946\n",
            "[3800]\tvalid_set's binary_logloss: 0.0447442\n",
            "[3850]\tvalid_set's binary_logloss: 0.0446695\n",
            "[3900]\tvalid_set's binary_logloss: 0.0446616\n",
            "[3950]\tvalid_set's binary_logloss: 0.0446146\n",
            "[4000]\tvalid_set's binary_logloss: 0.0445913\n",
            "[4050]\tvalid_set's binary_logloss: 0.0445054\n",
            "[4100]\tvalid_set's binary_logloss: 0.0444717\n",
            "[4150]\tvalid_set's binary_logloss: 0.0444097\n",
            "[4200]\tvalid_set's binary_logloss: 0.0443896\n",
            "[4250]\tvalid_set's binary_logloss: 0.0443627\n",
            "[4300]\tvalid_set's binary_logloss: 0.0443671\n",
            "[4350]\tvalid_set's binary_logloss: 0.0443314\n",
            "[4400]\tvalid_set's binary_logloss: 0.0443435\n",
            "[4450]\tvalid_set's binary_logloss: 0.044316\n",
            "[4500]\tvalid_set's binary_logloss: 0.0443064\n",
            "[4550]\tvalid_set's binary_logloss: 0.0443145\n",
            "[4600]\tvalid_set's binary_logloss: 0.0443077\n",
            "[4650]\tvalid_set's binary_logloss: 0.0442979\n",
            "[4700]\tvalid_set's binary_logloss: 0.0442504\n",
            "[4750]\tvalid_set's binary_logloss: 0.0442475\n",
            "[4800]\tvalid_set's binary_logloss: 0.0442396\n",
            "[4850]\tvalid_set's binary_logloss: 0.0442233\n",
            "[4900]\tvalid_set's binary_logloss: 0.0441969\n",
            "[4950]\tvalid_set's binary_logloss: 0.0441913\n",
            "[5000]\tvalid_set's binary_logloss: 0.0441906\n",
            "[5050]\tvalid_set's binary_logloss: 0.0441851\n",
            "[5100]\tvalid_set's binary_logloss: 0.0441843\n",
            "[5150]\tvalid_set's binary_logloss: 0.0441993\n",
            "[5200]\tvalid_set's binary_logloss: 0.0441944\n",
            "[5250]\tvalid_set's binary_logloss: 0.0441757\n",
            "[5300]\tvalid_set's binary_logloss: 0.0441569\n",
            "[5350]\tvalid_set's binary_logloss: 0.044174\n",
            "[5400]\tvalid_set's binary_logloss: 0.0441504\n",
            "[5450]\tvalid_set's binary_logloss: 0.0441672\n",
            "[5500]\tvalid_set's binary_logloss: 0.0442014\n",
            "[5550]\tvalid_set's binary_logloss: 0.0442074\n",
            "[5600]\tvalid_set's binary_logloss: 0.0441911\n",
            "[5650]\tvalid_set's binary_logloss: 0.0442069\n",
            "[5700]\tvalid_set's binary_logloss: 0.0442213\n",
            "[5750]\tvalid_set's binary_logloss: 0.0442234\n",
            "[5800]\tvalid_set's binary_logloss: 0.0442383\n",
            "[5850]\tvalid_set's binary_logloss: 0.0442601\n",
            "[5900]\tvalid_set's binary_logloss: 0.044296\n",
            "[5950]\tvalid_set's binary_logloss: 0.0443242\n",
            "[6000]\tvalid_set's binary_logloss: 0.0443527\n",
            "[6050]\tvalid_set's binary_logloss: 0.0443896\n",
            "[6100]\tvalid_set's binary_logloss: 0.0444528\n",
            "[6150]\tvalid_set's binary_logloss: 0.0445045\n",
            "[6200]\tvalid_set's binary_logloss: 0.0445401\n",
            "[6250]\tvalid_set's binary_logloss: 0.0445513\n",
            "[6300]\tvalid_set's binary_logloss: 0.0445582\n",
            "[6350]\tvalid_set's binary_logloss: 0.0445806\n",
            "[6400]\tvalid_set's binary_logloss: 0.0446096\n",
            "[6450]\tvalid_set's binary_logloss: 0.0446474\n",
            "[6500]\tvalid_set's binary_logloss: 0.0446906\n",
            "[6550]\tvalid_set's binary_logloss: 0.0447302\n",
            "[6600]\tvalid_set's binary_logloss: 0.0447605\n",
            "[6650]\tvalid_set's binary_logloss: 0.044783\n",
            "[6700]\tvalid_set's binary_logloss: 0.0448118\n",
            "[6750]\tvalid_set's binary_logloss: 0.0448626\n",
            "[6800]\tvalid_set's binary_logloss: 0.0448733\n",
            "[6850]\tvalid_set's binary_logloss: 0.0448965\n",
            "[6900]\tvalid_set's binary_logloss: 0.0449224\n",
            "[6950]\tvalid_set's binary_logloss: 0.0449733\n",
            "[7000]\tvalid_set's binary_logloss: 0.0450139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "\t0.9725\t = Validation score   (roc_auc)\n",
            "\t272.53s\t = Training   runtime\n",
            "\t11.2s\t = Validation runtime\n",
            "\t5273.7\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini ... Training model for up to 5319.04s of the 5319.03s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 5319.04s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting RandomForestGini with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.3/32.8 GB\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "\t0.9356\t = Validation score   (roc_auc)\n",
            "\t267.95s\t = Training   runtime\n",
            "\t1.72s\t = Validation runtime\n",
            "\t34344.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr ... Training model for up to 5048.68s of the 5048.67s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 5048.68s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting RandomForestEntr with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.3/32.7 GB\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "\t0.938\t = Validation score   (roc_auc)\n",
            "\t205.22s\t = Training   runtime\n",
            "\t1.44s\t = Validation runtime\n",
            "\t40953.8\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost ... Training model for up to 4841.29s of the 4841.28s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 4841.29s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting CatBoost with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=8.6/32.6 GB\n",
            "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 4, 'task_type': 'GPU'}\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6107215\ttest: 0.6106532\tbest: 0.6106532 (0)\ttotal: 43.2ms\tremaining: 43.2ms\n",
            "1:\tlearn: 0.5400615\ttest: 0.5399599\tbest: 0.5399599 (1)\ttotal: 81.3ms\tremaining: 0us\n",
            "bestTest = 0.5399598514\n",
            "bestIteration = 1\n",
            "0:\tlearn: 0.6071772\ttest: 0.6070544\tbest: 0.6070544 (0)\ttotal: 181ms\tremaining: 45.5s\n",
            "20:\tlearn: 0.1410450\ttest: 0.1414036\tbest: 0.1414036 (20)\ttotal: 2.9s\tremaining: 31.9s\n",
            "40:\tlearn: 0.1086544\ttest: 0.1097015\tbest: 0.1097015 (40)\ttotal: 5.68s\tremaining: 29.3s\n",
            "60:\tlearn: 0.1016902\ttest: 0.1029489\tbest: 0.1029489 (60)\ttotal: 8.45s\tremaining: 26.4s\n",
            "80:\tlearn: 0.0979432\ttest: 0.0992919\tbest: 0.0992919 (80)\ttotal: 11.2s\tremaining: 23.6s\n",
            "100:\tlearn: 0.0954674\ttest: 0.0969112\tbest: 0.0969112 (100)\ttotal: 13.8s\tremaining: 20.7s\n",
            "120:\tlearn: 0.0934882\ttest: 0.0949589\tbest: 0.0949589 (120)\ttotal: 16.6s\tremaining: 17.9s\n",
            "140:\tlearn: 0.0917134\ttest: 0.0932564\tbest: 0.0932564 (140)\ttotal: 19.2s\tremaining: 15.1s\n",
            "160:\tlearn: 0.0904626\ttest: 0.0919823\tbest: 0.0919823 (160)\ttotal: 21.9s\tremaining: 12.4s\n",
            "180:\tlearn: 0.0892769\ttest: 0.0908994\tbest: 0.0908994 (180)\ttotal: 24.6s\tremaining: 9.67s\n",
            "200:\tlearn: 0.0882914\ttest: 0.0900216\tbest: 0.0900216 (200)\ttotal: 27.4s\tremaining: 6.96s\n",
            "220:\tlearn: 0.0872888\ttest: 0.0890679\tbest: 0.0890679 (220)\ttotal: 30.1s\tremaining: 4.22s\n",
            "240:\tlearn: 0.0864464\ttest: 0.0883452\tbest: 0.0883452 (240)\ttotal: 32.9s\tremaining: 1.5s\n",
            "251:\tlearn: 0.0859785\ttest: 0.0879371\tbest: 0.0879371 (251)\ttotal: 34.4s\tremaining: 0us\n",
            "bestTest = 0.0879371016\n",
            "bestIteration = 251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
            "\t0.8928\t = Validation score   (roc_auc)\n",
            "\t47.82s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "\t233501.5\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 4793.17s of the 4793.17s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 4793.17s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting ExtraTreesGini with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.3/32.1 GB\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "\t0.9287\t = Validation score   (roc_auc)\n",
            "\t167.45s\t = Training   runtime\n",
            "\t1.78s\t = Validation runtime\n",
            "\t33183.0\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 4623.23s of the 4623.22s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 4623.23s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting ExtraTreesEntr with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.3/31.9 GB\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "\t0.9329\t = Validation score   (roc_auc)\n",
            "\t160.37s\t = Training   runtime\n",
            "\t1.46s\t = Validation runtime\n",
            "\t40354.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 4460.62s of the 4460.61s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 4460.62s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting NeuralNetFastAI with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=14.2/31.9 GB\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 31/31 categorical features\n",
            "Using 399 cont features\n",
            "Automated batch size selection: 512\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0-2): 3 x Embedding(6, 4)\n",
            "    (3): Embedding(61, 16)\n",
            "    (4): Embedding(62, 16)\n",
            "    (5-7): 3 x Embedding(4, 3)\n",
            "    (8): Embedding(5, 4)\n",
            "    (9-14): 6 x Embedding(4, 3)\n",
            "    (15): Embedding(5, 4)\n",
            "    (16): Embedding(4, 3)\n",
            "    (17): Embedding(5, 4)\n",
            "    (18-20): 3 x Embedding(4, 3)\n",
            "    (21): Embedding(76, 18)\n",
            "    (22): Embedding(114, 23)\n",
            "    (23): Embedding(168, 28)\n",
            "    (24): Embedding(6, 4)\n",
            "    (25-29): 5 x Embedding(4, 3)\n",
            "    (30): Embedding(1304, 89)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(399, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): LinBnDrop(\n",
            "      (0): Linear(in_features=671, out_features=200, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): LinBnDrop(\n",
            "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): LinBnDrop(\n",
            "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Automated epochs selection: training for 30 epoch(s). Estimated time budget use 560.83 / 579.03 sec\n",
            "Better model found at epoch 0 with valid_loss value: 0.10385915637016296.\n",
            "Better model found at epoch 6 with valid_loss value: 0.08888358622789383.\n",
            "No improvement since epoch 6: early stopping\n",
            "Model validation metrics: 0.08888358622789383\n",
            "Saving /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Saving /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "\t0.917\t = Validation score   (roc_auc)\n",
            "\t495.02s\t = Training   runtime\n",
            "\t1.98s\t = Validation runtime\n",
            "\t29831.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: XGBoost ... Training model for up to 3963.42s of the 3963.41s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 3963.42s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting XGBoost with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=10.8/30.1 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.13048\n",
            "[50]\tvalidation_0-logloss:0.08546\n",
            "[100]\tvalidation_0-logloss:0.08015\n",
            "[150]\tvalidation_0-logloss:0.07679\n",
            "[200]\tvalidation_0-logloss:0.07427\n",
            "[250]\tvalidation_0-logloss:0.07201\n",
            "[300]\tvalidation_0-logloss:0.07064\n",
            "[350]\tvalidation_0-logloss:0.06874\n",
            "[400]\tvalidation_0-logloss:0.06716\n",
            "[450]\tvalidation_0-logloss:0.06571\n",
            "[500]\tvalidation_0-logloss:0.06439\n",
            "[550]\tvalidation_0-logloss:0.06334\n",
            "[600]\tvalidation_0-logloss:0.06252\n",
            "[650]\tvalidation_0-logloss:0.06195\n",
            "[700]\tvalidation_0-logloss:0.06123\n",
            "[750]\tvalidation_0-logloss:0.06052\n",
            "[800]\tvalidation_0-logloss:0.05961\n",
            "[850]\tvalidation_0-logloss:0.05898\n",
            "[900]\tvalidation_0-logloss:0.05837\n",
            "[950]\tvalidation_0-logloss:0.05793\n",
            "[1000]\tvalidation_0-logloss:0.05744\n",
            "[1050]\tvalidation_0-logloss:0.05693\n",
            "[1100]\tvalidation_0-logloss:0.05639\n",
            "[1150]\tvalidation_0-logloss:0.05571\n",
            "[1200]\tvalidation_0-logloss:0.05500\n",
            "[1250]\tvalidation_0-logloss:0.05461\n",
            "[1300]\tvalidation_0-logloss:0.05428\n",
            "[1350]\tvalidation_0-logloss:0.05388\n",
            "[1400]\tvalidation_0-logloss:0.05344\n",
            "[1450]\tvalidation_0-logloss:0.05296\n",
            "[1500]\tvalidation_0-logloss:0.05240\n",
            "[1550]\tvalidation_0-logloss:0.05196\n",
            "[1600]\tvalidation_0-logloss:0.05172\n",
            "[1650]\tvalidation_0-logloss:0.05145\n",
            "[1700]\tvalidation_0-logloss:0.05118\n",
            "[1750]\tvalidation_0-logloss:0.05073\n",
            "[1800]\tvalidation_0-logloss:0.05044\n",
            "[1850]\tvalidation_0-logloss:0.05021\n",
            "[1900]\tvalidation_0-logloss:0.04989\n",
            "[1950]\tvalidation_0-logloss:0.04964\n",
            "[2000]\tvalidation_0-logloss:0.04942\n",
            "[2050]\tvalidation_0-logloss:0.04925\n",
            "[2100]\tvalidation_0-logloss:0.04910\n",
            "[2150]\tvalidation_0-logloss:0.04894\n",
            "[2200]\tvalidation_0-logloss:0.04881\n",
            "[2250]\tvalidation_0-logloss:0.04845\n",
            "[2300]\tvalidation_0-logloss:0.04832\n",
            "[2350]\tvalidation_0-logloss:0.04817\n",
            "[2400]\tvalidation_0-logloss:0.04807\n",
            "[2450]\tvalidation_0-logloss:0.04796\n",
            "[2500]\tvalidation_0-logloss:0.04787\n",
            "[2550]\tvalidation_0-logloss:0.04783\n",
            "[2600]\tvalidation_0-logloss:0.04770\n",
            "[2650]\tvalidation_0-logloss:0.04751\n",
            "[2700]\tvalidation_0-logloss:0.04742\n",
            "[2750]\tvalidation_0-logloss:0.04728\n",
            "[2800]\tvalidation_0-logloss:0.04725\n",
            "[2850]\tvalidation_0-logloss:0.04709\n",
            "[2900]\tvalidation_0-logloss:0.04703\n",
            "[2950]\tvalidation_0-logloss:0.04701\n",
            "[3000]\tvalidation_0-logloss:0.04692\n",
            "[3050]\tvalidation_0-logloss:0.04682\n",
            "[3100]\tvalidation_0-logloss:0.04673\n",
            "[3150]\tvalidation_0-logloss:0.04667\n",
            "[3200]\tvalidation_0-logloss:0.04661\n",
            "[3250]\tvalidation_0-logloss:0.04661\n",
            "[3300]\tvalidation_0-logloss:0.04663\n",
            "[3350]\tvalidation_0-logloss:0.04656\n",
            "[3400]\tvalidation_0-logloss:0.04646\n",
            "[3450]\tvalidation_0-logloss:0.04644\n",
            "[3500]\tvalidation_0-logloss:0.04642\n",
            "[3550]\tvalidation_0-logloss:0.04640\n",
            "[3600]\tvalidation_0-logloss:0.04635\n",
            "[3650]\tvalidation_0-logloss:0.04639\n",
            "[3700]\tvalidation_0-logloss:0.04639\n",
            "[3750]\tvalidation_0-logloss:0.04643\n",
            "[3800]\tvalidation_0-logloss:0.04642\n",
            "[3850]\tvalidation_0-logloss:0.04646\n",
            "[3900]\tvalidation_0-logloss:0.04648\n",
            "[3950]\tvalidation_0-logloss:0.04649\n",
            "[4000]\tvalidation_0-logloss:0.04649\n",
            "[4050]\tvalidation_0-logloss:0.04650\n",
            "[4100]\tvalidation_0-logloss:0.04650\n",
            "[4150]\tvalidation_0-logloss:0.04653\n",
            "[4200]\tvalidation_0-logloss:0.04653\n",
            "[4250]\tvalidation_0-logloss:0.04659\n",
            "[4300]\tvalidation_0-logloss:0.04658\n",
            "[4350]\tvalidation_0-logloss:0.04661\n",
            "[4400]\tvalidation_0-logloss:0.04667\n",
            "[4450]\tvalidation_0-logloss:0.04668\n",
            "[4500]\tvalidation_0-logloss:0.04673\n",
            "[4550]\tvalidation_0-logloss:0.04676\n",
            "[4600]\tvalidation_0-logloss:0.04682\n",
            "[4650]\tvalidation_0-logloss:0.04685\n",
            "[4662]\tvalidation_0-logloss:0.04686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [10:08:11] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n",
            "Saving /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "\t0.9716\t = Validation score   (roc_auc)\n",
            "\t160.09s\t = Training   runtime\n",
            "\t3.98s\t = Validation runtime\n",
            "\t14835.7\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 3799.27s of the 3799.26s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 3799.27s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting NeuralNetTorch with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=7.1/30.1 GB\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"TransactionID\",\n",
            "        \"TransactionDT\",\n",
            "        \"card1\",\n",
            "        \"card2\",\n",
            "        \"addr1\",\n",
            "        \"D9\",\n",
            "        \"D15\",\n",
            "        \"V4\",\n",
            "        \"V5\",\n",
            "        \"V10\",\n",
            "        \"V11\",\n",
            "        \"V12\",\n",
            "        \"V13\",\n",
            "        \"V19\",\n",
            "        \"V20\",\n",
            "        \"V29\",\n",
            "        \"V35\",\n",
            "        \"V36\",\n",
            "        \"V48\",\n",
            "        \"V53\",\n",
            "        \"V54\",\n",
            "        \"V61\",\n",
            "        \"V62\",\n",
            "        \"V66\",\n",
            "        \"V69\",\n",
            "        \"V75\",\n",
            "        \"V76\",\n",
            "        \"V82\",\n",
            "        \"V83\",\n",
            "        \"V90\",\n",
            "        \"V194\",\n",
            "        \"id_03\",\n",
            "        \"id_07\",\n",
            "        \"id_17\",\n",
            "        \"id_19\",\n",
            "        \"id_20\",\n",
            "        \"id_25\",\n",
            "        \"id_26\",\n",
            "        \"id_32\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"TransactionAmt\",\n",
            "        \"card3\",\n",
            "        \"card5\",\n",
            "        \"addr2\",\n",
            "        \"dist1\",\n",
            "        \"dist2\",\n",
            "        \"C1\",\n",
            "        \"C2\",\n",
            "        \"C3\",\n",
            "        \"C4\",\n",
            "        \"C5\",\n",
            "        \"C6\",\n",
            "        \"C7\",\n",
            "        \"C8\",\n",
            "        \"C9\",\n",
            "        \"C10\",\n",
            "        \"C11\",\n",
            "        \"C12\",\n",
            "        \"C13\",\n",
            "        \"C14\",\n",
            "        \"D1\",\n",
            "        \"D2\",\n",
            "        \"D3\",\n",
            "        \"D4\",\n",
            "        \"D5\",\n",
            "        \"D6\",\n",
            "        \"D7\",\n",
            "        \"D8\",\n",
            "        \"D10\",\n",
            "        \"D11\",\n",
            "        \"D12\",\n",
            "        \"D13\",\n",
            "        \"D14\",\n",
            "        \"V1\",\n",
            "        \"V2\",\n",
            "        \"V3\",\n",
            "        \"V6\",\n",
            "        \"V7\",\n",
            "        \"V8\",\n",
            "        \"V9\",\n",
            "        \"V14\",\n",
            "        \"V15\",\n",
            "        \"V17\",\n",
            "        \"V18\",\n",
            "        \"V21\",\n",
            "        \"V22\",\n",
            "        \"V23\",\n",
            "        \"V24\",\n",
            "        \"V25\",\n",
            "        \"V26\",\n",
            "        \"V27\",\n",
            "        \"V28\",\n",
            "        \"V30\",\n",
            "        \"V31\",\n",
            "        \"V32\",\n",
            "        \"V33\",\n",
            "        \"V34\",\n",
            "        \"V37\",\n",
            "        \"V38\",\n",
            "        \"V39\",\n",
            "        \"V40\",\n",
            "        \"V41\",\n",
            "        \"V42\",\n",
            "        \"V43\",\n",
            "        \"V44\",\n",
            "        \"V45\",\n",
            "        \"V46\",\n",
            "        \"V47\",\n",
            "        \"V49\",\n",
            "        \"V50\",\n",
            "        \"V51\",\n",
            "        \"V52\",\n",
            "        \"V55\",\n",
            "        \"V56\",\n",
            "        \"V57\",\n",
            "        \"V58\",\n",
            "        \"V59\",\n",
            "        \"V60\",\n",
            "        \"V63\",\n",
            "        \"V64\",\n",
            "        \"V65\",\n",
            "        \"V67\",\n",
            "        \"V68\",\n",
            "        \"V70\",\n",
            "        \"V71\",\n",
            "        \"V72\",\n",
            "        \"V73\",\n",
            "        \"V74\",\n",
            "        \"V77\",\n",
            "        \"V78\",\n",
            "        \"V79\",\n",
            "        \"V80\",\n",
            "        \"V81\",\n",
            "        \"V84\",\n",
            "        \"V85\",\n",
            "        \"V86\",\n",
            "        \"V87\",\n",
            "        \"V88\",\n",
            "        \"V89\",\n",
            "        \"V91\",\n",
            "        \"V92\",\n",
            "        \"V93\",\n",
            "        \"V94\",\n",
            "        \"V95\",\n",
            "        \"V96\",\n",
            "        \"V97\",\n",
            "        \"V98\",\n",
            "        \"V99\",\n",
            "        \"V100\",\n",
            "        \"V101\",\n",
            "        \"V102\",\n",
            "        \"V103\",\n",
            "        \"V104\",\n",
            "        \"V105\",\n",
            "        \"V106\",\n",
            "        \"V107\",\n",
            "        \"V108\",\n",
            "        \"V109\",\n",
            "        \"V110\",\n",
            "        \"V111\",\n",
            "        \"V112\",\n",
            "        \"V113\",\n",
            "        \"V114\",\n",
            "        \"V115\",\n",
            "        \"V116\",\n",
            "        \"V117\",\n",
            "        \"V118\",\n",
            "        \"V120\",\n",
            "        \"V121\",\n",
            "        \"V122\",\n",
            "        \"V123\",\n",
            "        \"V124\",\n",
            "        \"V125\",\n",
            "        \"V126\",\n",
            "        \"V127\",\n",
            "        \"V128\",\n",
            "        \"V129\",\n",
            "        \"V130\",\n",
            "        \"V131\",\n",
            "        \"V132\",\n",
            "        \"V133\",\n",
            "        \"V134\",\n",
            "        \"V135\",\n",
            "        \"V136\",\n",
            "        \"V137\",\n",
            "        \"V138\",\n",
            "        \"V139\",\n",
            "        \"V140\",\n",
            "        \"V141\",\n",
            "        \"V142\",\n",
            "        \"V143\",\n",
            "        \"V144\",\n",
            "        \"V145\",\n",
            "        \"V146\",\n",
            "        \"V147\",\n",
            "        \"V148\",\n",
            "        \"V149\",\n",
            "        \"V150\",\n",
            "        \"V151\",\n",
            "        \"V152\",\n",
            "        \"V153\",\n",
            "        \"V154\",\n",
            "        \"V155\",\n",
            "        \"V156\",\n",
            "        \"V157\",\n",
            "        \"V158\",\n",
            "        \"V159\",\n",
            "        \"V160\",\n",
            "        \"V161\",\n",
            "        \"V162\",\n",
            "        \"V163\",\n",
            "        \"V164\",\n",
            "        \"V165\",\n",
            "        \"V166\",\n",
            "        \"V167\",\n",
            "        \"V168\",\n",
            "        \"V169\",\n",
            "        \"V170\",\n",
            "        \"V171\",\n",
            "        \"V172\",\n",
            "        \"V173\",\n",
            "        \"V174\",\n",
            "        \"V175\",\n",
            "        \"V176\",\n",
            "        \"V177\",\n",
            "        \"V178\",\n",
            "        \"V179\",\n",
            "        \"V180\",\n",
            "        \"V181\",\n",
            "        \"V182\",\n",
            "        \"V183\",\n",
            "        \"V184\",\n",
            "        \"V185\",\n",
            "        \"V186\",\n",
            "        \"V187\",\n",
            "        \"V188\",\n",
            "        \"V189\",\n",
            "        \"V190\",\n",
            "        \"V191\",\n",
            "        \"V192\",\n",
            "        \"V193\",\n",
            "        \"V196\",\n",
            "        \"V197\",\n",
            "        \"V198\",\n",
            "        \"V199\",\n",
            "        \"V200\",\n",
            "        \"V201\",\n",
            "        \"V202\",\n",
            "        \"V203\",\n",
            "        \"V204\",\n",
            "        \"V205\",\n",
            "        \"V206\",\n",
            "        \"V207\",\n",
            "        \"V208\",\n",
            "        \"V209\",\n",
            "        \"V210\",\n",
            "        \"V211\",\n",
            "        \"V212\",\n",
            "        \"V213\",\n",
            "        \"V214\",\n",
            "        \"V215\",\n",
            "        \"V216\",\n",
            "        \"V217\",\n",
            "        \"V218\",\n",
            "        \"V219\",\n",
            "        \"V220\",\n",
            "        \"V221\",\n",
            "        \"V222\",\n",
            "        \"V223\",\n",
            "        \"V224\",\n",
            "        \"V225\",\n",
            "        \"V226\",\n",
            "        \"V227\",\n",
            "        \"V228\",\n",
            "        \"V229\",\n",
            "        \"V230\",\n",
            "        \"V231\",\n",
            "        \"V232\",\n",
            "        \"V233\",\n",
            "        \"V234\",\n",
            "        \"V235\",\n",
            "        \"V236\",\n",
            "        \"V237\",\n",
            "        \"V238\",\n",
            "        \"V239\",\n",
            "        \"V240\",\n",
            "        \"V241\",\n",
            "        \"V242\",\n",
            "        \"V243\",\n",
            "        \"V244\",\n",
            "        \"V245\",\n",
            "        \"V246\",\n",
            "        \"V247\",\n",
            "        \"V248\",\n",
            "        \"V249\",\n",
            "        \"V250\",\n",
            "        \"V251\",\n",
            "        \"V252\",\n",
            "        \"V253\",\n",
            "        \"V254\",\n",
            "        \"V255\",\n",
            "        \"V256\",\n",
            "        \"V257\",\n",
            "        \"V258\",\n",
            "        \"V259\",\n",
            "        \"V260\",\n",
            "        \"V261\",\n",
            "        \"V262\",\n",
            "        \"V263\",\n",
            "        \"V264\",\n",
            "        \"V265\",\n",
            "        \"V266\",\n",
            "        \"V267\",\n",
            "        \"V268\",\n",
            "        \"V269\",\n",
            "        \"V270\",\n",
            "        \"V271\",\n",
            "        \"V272\",\n",
            "        \"V273\",\n",
            "        \"V274\",\n",
            "        \"V275\",\n",
            "        \"V276\",\n",
            "        \"V277\",\n",
            "        \"V278\",\n",
            "        \"V279\",\n",
            "        \"V280\",\n",
            "        \"V281\",\n",
            "        \"V282\",\n",
            "        \"V283\",\n",
            "        \"V284\",\n",
            "        \"V285\",\n",
            "        \"V286\",\n",
            "        \"V287\",\n",
            "        \"V288\",\n",
            "        \"V289\",\n",
            "        \"V290\",\n",
            "        \"V291\",\n",
            "        \"V292\",\n",
            "        \"V293\",\n",
            "        \"V294\",\n",
            "        \"V295\",\n",
            "        \"V296\",\n",
            "        \"V297\",\n",
            "        \"V298\",\n",
            "        \"V299\",\n",
            "        \"V300\",\n",
            "        \"V301\",\n",
            "        \"V302\",\n",
            "        \"V303\",\n",
            "        \"V304\",\n",
            "        \"V305\",\n",
            "        \"V306\",\n",
            "        \"V307\",\n",
            "        \"V308\",\n",
            "        \"V309\",\n",
            "        \"V310\",\n",
            "        \"V311\",\n",
            "        \"V312\",\n",
            "        \"V313\",\n",
            "        \"V314\",\n",
            "        \"V315\",\n",
            "        \"V316\",\n",
            "        \"V317\",\n",
            "        \"V318\",\n",
            "        \"V319\",\n",
            "        \"V320\",\n",
            "        \"V321\",\n",
            "        \"V322\",\n",
            "        \"V323\",\n",
            "        \"V324\",\n",
            "        \"V325\",\n",
            "        \"V326\",\n",
            "        \"V327\",\n",
            "        \"V328\",\n",
            "        \"V329\",\n",
            "        \"V330\",\n",
            "        \"V331\",\n",
            "        \"V332\",\n",
            "        \"V333\",\n",
            "        \"V334\",\n",
            "        \"V335\",\n",
            "        \"V336\",\n",
            "        \"V337\",\n",
            "        \"V338\",\n",
            "        \"V339\",\n",
            "        \"id_01\",\n",
            "        \"id_02\",\n",
            "        \"id_04\",\n",
            "        \"id_05\",\n",
            "        \"id_06\",\n",
            "        \"id_08\",\n",
            "        \"id_09\",\n",
            "        \"id_10\",\n",
            "        \"id_11\",\n",
            "        \"id_13\",\n",
            "        \"id_14\",\n",
            "        \"id_18\",\n",
            "        \"id_21\",\n",
            "        \"id_22\",\n",
            "        \"id_24\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"M1\",\n",
            "        \"M2\",\n",
            "        \"M3\",\n",
            "        \"M5\",\n",
            "        \"M6\",\n",
            "        \"M7\",\n",
            "        \"M8\",\n",
            "        \"M9\",\n",
            "        \"id_12\",\n",
            "        \"id_16\",\n",
            "        \"id_27\",\n",
            "        \"id_28\",\n",
            "        \"id_29\",\n",
            "        \"id_35\",\n",
            "        \"id_36\",\n",
            "        \"id_37\",\n",
            "        \"id_38\",\n",
            "        \"DeviceType\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"ProductCD\",\n",
            "        \"card4\",\n",
            "        \"card6\",\n",
            "        \"P_emaildomain\",\n",
            "        \"R_emaildomain\",\n",
            "        \"M4\",\n",
            "        \"id_15\",\n",
            "        \"id_23\",\n",
            "        \"id_30\",\n",
            "        \"id_31\",\n",
            "        \"id_33\",\n",
            "        \"id_34\",\n",
            "        \"DeviceInfo\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 472432 examples, 430 features (417 vector, 13 embedding)\n",
            "Training on GPU (CUDA)\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0-2): 3 x Embedding(6, 4)\n",
            "    (3): Embedding(61, 15)\n",
            "    (4): Embedding(62, 16)\n",
            "    (5-7): 3 x Embedding(5, 3)\n",
            "    (8): Embedding(77, 18)\n",
            "    (9-10): 2 x Embedding(102, 21)\n",
            "    (11): Embedding(6, 4)\n",
            "    (12): Embedding(102, 21)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=590, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.1, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 1000 epochs...\n",
            "Epoch 1 (Update 1845).\tTrain loss: 0.1097, Val roc_auc: 0.8736, Best Epoch: 1\n",
            "Epoch 2 (Update 3690).\tTrain loss: 0.0987, Val roc_auc: 0.8816, Best Epoch: 2\n",
            "Epoch 3 (Update 5535).\tTrain loss: 0.0957, Val roc_auc: 0.8872, Best Epoch: 3\n",
            "Epoch 4 (Update 7380).\tTrain loss: 0.0935, Val roc_auc: 0.8914, Best Epoch: 4\n",
            "Epoch 5 (Update 9225).\tTrain loss: 0.0916, Val roc_auc: 0.8907, Best Epoch: 4\n",
            "Epoch 6 (Update 11070).\tTrain loss: 0.0902, Val roc_auc: 0.8938, Best Epoch: 6\n",
            "Epoch 7 (Update 12915).\tTrain loss: 0.0888, Val roc_auc: 0.8967, Best Epoch: 7\n",
            "Epoch 8 (Update 14760).\tTrain loss: 0.0875, Val roc_auc: 0.8993, Best Epoch: 8\n",
            "Epoch 9 (Update 16605).\tTrain loss: 0.0864, Val roc_auc: 0.8906, Best Epoch: 8\n",
            "Epoch 10 (Update 18450).\tTrain loss: 0.0854, Val roc_auc: 0.9036, Best Epoch: 10\n",
            "Epoch 11 (Update 20295).\tTrain loss: 0.0844, Val roc_auc: 0.9025, Best Epoch: 10\n",
            "Epoch 12 (Update 22140).\tTrain loss: 0.0835, Val roc_auc: 0.9003, Best Epoch: 10\n",
            "Epoch 13 (Update 23985).\tTrain loss: 0.0826, Val roc_auc: 0.9035, Best Epoch: 10\n",
            "Epoch 14 (Update 25830).\tTrain loss: 0.0818, Val roc_auc: 0.9045, Best Epoch: 14\n",
            "Epoch 15 (Update 27675).\tTrain loss: 0.0807, Val roc_auc: 0.9084, Best Epoch: 15\n",
            "Epoch 16 (Update 29520).\tTrain loss: 0.0802, Val roc_auc: 0.9101, Best Epoch: 16\n",
            "Epoch 17 (Update 31365).\tTrain loss: 0.0795, Val roc_auc: 0.9049, Best Epoch: 16\n",
            "Epoch 18 (Update 33210).\tTrain loss: 0.0788, Val roc_auc: 0.9113, Best Epoch: 18\n",
            "Epoch 19 (Update 35055).\tTrain loss: 0.0784, Val roc_auc: 0.9084, Best Epoch: 18\n",
            "Epoch 20 (Update 36900).\tTrain loss: 0.0778, Val roc_auc: 0.9085, Best Epoch: 18\n",
            "Epoch 21 (Update 38745).\tTrain loss: 0.0769, Val roc_auc: 0.9091, Best Epoch: 18\n",
            "Epoch 22 (Update 40590).\tTrain loss: 0.0766, Val roc_auc: 0.9099, Best Epoch: 18\n",
            "Epoch 23 (Update 42435).\tTrain loss: 0.0761, Val roc_auc: 0.9119, Best Epoch: 23\n",
            "Epoch 24 (Update 44280).\tTrain loss: 0.0755, Val roc_auc: 0.9085, Best Epoch: 23\n",
            "Epoch 25 (Update 46125).\tTrain loss: 0.075, Val roc_auc: 0.9049, Best Epoch: 23\n",
            "Epoch 26 (Update 47970).\tTrain loss: 0.0746, Val roc_auc: 0.9084, Best Epoch: 23\n",
            "Epoch 27 (Update 49815).\tTrain loss: 0.074, Val roc_auc: 0.9124, Best Epoch: 27\n",
            "Epoch 28 (Update 51660).\tTrain loss: 0.0736, Val roc_auc: 0.9105, Best Epoch: 27\n",
            "Epoch 29 (Update 53505).\tTrain loss: 0.0729, Val roc_auc: 0.9143, Best Epoch: 29\n",
            "Epoch 30 (Update 55350).\tTrain loss: 0.0727, Val roc_auc: 0.9119, Best Epoch: 29\n",
            "Epoch 31 (Update 57195).\tTrain loss: 0.0727, Val roc_auc: 0.912, Best Epoch: 29\n",
            "Epoch 32 (Update 59040).\tTrain loss: 0.0722, Val roc_auc: 0.9128, Best Epoch: 29\n",
            "Epoch 33 (Update 60885).\tTrain loss: 0.0715, Val roc_auc: 0.9131, Best Epoch: 29\n",
            "Epoch 34 (Update 62730).\tTrain loss: 0.0713, Val roc_auc: 0.917, Best Epoch: 34\n",
            "Epoch 35 (Update 64575).\tTrain loss: 0.0709, Val roc_auc: 0.9097, Best Epoch: 34\n",
            "Epoch 36 (Update 66420).\tTrain loss: 0.0705, Val roc_auc: 0.9138, Best Epoch: 34\n",
            "Epoch 37 (Update 68265).\tTrain loss: 0.0702, Val roc_auc: 0.9156, Best Epoch: 34\n",
            "Epoch 38 (Update 70110).\tTrain loss: 0.0701, Val roc_auc: 0.9154, Best Epoch: 34\n",
            "Epoch 39 (Update 71955).\tTrain loss: 0.0696, Val roc_auc: 0.9061, Best Epoch: 34\n",
            "Epoch 40 (Update 73800).\tTrain loss: 0.0693, Val roc_auc: 0.9154, Best Epoch: 34\n",
            "Epoch 41 (Update 75645).\tTrain loss: 0.0691, Val roc_auc: 0.9149, Best Epoch: 34\n",
            "Epoch 42 (Update 77490).\tTrain loss: 0.0691, Val roc_auc: 0.9103, Best Epoch: 34\n",
            "Epoch 43 (Update 79335).\tTrain loss: 0.0688, Val roc_auc: 0.9042, Best Epoch: 34\n",
            "Epoch 44 (Update 81180).\tTrain loss: 0.0682, Val roc_auc: 0.9098, Best Epoch: 34\n",
            "Epoch 45 (Update 83025).\tTrain loss: 0.0679, Val roc_auc: 0.9173, Best Epoch: 45\n",
            "Epoch 46 (Update 84870).\tTrain loss: 0.0678, Val roc_auc: 0.9137, Best Epoch: 45\n",
            "Epoch 47 (Update 86715).\tTrain loss: 0.0669, Val roc_auc: 0.9192, Best Epoch: 47\n",
            "Epoch 48 (Update 88560).\tTrain loss: 0.0673, Val roc_auc: 0.9137, Best Epoch: 47\n",
            "Epoch 49 (Update 90405).\tTrain loss: 0.0672, Val roc_auc: 0.9119, Best Epoch: 47\n",
            "Epoch 50 (Update 92250).\tTrain loss: 0.0665, Val roc_auc: 0.9153, Best Epoch: 47\n",
            "Epoch 51 (Update 94095).\tTrain loss: 0.0666, Val roc_auc: 0.912, Best Epoch: 47\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 51)\n",
            "Best model found on Epoch 47 (Update 86715). Val roc_auc: 0.9192228764249275\n",
            "Saving /content/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "\t0.9192\t = Validation score   (roc_auc)\n",
            "\t591.78s\t = Training   runtime\n",
            "\t3.18s\t = Validation runtime\n",
            "\t18573.5\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBMLarge ... Training model for up to 3204.29s of the 3204.28s of remaining time.\n",
            "\tTime limit adjusted due to model hyperparameters: 3204.29s -> 600.00s (ag.max_time_limit=600, ag.max_time_limit_ratio=1.0, ag.min_time_limit=0)\n",
            "\tFitting LightGBMLarge with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=8.1/30.1 GB\n",
            "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0880336\n",
            "[100]\tvalid_set's binary_logloss: 0.0755784\n",
            "[150]\tvalid_set's binary_logloss: 0.0684044\n",
            "[200]\tvalid_set's binary_logloss: 0.0640427\n",
            "[250]\tvalid_set's binary_logloss: 0.0610058\n",
            "[300]\tvalid_set's binary_logloss: 0.0589466\n",
            "[350]\tvalid_set's binary_logloss: 0.0572527\n",
            "[400]\tvalid_set's binary_logloss: 0.0559764\n",
            "[450]\tvalid_set's binary_logloss: 0.0547917\n",
            "[500]\tvalid_set's binary_logloss: 0.0536916\n",
            "[550]\tvalid_set's binary_logloss: 0.0527685\n",
            "[600]\tvalid_set's binary_logloss: 0.0519002\n",
            "[650]\tvalid_set's binary_logloss: 0.0511564\n",
            "[700]\tvalid_set's binary_logloss: 0.0503616\n",
            "[750]\tvalid_set's binary_logloss: 0.0496843\n",
            "[800]\tvalid_set's binary_logloss: 0.049099\n",
            "[850]\tvalid_set's binary_logloss: 0.0485218\n",
            "[900]\tvalid_set's binary_logloss: 0.04804\n",
            "[950]\tvalid_set's binary_logloss: 0.0476509\n",
            "[1000]\tvalid_set's binary_logloss: 0.0472809\n",
            "[1050]\tvalid_set's binary_logloss: 0.0469302\n",
            "[1100]\tvalid_set's binary_logloss: 0.0466281\n",
            "[1150]\tvalid_set's binary_logloss: 0.0463624\n",
            "[1200]\tvalid_set's binary_logloss: 0.0460682\n",
            "[1250]\tvalid_set's binary_logloss: 0.0458068\n",
            "[1300]\tvalid_set's binary_logloss: 0.0456036\n",
            "[1350]\tvalid_set's binary_logloss: 0.0454014\n",
            "[1400]\tvalid_set's binary_logloss: 0.0451775\n",
            "[1450]\tvalid_set's binary_logloss: 0.0450582\n",
            "[1500]\tvalid_set's binary_logloss: 0.0448814\n",
            "[1550]\tvalid_set's binary_logloss: 0.0447625\n",
            "[1600]\tvalid_set's binary_logloss: 0.0446345\n",
            "[1650]\tvalid_set's binary_logloss: 0.0445801\n",
            "[1700]\tvalid_set's binary_logloss: 0.0444627\n",
            "[1750]\tvalid_set's binary_logloss: 0.0443573\n",
            "[1800]\tvalid_set's binary_logloss: 0.0442831\n",
            "[1850]\tvalid_set's binary_logloss: 0.044252\n",
            "[1900]\tvalid_set's binary_logloss: 0.0441962\n",
            "[1950]\tvalid_set's binary_logloss: 0.0441699\n",
            "[2000]\tvalid_set's binary_logloss: 0.0441885\n",
            "[2050]\tvalid_set's binary_logloss: 0.044206\n",
            "[2100]\tvalid_set's binary_logloss: 0.0442206\n",
            "[2150]\tvalid_set's binary_logloss: 0.0442554\n",
            "[2200]\tvalid_set's binary_logloss: 0.0442673\n",
            "[2250]\tvalid_set's binary_logloss: 0.0442871\n",
            "[2300]\tvalid_set's binary_logloss: 0.0443072\n",
            "[2350]\tvalid_set's binary_logloss: 0.0443378\n",
            "[2400]\tvalid_set's binary_logloss: 0.0443819\n",
            "[2450]\tvalid_set's binary_logloss: 0.0444415\n",
            "[2500]\tvalid_set's binary_logloss: 0.044503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "\t0.9739\t = Validation score   (roc_auc)\n",
            "\t246.93s\t = Training   runtime\n",
            "\t8.09s\t = Validation runtime\n",
            "\t7301.6\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 597.05s of the 2948.89s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 10\n",
            "Ensemble weights: \n",
            "[0.1 0.2 0.  0.  0.  0.  0.  0.  0.2 0.  0.5]\n",
            "\t0.27s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMLarge': 0.5, 'LightGBM': 0.2, 'XGBoost': 0.2, 'LightGBMXT': 0.1}\n",
            "\t0.9759\t = Validation score   (roc_auc)\n",
            "\t2.43s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t1550.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 3057.9s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1550.4 rows/s (59054 batch size)\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Saving /content/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels\")\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2   0.975872     roc_auc      38.089493  1034.209839                0.012952           2.429978            2       True         12\n",
            "1         LightGBMLarge   0.973947     roc_auc       8.087820   246.932923                8.087820         246.932923            1       True         11\n",
            "2              LightGBM   0.972541     roc_auc      11.197899   272.529114               11.197899         272.529114            1       True          2\n",
            "3               XGBoost   0.971573     roc_auc       3.980546   160.087104                3.980546         160.087104            1       True          9\n",
            "4            LightGBMXT   0.970478     roc_auc      14.810276   352.230719               14.810276         352.230719            1       True          1\n",
            "5      RandomForestEntr   0.938039     roc_auc       1.441967   205.222568                1.441967         205.222568            1       True          4\n",
            "6      RandomForestGini   0.935588     roc_auc       1.719464   267.945380                1.719464         267.945380            1       True          3\n",
            "7        ExtraTreesEntr   0.932868     roc_auc       1.463384   160.373456                1.463384         160.373456            1       True          7\n",
            "8        ExtraTreesGini   0.928724     roc_auc       1.779644   167.449829                1.779644         167.449829            1       True          6\n",
            "9        NeuralNetTorch   0.919223     roc_auc       3.179468   591.775288                3.179468         591.775288            1       True         10\n",
            "10      NeuralNetFastAI   0.917028     roc_auc       1.979590   495.016672                1.979590         495.016672            1       True          8\n",
            "11             CatBoost   0.892793     roc_auc       0.252906    47.817655                0.252906          47.817655            1       True          5\n",
            "Number of models trained: 12\n",
            "Types of models trained:\n",
            "{'TabularNeuralNetTorchModel', 'XGBoostModel', 'NNFastAiTabularModel', 'LGBModel', 'WeightedEnsembleModel', 'CatBoostModel', 'XTModel', 'RFModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "Plot summary of models saved to file: /content/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard()"
      ],
      "metadata": {
        "id": "782_DHP4LEkR",
        "outputId": "14316f7c-920d-4c95-a91c-11082c2d3243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "id": "782_DHP4LEkR",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model  score_val eval_metric  pred_time_val     fit_time  \\\n",
              "0   WeightedEnsemble_L2   0.975872     roc_auc      38.089493  1034.209839   \n",
              "1         LightGBMLarge   0.973947     roc_auc       8.087820   246.932923   \n",
              "2              LightGBM   0.972541     roc_auc      11.197899   272.529114   \n",
              "3               XGBoost   0.971573     roc_auc       3.980546   160.087104   \n",
              "4            LightGBMXT   0.970478     roc_auc      14.810276   352.230719   \n",
              "5      RandomForestEntr   0.938039     roc_auc       1.441967   205.222568   \n",
              "6      RandomForestGini   0.935588     roc_auc       1.719464   267.945380   \n",
              "7        ExtraTreesEntr   0.932868     roc_auc       1.463384   160.373456   \n",
              "8        ExtraTreesGini   0.928724     roc_auc       1.779644   167.449829   \n",
              "9        NeuralNetTorch   0.919223     roc_auc       3.179468   591.775288   \n",
              "10      NeuralNetFastAI   0.917028     roc_auc       1.979590   495.016672   \n",
              "11             CatBoost   0.892793     roc_auc       0.252906    47.817655   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.012952           2.429978            2       True   \n",
              "1                 8.087820         246.932923            1       True   \n",
              "2                11.197899         272.529114            1       True   \n",
              "3                 3.980546         160.087104            1       True   \n",
              "4                14.810276         352.230719            1       True   \n",
              "5                 1.441967         205.222568            1       True   \n",
              "6                 1.719464         267.945380            1       True   \n",
              "7                 1.463384         160.373456            1       True   \n",
              "8                 1.779644         167.449829            1       True   \n",
              "9                 3.179468         591.775288            1       True   \n",
              "10                1.979590         495.016672            1       True   \n",
              "11                0.252906          47.817655            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          12  \n",
              "1          11  \n",
              "2           2  \n",
              "3           9  \n",
              "4           1  \n",
              "5           4  \n",
              "6           3  \n",
              "7           7  \n",
              "8           6  \n",
              "9          10  \n",
              "10          8  \n",
              "11          5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1f23911-4e90-41f2-8090-a44b968efcd5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.975872</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>38.089493</td>\n",
              "      <td>1034.209839</td>\n",
              "      <td>0.012952</td>\n",
              "      <td>2.429978</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.973947</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>8.087820</td>\n",
              "      <td>246.932923</td>\n",
              "      <td>8.087820</td>\n",
              "      <td>246.932923</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.972541</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>11.197899</td>\n",
              "      <td>272.529114</td>\n",
              "      <td>11.197899</td>\n",
              "      <td>272.529114</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.971573</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>3.980546</td>\n",
              "      <td>160.087104</td>\n",
              "      <td>3.980546</td>\n",
              "      <td>160.087104</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.970478</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>14.810276</td>\n",
              "      <td>352.230719</td>\n",
              "      <td>14.810276</td>\n",
              "      <td>352.230719</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.938039</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.441967</td>\n",
              "      <td>205.222568</td>\n",
              "      <td>1.441967</td>\n",
              "      <td>205.222568</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.935588</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.719464</td>\n",
              "      <td>267.945380</td>\n",
              "      <td>1.719464</td>\n",
              "      <td>267.945380</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.932868</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.463384</td>\n",
              "      <td>160.373456</td>\n",
              "      <td>1.463384</td>\n",
              "      <td>160.373456</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.928724</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.779644</td>\n",
              "      <td>167.449829</td>\n",
              "      <td>1.779644</td>\n",
              "      <td>167.449829</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.919223</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>3.179468</td>\n",
              "      <td>591.775288</td>\n",
              "      <td>3.179468</td>\n",
              "      <td>591.775288</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.917028</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.979590</td>\n",
              "      <td>495.016672</td>\n",
              "      <td>1.979590</td>\n",
              "      <td>495.016672</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.892793</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.252906</td>\n",
              "      <td>47.817655</td>\n",
              "      <td>0.252906</td>\n",
              "      <td>47.817655</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1f23911-4e90-41f2-8090-a44b968efcd5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1f23911-4e90-41f2-8090-a44b968efcd5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1f23911-4e90-41f2-8090-a44b968efcd5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b84151b2-a98e-490c-a235-b00546b74605\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b84151b2-a98e-490c-a235-b00546b74605')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b84151b2-a98e-490c-a235-b00546b74605 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"NeuralNetFastAI\",\n          \"NeuralNetTorch\",\n          \"WeightedEnsemble_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027986403722676485,\n        \"min\": 0.892793427715731,\n        \"max\": 0.9758717227267695,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.9170279840507174,\n          0.9192228764249275,\n          0.9758717227267695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roc_auc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.686288649905814,\n        \"min\": 0.25290632247924805,\n        \"max\": 38.08949327468872,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          1.9795899391174316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 267.19665442026707,\n        \"min\": 47.817654848098755,\n        \"max\": 1034.209838628769,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          495.01667189598083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.698946885489398,\n        \"min\": 0.012952089309692383,\n        \"max\": 14.810275554656982,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          1.9795899391174316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 169.26662773088756,\n        \"min\": 2.429978370666504,\n        \"max\": 591.7752883434296,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          495.01667189598083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_true = test_data[label].astype(int)\n",
        "y_prad = predictor.predict(test_data.drop(columns=[label]),model='LightGBMLarge')\n",
        "auc = roc_auc_score(y_true, y_prad)\n",
        "print(auc)"
      ],
      "metadata": {
        "id": "tmwQfUAoLb22",
        "outputId": "2f510a09-40b9-4b61-aa08-cee670fa27d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tmwQfUAoLb22",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8469334058814745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prad.value_counts(),y_true.value_counts()"
      ],
      "metadata": {
        "id": "sqnEoUy5NKZ4",
        "outputId": "662c5863-5124-4ce2-93cd-e7697a177510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sqnEoUy5NKZ4",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(isFraud\n",
              " 0    57569\n",
              " 1     1485\n",
              " Name: count, dtype: int64,\n",
              " isFraud\n",
              " 0    56987\n",
              " 1     2067\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_identity = pd.read_csv(directory+'test_identity.csv')\n",
        "test_transaction = pd.read_csv(directory+'test_transaction.csv')\n",
        "test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n",
        "\n",
        "y_predproba = predictor.predict_proba(test_data)\n",
        "y_predproba.head(5)  # some example predicted fraud-probabilities"
      ],
      "metadata": {
        "id": "dt9S76KQaz6e"
      },
      "id": "dt9S76KQaz6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "id": "oQgwNpCNa1ia"
      },
      "id": "oQgwNpCNa1ia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "id": "e3jdxESRa3Kt"
      },
      "id": "e3jdxESRa3Kt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "id": "Vez_9GNza4vC"
      },
      "id": "Vez_9GNza4vC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "ot_fBRgJbCxN"
      },
      "id": "ot_fBRgJbCxN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}