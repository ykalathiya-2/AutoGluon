{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykalathiya-2/AutoGluon/blob/main/fraud_detection/fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLOYOO10iA2h",
        "outputId": "ae89aceb-e843-4e9c-88a6-db6ea4b173cd"
      },
      "id": "dLOYOO10iA2h",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_columns', 200)"
      ],
      "metadata": {
        "id": "Oyd7hRnAmnOh"
      },
      "id": "Oyd7hRnAmnOh",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/AutoGluon_dataset/ieee-fraud-detection.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQEE4yP4XXU6",
        "outputId": "2cfc7284-f788-43f8-f78a-e9d524311a47"
      },
      "id": "xQEE4yP4XXU6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/AutoGluon_dataset/ieee-fraud-detection.zip\n",
            "  inflating: /content/sample_submission.csv  \n",
            "  inflating: /content/test_identity.csv  \n",
            "  inflating: /content/test_transaction.csv  \n",
            "  inflating: /content/train_identity.csv  \n",
            "  inflating: /content/train_transaction.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4FFNUZSXiGM",
        "outputId": "40668681-ef1d-4175-ebfe-a1cca6289f3f"
      },
      "id": "r4FFNUZSXiGM",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = '/content/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "KLaNxkUWXfTA"
      },
      "id": "KLaNxkUWXfTA",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "Xj-iOEArZ6iQ"
      },
      "id": "Xj-iOEArZ6iQ",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['isFraud'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DvvGLdMgxZqR",
        "outputId": "1d4ab8b4-a699-4870-e0e1-acbab5ac17af"
      },
      "id": "DvvGLdMgxZqR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isFraud\n",
              "0    569877\n",
              "1     20663\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>569877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(train_data, test_size=0.2, random_state=42,stratify=train_data['isFraud'])\n",
        "test_data, val_data = train_test_split(temp_data, test_size=0.5, random_state=42,stratify=temp_data['isFraud'])"
      ],
      "metadata": {
        "id": "PkN7w2qMl6Tj"
      },
      "id": "PkN7w2qMl6Tj",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "feunXiRHmF2U",
        "outputId": "0db25064-895e-47dc-a650-0192d1130f2f"
      },
      "id": "feunXiRHmF2U",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
              "40809         3027809        0        1008491          100.00         R   \n",
              "285886        3272886        0        7008212           29.99         W   \n",
              "104256        3091256        0        2071522          107.95         W   \n",
              "507860        3494860        0       13299752          241.95         W   \n",
              "196382        3183382        0        4412283          117.00         W   \n",
              "\n",
              "        card1  card2  card3             card4  card5   card6  addr1  addr2  \\\n",
              "40809    6177  399.0  150.0  american express  150.0  credit  264.0   87.0   \n",
              "285886   7900  345.0  150.0        mastercard  224.0   debit  143.0   87.0   \n",
              "104256  11690  111.0  150.0              visa  226.0  credit  191.0   87.0   \n",
              "507860   2616  327.0  150.0          discover  102.0  credit  330.0   87.0   \n",
              "196382  13780  298.0  150.0              visa  226.0   debit  441.0   87.0   \n",
              "\n",
              "        dist1  dist2  P_emaildomain  R_emaildomain   C1   C2   C3   C4   C5  \\\n",
              "40809     NaN    1.0  anonymous.com  anonymous.com  1.0  1.0  0.0  2.0  0.0   \n",
              "285886    4.0    NaN      gmail.com            NaN  1.0  1.0  0.0  0.0  0.0   \n",
              "104256    NaN    NaN    comcast.net            NaN  1.0  1.0  0.0  0.0  1.0   \n",
              "507860    3.0    NaN            NaN            NaN  1.0  2.0  0.0  0.0  1.0   \n",
              "196382    5.0    NaN            NaN            NaN  1.0  1.0  0.0  0.0  0.0   \n",
              "\n",
              "         C6   C7   C8   C9  C10  C11  C12   C13  C14     D1     D2    D3  \\\n",
              "40809   1.0  0.0  2.0  0.0  2.0  1.0  0.0   2.0  1.0  609.0  609.0   NaN   \n",
              "285886  1.0  0.0  0.0  1.0  0.0  1.0  0.0   0.0  0.0    0.0    NaN   NaN   \n",
              "104256  1.0  0.0  0.0  1.0  0.0  1.0  0.0  15.0  1.0  501.0  501.0  18.0   \n",
              "507860  1.0  0.0  0.0  1.0  0.0  1.0  0.0   4.0  1.0  177.0  177.0  86.0   \n",
              "196382  0.0  0.0  0.0  1.0  0.0  1.0  0.0   2.0  1.0    0.0    0.0   0.0   \n",
              "\n",
              "           D4    D5  D6  D7          D8        D9    D10    D11  D12  D13  \\\n",
              "40809     NaN   NaN NaN NaN  609.666687  0.666666    NaN    NaN  NaN  NaN   \n",
              "285886    0.0   NaN NaN NaN         NaN       NaN    0.0    0.0  NaN  NaN   \n",
              "104256  502.0  18.0 NaN NaN         NaN       NaN  502.0    NaN  NaN  NaN   \n",
              "507860    NaN   NaN NaN NaN         NaN       NaN  177.0  177.0  NaN  NaN   \n",
              "196382    NaN   NaN NaN NaN         NaN       NaN    0.0    0.0  NaN  NaN   \n",
              "\n",
              "        D14    D15   M1   M2   M3   M4   M5   M6   M7   M8   M9   V1   V2  \\\n",
              "40809   NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  NaN    0.0    T    T    T   M0    T    F    F    F    T  1.0  1.0   \n",
              "104256  NaN  502.0  NaN  NaN  NaN  NaN  NaN    T  NaN  NaN  NaN  NaN  NaN   \n",
              "507860  NaN  177.0    T    T    F  NaN  NaN    T    F    F    T  1.0  1.0   \n",
              "196382  NaN    0.0    T    T    T   M0    T    F  NaN  NaN  NaN  1.0  1.0   \n",
              "\n",
              "         V3   V4   V5   V6   V7   V8   V9  V10  V11  V12  V13  V14  V15  V16  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
              "104256  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  1.0  1.0  0.0  0.0   \n",
              "507860  1.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0   \n",
              "196382  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
              "\n",
              "        V17  V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
              "104256  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0   \n",
              "507860  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0   \n",
              "196382  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "        V31  V32  V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "104256  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "507860  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "196382  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "\n",
              "        V45  ...  V280  V281  V282  V283  V284  V285  V286  V287  V288  V289  \\\n",
              "40809   NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886  1.0  ...   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256  1.0  ...   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
              "507860  NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382  NaN  ...   1.0   1.0   2.0   2.0   1.0   1.0   1.0   1.0   1.0   1.0   \n",
              "\n",
              "        V290  V291  V292  V293  V294  V295  V296  V297  V298  V299  V300  \\\n",
              "40809    1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "507860   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "        V301  V302  V303  V304  V305   V306   V307   V308   V309   V310  \\\n",
              "40809    0.0   1.0   1.0   1.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "285886   0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "104256   0.0   0.0   0.0   0.0   1.0    0.0  200.0    0.0    0.0  200.0   \n",
              "507860   0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "196382   0.0   0.0   0.0   0.0   1.0  117.0  117.0  117.0  117.0  117.0   \n",
              "\n",
              "         V311   V312   V313   V314   V315  V316  V317  V318  V319  V320  V321  \\\n",
              "40809     0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "507860    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382  117.0  117.0  117.0  117.0  117.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "        V322  V323  V324  V325  V326  V327  V328  V329  V330  V331  V332  \\\n",
              "40809    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "104256   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "507860   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "196382   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "\n",
              "        V333  V334  V335  V336  V337  V338  V339  id_01    id_02  id_03  \\\n",
              "40809    0.0   0.0   0.0   0.0   0.0   0.0   0.0   -5.0  58410.0    0.0   \n",
              "285886   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "104256   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "507860   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "196382   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "\n",
              "        id_04  id_05  id_06  id_07  id_08  id_09  id_10  id_11     id_12  \\\n",
              "40809     0.0    0.0    0.0    NaN    NaN    0.0    0.0  100.0  NotFound   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "\n",
              "        id_13  id_14  id_15  id_16  id_17  id_18  id_19  id_20  id_21  id_22  \\\n",
              "40809    52.0 -360.0  Found  Found  166.0    NaN  300.0  214.0    NaN    NaN   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "        id_23  id_24  id_25  id_26  id_27  id_28  id_29      id_30  \\\n",
              "40809     NaN    NaN    NaN    NaN    NaN  Found  Found  Windows 7   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "\n",
              "                      id_31  id_32      id_33           id_34  id_35  id_36  \\\n",
              "40809   ie 11.0 for desktop   24.0  1920x1080  match_status:2      T      F   \n",
              "285886                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "104256                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "507860                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "196382                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "\n",
              "        id_37  id_38  DeviceType   DeviceInfo  \n",
              "40809       T      T     desktop  Trident/7.0  \n",
              "285886    NaN    NaN         NaN          NaN  \n",
              "104256    NaN    NaN         NaN          NaN  \n",
              "507860    NaN    NaN         NaN          NaN  \n",
              "196382    NaN    NaN         NaN          NaN  \n",
              "\n",
              "[5 rows x 434 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd23092-c034-43e7-a448-3d5cf170c8c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>M1</th>\n",
              "      <th>M2</th>\n",
              "      <th>M3</th>\n",
              "      <th>M4</th>\n",
              "      <th>M5</th>\n",
              "      <th>M6</th>\n",
              "      <th>M7</th>\n",
              "      <th>M8</th>\n",
              "      <th>M9</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>...</th>\n",
              "      <th>V280</th>\n",
              "      <th>V281</th>\n",
              "      <th>V282</th>\n",
              "      <th>V283</th>\n",
              "      <th>V284</th>\n",
              "      <th>V285</th>\n",
              "      <th>V286</th>\n",
              "      <th>V287</th>\n",
              "      <th>V288</th>\n",
              "      <th>V289</th>\n",
              "      <th>V290</th>\n",
              "      <th>V291</th>\n",
              "      <th>V292</th>\n",
              "      <th>V293</th>\n",
              "      <th>V294</th>\n",
              "      <th>V295</th>\n",
              "      <th>V296</th>\n",
              "      <th>V297</th>\n",
              "      <th>V298</th>\n",
              "      <th>V299</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40809</th>\n",
              "      <td>3027809</td>\n",
              "      <td>0</td>\n",
              "      <td>1008491</td>\n",
              "      <td>100.00</td>\n",
              "      <td>R</td>\n",
              "      <td>6177</td>\n",
              "      <td>399.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>american express</td>\n",
              "      <td>150.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>264.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>anonymous.com</td>\n",
              "      <td>anonymous.com</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>609.666687</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>58410.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>300.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Windows 7</td>\n",
              "      <td>ie 11.0 for desktop</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285886</th>\n",
              "      <td>3272886</td>\n",
              "      <td>0</td>\n",
              "      <td>7008212</td>\n",
              "      <td>29.99</td>\n",
              "      <td>W</td>\n",
              "      <td>7900</td>\n",
              "      <td>345.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>143.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>M0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104256</th>\n",
              "      <td>3091256</td>\n",
              "      <td>0</td>\n",
              "      <td>2071522</td>\n",
              "      <td>107.95</td>\n",
              "      <td>W</td>\n",
              "      <td>11690</td>\n",
              "      <td>111.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>191.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>comcast.net</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>502.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>502.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507860</th>\n",
              "      <td>3494860</td>\n",
              "      <td>0</td>\n",
              "      <td>13299752</td>\n",
              "      <td>241.95</td>\n",
              "      <td>W</td>\n",
              "      <td>2616</td>\n",
              "      <td>327.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>177.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>177.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196382</th>\n",
              "      <td>3183382</td>\n",
              "      <td>0</td>\n",
              "      <td>4412283</td>\n",
              "      <td>117.00</td>\n",
              "      <td>W</td>\n",
              "      <td>13780</td>\n",
              "      <td>298.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>441.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>M0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 434 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd23092-c034-43e7-a448-3d5cf170c8c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cd23092-c034-43e7-a448-3d5cf170c8c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cd23092-c034-43e7-a448-3d5cf170c8c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e679f54-27f7-41b6-8c48-3d54ff7d6ca8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e679f54-27f7-41b6-8c48-3d54ff7d6ca8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e679f54-27f7-41b6-8c48-3d54ff7d6ca8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELMPJ2u6m3pH",
        "outputId": "7697c4a7-86f2-45e1-f5e7-16905818caf2"
      },
      "id": "ELMPJ2u6m3pH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(472432, 434)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01MxaCIRm5jY",
        "outputId": "03c46b35-da7b-40d8-f3e9-7b378a4e66f7"
      },
      "id": "01MxaCIRm5jY",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 472432 entries, 40809 to 337290\n",
            "Columns: 434 entries, TransactionID to DeviceInfo\n",
            "dtypes: float64(399), int64(4), object(31)\n",
            "memory usage: 1.5+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Gm1betSrbGnG",
        "outputId": "c70a24b7-4a0a-47fb-b0c0-ca07c604b705"
      },
      "id": "Gm1betSrbGnG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       TransactionID        isFraud  TransactionDT  TransactionAmt  \\\n",
              "count   4.724320e+05  472432.000000   4.724320e+05   472432.000000   \n",
              "mean    3.282316e+06       0.034989   7.373394e+06      135.071756   \n",
              "std     1.704469e+05       0.183753   4.616510e+06      241.371497   \n",
              "min     2.987000e+06       0.000000   8.640000e+04        0.251000   \n",
              "25%     3.134756e+06       0.000000   3.028537e+06       43.140000   \n",
              "50%     3.282400e+06       0.000000   7.309639e+06       68.911000   \n",
              "75%     3.429918e+06       0.000000   1.124764e+07      125.000000   \n",
              "max     3.577539e+06       1.000000   1.581113e+07    31937.391000   \n",
              "\n",
              "               card1          card2          card3         card5  \\\n",
              "count  472432.000000  465285.000000  471197.000000  469035.00000   \n",
              "mean     9903.027720     362.527137     153.203514     199.30153   \n",
              "std      4902.685441     157.783396      11.353198      41.21739   \n",
              "min      1001.000000     100.000000     100.000000     100.00000   \n",
              "25%      6019.000000     214.000000     150.000000     166.00000   \n",
              "50%      9689.000000     361.000000     150.000000     226.00000   \n",
              "75%     14203.000000     512.000000     150.000000     226.00000   \n",
              "max     18396.000000     600.000000     231.000000     237.00000   \n",
              "\n",
              "               addr1          addr2          dist1         dist2  \\\n",
              "count  419709.000000  419709.000000  190428.000000  30156.000000   \n",
              "mean      290.762967      86.799525     118.583764    231.967933   \n",
              "std       101.785679       2.709423     371.935971    530.961675   \n",
              "min       100.000000      10.000000       0.000000      0.000000   \n",
              "25%       204.000000      87.000000       3.000000      7.000000   \n",
              "50%       299.000000      87.000000       8.000000     38.000000   \n",
              "75%       330.000000      87.000000      24.000000    207.000000   \n",
              "max       540.000000     102.000000   10286.000000  11623.000000   \n",
              "\n",
              "                  C1             C2             C3             C4  \\\n",
              "count  472432.000000  472432.000000  472432.000000  472432.000000   \n",
              "mean       14.032987      15.208627       0.005542       4.070306   \n",
              "std       132.403910     153.286836       0.141592      68.312944   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       0.000000       0.000000   \n",
              "50%         1.000000       1.000000       0.000000       0.000000   \n",
              "75%         3.000000       3.000000       0.000000       0.000000   \n",
              "max      4685.000000    5691.000000      26.000000    2253.000000   \n",
              "\n",
              "                  C5             C6             C7             C8  \\\n",
              "count  472432.000000  472432.000000  472432.000000  472432.000000   \n",
              "mean        5.552901       9.037030       2.822131       5.110992   \n",
              "std        25.731393      70.983085      61.099606      94.517683   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       0.000000       0.000000   \n",
              "50%         0.000000       1.000000       0.000000       0.000000   \n",
              "75%         1.000000       2.000000       0.000000       0.000000   \n",
              "max       349.000000    2253.000000    2255.000000    3331.000000   \n",
              "\n",
              "                  C9            C10            C11            C12  \\\n",
              "count  472432.000000  472432.000000  472432.000000  472432.000000   \n",
              "mean        4.467680       5.204834      10.198232       4.040867   \n",
              "std        16.637458      94.760417      93.546109      85.789475   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       1.000000       0.000000   \n",
              "50%         1.000000       0.000000       1.000000       0.000000   \n",
              "75%         2.000000       0.000000       2.000000       0.000000   \n",
              "max       210.000000    3257.000000    3188.000000    3188.000000   \n",
              "\n",
              "                 C13            C14             D1             D2  \\\n",
              "count  472432.000000  472432.000000  471398.000000  247635.000000   \n",
              "mean       32.418708       8.266002      94.290778     169.547641   \n",
              "std       128.712688      49.233935     157.580267     177.240248   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       0.000000      26.000000   \n",
              "50%         3.000000       1.000000       3.000000      97.000000   \n",
              "75%        12.000000       2.000000     122.000000     276.000000   \n",
              "max      2918.000000    1429.000000     640.000000     640.000000   \n",
              "\n",
              "                  D3             D4             D5            D6  \\\n",
              "count  261839.000000  337134.000000  224193.000000  58756.000000   \n",
              "mean       28.292470     139.916333      42.325206     69.584553   \n",
              "std        62.242703     191.026108      89.022043    143.456867   \n",
              "min         0.000000    -122.000000       0.000000    -83.000000   \n",
              "25%         1.000000       0.000000       1.000000      0.000000   \n",
              "50%         8.000000      26.000000      10.000000      0.000000   \n",
              "75%        27.000000     253.000000      32.000000     39.000000   \n",
              "max       819.000000     864.000000     819.000000    873.000000   \n",
              "\n",
              "                 D7            D8            D9            D10            D11  \\\n",
              "count  31179.000000  60129.000000  60129.000000  411587.000000  248762.000000   \n",
              "mean      41.567369    146.037489      0.560664     124.141052     146.878374   \n",
              "std       99.928586    231.821386      0.316786     182.744118     186.155725   \n",
              "min        0.000000      0.000000      0.000000       0.000000     -33.000000   \n",
              "25%        0.000000      0.958333      0.208333       0.000000       0.000000   \n",
              "50%        0.000000     37.916664      0.666666      15.000000      43.000000   \n",
              "75%       17.000000    187.291672      0.833333     198.000000     275.000000   \n",
              "max      843.000000   1707.791626      0.958333     876.000000     670.000000   \n",
              "\n",
              "                D12           D13           D14            D15             V1  \\\n",
              "count  51953.000000  49740.000000  49944.000000  401062.000000  248762.000000   \n",
              "mean      53.991974     17.651488     57.590261     163.775763       0.999944   \n",
              "std      124.102784     67.093694    135.987939     202.729060       0.007502   \n",
              "min      -83.000000      0.000000   -193.000000     -83.000000       0.000000   \n",
              "25%        0.000000      0.000000      0.000000       0.000000       1.000000   \n",
              "50%        0.000000      0.000000      0.000000      52.000000       1.000000   \n",
              "75%       12.000000      0.000000      2.000000     314.000000       1.000000   \n",
              "max      648.000000    847.000000    878.000000     879.000000       1.000000   \n",
              "\n",
              "                  V2             V3             V4             V5  \\\n",
              "count  248762.000000  248762.000000  248762.000000  248762.000000   \n",
              "mean        1.045276       1.078320       0.846214       0.876866   \n",
              "std         0.240037       0.321103       0.439820       0.475907   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       1.000000       1.000000   \n",
              "50%         1.000000       1.000000       1.000000       1.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         8.000000       9.000000       6.000000       6.000000   \n",
              "\n",
              "                  V6             V7             V8             V9  \\\n",
              "count  248762.000000  248762.000000  248762.000000  248762.000000   \n",
              "mean        1.045980       1.073070       1.027830       1.041666   \n",
              "std         0.239543       0.304999       0.186218       0.226492   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       1.000000       1.000000   \n",
              "50%         1.000000       1.000000       1.000000       1.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         9.000000       9.000000       8.000000       8.000000   \n",
              "\n",
              "                 V10            V11            V12            V13  \\\n",
              "count  248762.000000  248762.000000  411548.000000  411548.000000   \n",
              "mean        0.463065       0.478023       0.559568       0.598674   \n",
              "std         0.521544       0.552247       0.510389       0.531891   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       1.000000       1.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         4.000000       5.000000       3.000000       6.000000   \n",
              "\n",
              "                 V14            V15            V16            V17  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.999478       0.122792       0.123852       0.134553   \n",
              "std         0.022851       0.332787       0.342085       0.364560   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       0.000000   \n",
              "50%         1.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       7.000000      15.000000      15.000000   \n",
              "\n",
              "                 V18            V19            V20            V21  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.135870       0.815878       0.847269       0.130274   \n",
              "std         0.371654       0.425479       0.458769       0.339752   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       1.000000       0.000000   \n",
              "50%         0.000000       1.000000       1.000000       0.000000   \n",
              "75%         0.000000       1.000000       1.000000       0.000000   \n",
              "max        15.000000       7.000000      15.000000       5.000000   \n",
              "\n",
              "                 V22            V23            V24            V25  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.132857       1.034742       1.057979       0.977619   \n",
              "std         0.359792       0.248966       0.306040       0.185509   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       1.000000       1.000000   \n",
              "50%         0.000000       1.000000       1.000000       1.000000   \n",
              "75%         0.000000       1.000000       1.000000       1.000000   \n",
              "max         8.000000      13.000000      13.000000       7.000000   \n",
              "\n",
              "                 V26            V27            V28            V29  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.987817       0.000787       0.000843       0.386895   \n",
              "std         0.207378       0.028901       0.031436       0.510507   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       0.000000   \n",
              "50%         1.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       1.000000   \n",
              "max        13.000000       4.000000       4.000000       5.000000   \n",
              "\n",
              "                 V30            V31            V32            V33  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.405326       0.141369       0.142977       0.131105   \n",
              "std         0.553574       0.356318       0.367834       0.341203   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       0.000000   \n",
              "max         9.000000       7.000000      15.000000       7.000000   \n",
              "\n",
              "                 V34            V35            V36            V37  \\\n",
              "count  411548.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        0.139476       0.542442       0.579028       1.108097   \n",
              "std         0.356876       0.516015       0.539235       0.693882   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       1.000000   \n",
              "50%         0.000000       1.000000       1.000000       1.000000   \n",
              "75%         0.000000       1.000000       1.000000       1.000000   \n",
              "max        13.000000       3.000000       5.000000      54.000000   \n",
              "\n",
              "                 V38            V39            V40            V41  \\\n",
              "count  337096.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        1.162535       0.166881       0.177908       0.999235   \n",
              "std         0.862675       0.453426       0.506937       0.027655   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       1.000000   \n",
              "50%         1.000000       0.000000       0.000000       1.000000   \n",
              "75%         1.000000       0.000000       0.000000       1.000000   \n",
              "max        54.000000      15.000000      24.000000       1.000000   \n",
              "\n",
              "                 V42            V43            V44            V45  \\\n",
              "count  337096.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        0.156958       0.169797       1.084225       1.121117   \n",
              "std         0.383964       0.434360       0.647636       0.738306   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       1.000000       1.000000   \n",
              "50%         0.000000       0.000000       1.000000       1.000000   \n",
              "75%         0.000000       0.000000       1.000000       1.000000   \n",
              "max         8.000000       8.000000      48.000000      48.000000   \n",
              "\n",
              "                 V46            V47            V48            V49  \\\n",
              "count  337096.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        1.022237       1.038485       0.382099       0.396753   \n",
              "std         0.166645       0.231641       0.507784       0.542471   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       0.000000       0.000000   \n",
              "50%         1.000000       1.000000       0.000000       0.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         6.000000      12.000000       5.000000       5.000000   \n",
              "\n",
              "                 V50            V51            V52            V53  \\\n",
              "count  337096.000000  337096.000000  337096.000000  410643.000000   \n",
              "mean        0.165490       0.171094       0.183206       0.576839   \n",
              "std         0.374739       0.404220       0.439467       0.511402   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       1.000000   \n",
              "75%         0.000000       0.000000       0.000000       1.000000   \n",
              "max         5.000000       6.000000      12.000000       5.000000   \n",
              "\n",
              "                 V54            V55            V56            V57  \\\n",
              "count  410643.000000  410643.000000  410643.000000  410643.000000   \n",
              "mean        0.619433       1.067879       1.121604       0.128761   \n",
              "std         0.534515       0.394029       0.674774       0.349482   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       1.000000       0.000000   \n",
              "50%         1.000000       1.000000       1.000000       0.000000   \n",
              "75%         1.000000       1.000000       1.000000       0.000000   \n",
              "max         6.000000      17.000000      51.000000       6.000000   \n",
              "\n",
              "                 V58            V59  ...           V263           V264  \\\n",
              "count  410643.000000  410643.000000  ...  104634.000000  104634.000000   \n",
              "mean        0.133050       0.135025  ...     115.331141     197.024192   \n",
              "std         0.374611       0.380377  ...    1304.395428    2251.429647   \n",
              "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "25%         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "75%         0.000000       0.000000  ...       0.000000      33.835201   \n",
              "max        10.000000      16.000000  ...  153600.000000  153600.000000   \n",
              "\n",
              "                V265           V266           V267           V268  \\\n",
              "count  104634.000000  104634.000000  104634.000000  104634.000000   \n",
              "mean      150.524102       9.419733      35.853965      18.750623   \n",
              "std      1596.621628     225.991041     638.130103     318.872244   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%        21.200001       0.000000       0.000000       0.000000   \n",
              "max    153600.000000   55125.000000   55125.000000   55125.000000   \n",
              "\n",
              "                V269           V270           V271           V272  \\\n",
              "count  104634.000000  113426.000000  113426.000000  113426.000000   \n",
              "mean        6.215661       7.837482       9.618513       8.619011   \n",
              "std       225.304837      66.283284      75.350497      70.841693   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max     55125.000000    4000.000000    4000.000000    4000.000000   \n",
              "\n",
              "                V273           V274           V275           V276  \\\n",
              "count  104634.000000  104634.000000  104634.000000  104634.000000   \n",
              "mean       71.711838     104.055281      86.369361      31.286498   \n",
              "std       912.198953    1233.851264    1048.212356     634.164242   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max     51200.000000   66000.000000   51200.000000  104060.000000   \n",
              "\n",
              "                V277           V278           V279           V280  \\\n",
              "count  104634.000000  104634.000000  472424.000000  472424.000000   \n",
              "mean       51.056396      41.795056       1.118349       1.962747   \n",
              "std       747.043020     680.276486      20.934257      27.790722   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       1.000000   \n",
              "max    104060.000000  104060.000000     879.000000     975.000000   \n",
              "\n",
              "                V281           V282           V283           V284  \\\n",
              "count  471398.000000  471398.000000  471398.000000  472424.000000   \n",
              "mean        0.087794       0.817163       0.991044       0.088577   \n",
              "std         0.513986       0.923735       1.568529       0.338419   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       1.000000       1.000000       0.000000   \n",
              "75%         0.000000       1.000000       1.000000       0.000000   \n",
              "max        22.000000      32.000000      68.000000      12.000000   \n",
              "\n",
              "                V285           V286           V287           V288  \\\n",
              "count  472424.000000  472424.000000  472424.000000  471398.000000   \n",
              "mean        1.163580       0.031705       0.357973       0.184074   \n",
              "std         3.257427       0.191634       1.076463       0.430966   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       0.000000   \n",
              "max        95.000000       8.000000      31.000000      10.000000   \n",
              "\n",
              "                V289           V290           V291           V292  \\\n",
              "count  471398.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean        0.235285       1.104112       1.670154       1.243121   \n",
              "std         0.598261       0.790309      16.579363       3.868017   \n",
              "min         0.000000       1.000000       1.000000       1.000000   \n",
              "25%         0.000000       1.000000       1.000000       1.000000   \n",
              "50%         0.000000       1.000000       1.000000       1.000000   \n",
              "75%         0.000000       1.000000       1.000000       1.000000   \n",
              "max        12.000000      67.000000    1055.000000     323.000000   \n",
              "\n",
              "                V293           V294           V295           V296  \\\n",
              "count  472424.000000  472424.000000  472424.000000  471398.000000   \n",
              "mean        0.937903       2.318648       1.430361       0.327358   \n",
              "std        20.503040      39.608404      25.906506       3.255640   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max       868.000000    1286.000000     928.000000      93.000000   \n",
              "\n",
              "                V297           V298           V299           V300  \\\n",
              "count  472424.000000  472424.000000  472424.000000  471398.000000   \n",
              "mean        0.088897       0.297574       0.170906       0.045117   \n",
              "std         0.626812       3.168491       1.719834       0.289040   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max        12.000000      93.000000      49.000000      11.000000   \n",
              "\n",
              "                V301           V302           V303           V304  \\\n",
              "count  471398.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean        0.051557       0.252483       0.283709       0.264781   \n",
              "std         0.317049       0.482676       0.624290       0.528128   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max        13.000000      16.000000      20.000000      16.000000   \n",
              "\n",
              "                V305           V306           V307           V308  \\\n",
              "count  472424.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean        1.000004     139.185746     408.585703     229.801314   \n",
              "std         0.002058    2340.366681    4394.257176    3015.639763   \n",
              "min         1.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       0.000000   \n",
              "50%         1.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000     151.000000      36.374399   \n",
              "max         2.000000  108800.000000  145765.000000  108800.000000   \n",
              "\n",
              "                V309           V310           V311           V312  \\\n",
              "count  472424.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean       11.043251     118.096039       4.299015      39.261609   \n",
              "std       123.164461     355.508258     111.391074     177.550832   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000     107.949997       0.000000       0.000000   \n",
              "max     55125.000000   55125.000000   55125.000000   55125.000000   \n",
              "\n",
              "                V313           V314           V315           V316  \\\n",
              "count  471398.000000  471398.000000  471398.000000  472424.000000   \n",
              "mean       21.391813      43.172440      26.792160     109.272638   \n",
              "std        96.323808     173.127457     116.922643    2260.182139   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max      4817.470215    7519.870117    4817.470215   93630.000000   \n",
              "\n",
              "                V317           V318           V319           V320  \\\n",
              "count  472424.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean      247.806641     161.608498      18.242533      41.854071   \n",
              "std      3983.003265    2786.397337     333.129270     474.271828   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max    134021.000000   98476.000000  104060.000000  104060.000000   \n",
              "\n",
              "                V321          V322          V323          V324          V325  \\\n",
              "count  472424.000000  65995.000000  65995.000000  65995.000000  65995.000000   \n",
              "mean       28.154157      6.172346     13.021971      9.118206      0.058626   \n",
              "std       383.439267     55.743839    106.467772     73.374424      0.303183   \n",
              "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%         0.000000      0.000000      1.000000      0.000000      0.000000   \n",
              "max    104060.000000    879.000000   1411.000000    976.000000     12.000000   \n",
              "\n",
              "               V326          V327         V328          V329          V330  \\\n",
              "count  65995.000000  65995.000000  65995.00000  65995.000000  65995.000000   \n",
              "mean       0.843518      0.294553      0.33498      1.302705      0.770649   \n",
              "std        3.929171      1.358688      1.57068      8.743791      4.711790   \n",
              "min        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "max       44.000000     18.000000     15.00000     99.000000     55.000000   \n",
              "\n",
              "                V331           V332           V333          V334  \\\n",
              "count   65995.000000   65995.000000   65995.000000  65995.000000   \n",
              "mean      717.371506    1369.215320    1008.861322     10.173960   \n",
              "std      6197.946391   11147.950514    7937.940219    265.961322   \n",
              "min         0.000000       0.000000       0.000000      0.000000   \n",
              "25%         0.000000       0.000000       0.000000      0.000000   \n",
              "50%         0.000000       0.000000       0.000000      0.000000   \n",
              "75%         0.000000      25.000000       0.000000      0.000000   \n",
              "max    160000.000000  160000.000000  160000.000000  55125.000000   \n",
              "\n",
              "               V335          V336           V337           V338  \\\n",
              "count  65995.000000  65995.000000   65995.000000   65995.000000   \n",
              "mean      59.177881     28.717916      55.487174     150.920290   \n",
              "std      404.746249    294.103054     700.321813    1114.146312   \n",
              "min        0.000000      0.000000       0.000000       0.000000   \n",
              "25%        0.000000      0.000000       0.000000       0.000000   \n",
              "50%        0.000000      0.000000       0.000000       0.000000   \n",
              "75%        0.000000      0.000000       0.000000       0.000000   \n",
              "max    55125.000000  55125.000000  104060.000000  104060.000000   \n",
              "\n",
              "                V339          id_01          id_02         id_03  \\\n",
              "count   65995.000000  115658.000000  112989.000000  53192.000000   \n",
              "mean      100.760998     -10.178682  174752.397685      0.061156   \n",
              "std       841.480465      14.352676  159604.598061      0.597383   \n",
              "min         0.000000    -100.000000      30.000000    -13.000000   \n",
              "25%         0.000000     -10.000000   67963.000000      0.000000   \n",
              "50%         0.000000      -5.000000  125988.000000      0.000000   \n",
              "75%         0.000000      -5.000000  228757.000000      0.000000   \n",
              "max    104060.000000       0.000000  999595.000000      9.000000   \n",
              "\n",
              "              id_04          id_05          id_06        id_07        id_08  \\\n",
              "count  53192.000000  109791.000000  109791.000000  4114.000000  4114.000000   \n",
              "mean      -0.059821       1.612855      -6.687789    13.372387   -38.516529   \n",
              "std        0.709789       5.254521      16.472918    11.410702    26.080732   \n",
              "min      -28.000000     -72.000000    -100.000000   -46.000000  -100.000000   \n",
              "25%        0.000000       0.000000      -6.000000     5.000000   -48.000000   \n",
              "50%        0.000000       0.000000       0.000000    14.000000   -34.000000   \n",
              "75%        0.000000       1.000000       0.000000    22.000000   -23.000000   \n",
              "max        0.000000      52.000000       0.000000    61.000000     0.000000   \n",
              "\n",
              "              id_09         id_10          id_11          id_13         id_14  \\\n",
              "count  60129.000000  60129.000000  113079.000000  102085.000000  64168.000000   \n",
              "mean       0.089557     -0.306425      99.743676      48.070461   -344.615696   \n",
              "std        0.982185      2.888210       1.131255      11.769504     93.435337   \n",
              "min      -36.000000   -100.000000      90.000000      10.000000   -660.000000   \n",
              "25%        0.000000      0.000000     100.000000      49.000000   -360.000000   \n",
              "50%        0.000000      0.000000     100.000000      52.000000   -300.000000   \n",
              "75%        0.000000      0.000000     100.000000      52.000000   -300.000000   \n",
              "max       17.000000      0.000000     100.000000      64.000000    720.000000   \n",
              "\n",
              "               id_17         id_18          id_19          id_20        id_21  \\\n",
              "count  111801.000000  36124.000000  111759.000000  111713.000000  4119.000000   \n",
              "mean      189.469915     14.239647     352.662408     403.676054   371.726633   \n",
              "std        30.392523      1.573547     141.276876     152.056911   200.853603   \n",
              "min       100.000000     10.000000     100.000000     100.000000   100.000000   \n",
              "25%       166.000000     13.000000     266.000000     256.000000   252.000000   \n",
              "50%       166.000000     15.000000     341.000000     472.000000   252.000000   \n",
              "75%       225.000000     15.000000     427.000000     533.000000   500.000000   \n",
              "max       229.000000     29.000000     671.000000     661.000000   854.000000   \n",
              "\n",
              "             id_22        id_24        id_25        id_26         id_32  \n",
              "count  4126.000000  3793.000000  4102.000000  4122.000000  62203.000000  \n",
              "mean     15.950315    12.792776   328.958313   149.121058     26.516920  \n",
              "std       6.823112     2.346845    97.406803    32.192881      3.739222  \n",
              "min      10.000000    11.000000   100.000000   100.000000      0.000000  \n",
              "25%      14.000000    11.000000   321.000000   119.000000     24.000000  \n",
              "50%      14.000000    11.000000   321.000000   147.000000     24.000000  \n",
              "75%      14.000000    15.000000   366.750000   169.000000     32.000000  \n",
              "max      44.000000    26.000000   548.000000   216.000000     32.000000  \n",
              "\n",
              "[8 rows x 403 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4dc5381-cfde-482d-91ab-5060e3ca8ef6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>V51</th>\n",
              "      <th>V52</th>\n",
              "      <th>V53</th>\n",
              "      <th>V54</th>\n",
              "      <th>V55</th>\n",
              "      <th>V56</th>\n",
              "      <th>V57</th>\n",
              "      <th>V58</th>\n",
              "      <th>V59</th>\n",
              "      <th>...</th>\n",
              "      <th>V263</th>\n",
              "      <th>V264</th>\n",
              "      <th>V265</th>\n",
              "      <th>V266</th>\n",
              "      <th>V267</th>\n",
              "      <th>V268</th>\n",
              "      <th>V269</th>\n",
              "      <th>V270</th>\n",
              "      <th>V271</th>\n",
              "      <th>V272</th>\n",
              "      <th>V273</th>\n",
              "      <th>V274</th>\n",
              "      <th>V275</th>\n",
              "      <th>V276</th>\n",
              "      <th>V277</th>\n",
              "      <th>V278</th>\n",
              "      <th>V279</th>\n",
              "      <th>V280</th>\n",
              "      <th>V281</th>\n",
              "      <th>V282</th>\n",
              "      <th>V283</th>\n",
              "      <th>V284</th>\n",
              "      <th>V285</th>\n",
              "      <th>V286</th>\n",
              "      <th>V287</th>\n",
              "      <th>V288</th>\n",
              "      <th>V289</th>\n",
              "      <th>V290</th>\n",
              "      <th>V291</th>\n",
              "      <th>V292</th>\n",
              "      <th>V293</th>\n",
              "      <th>V294</th>\n",
              "      <th>V295</th>\n",
              "      <th>V296</th>\n",
              "      <th>V297</th>\n",
              "      <th>V298</th>\n",
              "      <th>V299</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.724320e+05</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>4.724320e+05</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>465285.000000</td>\n",
              "      <td>471197.000000</td>\n",
              "      <td>469035.00000</td>\n",
              "      <td>419709.000000</td>\n",
              "      <td>419709.000000</td>\n",
              "      <td>190428.000000</td>\n",
              "      <td>30156.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>247635.000000</td>\n",
              "      <td>261839.000000</td>\n",
              "      <td>337134.000000</td>\n",
              "      <td>224193.000000</td>\n",
              "      <td>58756.000000</td>\n",
              "      <td>31179.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>411587.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>51953.000000</td>\n",
              "      <td>49740.000000</td>\n",
              "      <td>49944.000000</td>\n",
              "      <td>401062.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>113426.000000</td>\n",
              "      <td>113426.000000</td>\n",
              "      <td>113426.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.00000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>115658.000000</td>\n",
              "      <td>112989.000000</td>\n",
              "      <td>53192.000000</td>\n",
              "      <td>53192.000000</td>\n",
              "      <td>109791.000000</td>\n",
              "      <td>109791.000000</td>\n",
              "      <td>4114.000000</td>\n",
              "      <td>4114.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>113079.000000</td>\n",
              "      <td>102085.000000</td>\n",
              "      <td>64168.000000</td>\n",
              "      <td>111801.000000</td>\n",
              "      <td>36124.000000</td>\n",
              "      <td>111759.000000</td>\n",
              "      <td>111713.000000</td>\n",
              "      <td>4119.000000</td>\n",
              "      <td>4126.000000</td>\n",
              "      <td>3793.000000</td>\n",
              "      <td>4102.000000</td>\n",
              "      <td>4122.000000</td>\n",
              "      <td>62203.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.282316e+06</td>\n",
              "      <td>0.034989</td>\n",
              "      <td>7.373394e+06</td>\n",
              "      <td>135.071756</td>\n",
              "      <td>9903.027720</td>\n",
              "      <td>362.527137</td>\n",
              "      <td>153.203514</td>\n",
              "      <td>199.30153</td>\n",
              "      <td>290.762967</td>\n",
              "      <td>86.799525</td>\n",
              "      <td>118.583764</td>\n",
              "      <td>231.967933</td>\n",
              "      <td>14.032987</td>\n",
              "      <td>15.208627</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>4.070306</td>\n",
              "      <td>5.552901</td>\n",
              "      <td>9.037030</td>\n",
              "      <td>2.822131</td>\n",
              "      <td>5.110992</td>\n",
              "      <td>4.467680</td>\n",
              "      <td>5.204834</td>\n",
              "      <td>10.198232</td>\n",
              "      <td>4.040867</td>\n",
              "      <td>32.418708</td>\n",
              "      <td>8.266002</td>\n",
              "      <td>94.290778</td>\n",
              "      <td>169.547641</td>\n",
              "      <td>28.292470</td>\n",
              "      <td>139.916333</td>\n",
              "      <td>42.325206</td>\n",
              "      <td>69.584553</td>\n",
              "      <td>41.567369</td>\n",
              "      <td>146.037489</td>\n",
              "      <td>0.560664</td>\n",
              "      <td>124.141052</td>\n",
              "      <td>146.878374</td>\n",
              "      <td>53.991974</td>\n",
              "      <td>17.651488</td>\n",
              "      <td>57.590261</td>\n",
              "      <td>163.775763</td>\n",
              "      <td>0.999944</td>\n",
              "      <td>1.045276</td>\n",
              "      <td>1.078320</td>\n",
              "      <td>0.846214</td>\n",
              "      <td>0.876866</td>\n",
              "      <td>1.045980</td>\n",
              "      <td>1.073070</td>\n",
              "      <td>1.027830</td>\n",
              "      <td>1.041666</td>\n",
              "      <td>0.463065</td>\n",
              "      <td>0.478023</td>\n",
              "      <td>0.559568</td>\n",
              "      <td>0.598674</td>\n",
              "      <td>0.999478</td>\n",
              "      <td>0.122792</td>\n",
              "      <td>0.123852</td>\n",
              "      <td>0.134553</td>\n",
              "      <td>0.135870</td>\n",
              "      <td>0.815878</td>\n",
              "      <td>0.847269</td>\n",
              "      <td>0.130274</td>\n",
              "      <td>0.132857</td>\n",
              "      <td>1.034742</td>\n",
              "      <td>1.057979</td>\n",
              "      <td>0.977619</td>\n",
              "      <td>0.987817</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>0.386895</td>\n",
              "      <td>0.405326</td>\n",
              "      <td>0.141369</td>\n",
              "      <td>0.142977</td>\n",
              "      <td>0.131105</td>\n",
              "      <td>0.139476</td>\n",
              "      <td>0.542442</td>\n",
              "      <td>0.579028</td>\n",
              "      <td>1.108097</td>\n",
              "      <td>1.162535</td>\n",
              "      <td>0.166881</td>\n",
              "      <td>0.177908</td>\n",
              "      <td>0.999235</td>\n",
              "      <td>0.156958</td>\n",
              "      <td>0.169797</td>\n",
              "      <td>1.084225</td>\n",
              "      <td>1.121117</td>\n",
              "      <td>1.022237</td>\n",
              "      <td>1.038485</td>\n",
              "      <td>0.382099</td>\n",
              "      <td>0.396753</td>\n",
              "      <td>0.165490</td>\n",
              "      <td>0.171094</td>\n",
              "      <td>0.183206</td>\n",
              "      <td>0.576839</td>\n",
              "      <td>0.619433</td>\n",
              "      <td>1.067879</td>\n",
              "      <td>1.121604</td>\n",
              "      <td>0.128761</td>\n",
              "      <td>0.133050</td>\n",
              "      <td>0.135025</td>\n",
              "      <td>...</td>\n",
              "      <td>115.331141</td>\n",
              "      <td>197.024192</td>\n",
              "      <td>150.524102</td>\n",
              "      <td>9.419733</td>\n",
              "      <td>35.853965</td>\n",
              "      <td>18.750623</td>\n",
              "      <td>6.215661</td>\n",
              "      <td>7.837482</td>\n",
              "      <td>9.618513</td>\n",
              "      <td>8.619011</td>\n",
              "      <td>71.711838</td>\n",
              "      <td>104.055281</td>\n",
              "      <td>86.369361</td>\n",
              "      <td>31.286498</td>\n",
              "      <td>51.056396</td>\n",
              "      <td>41.795056</td>\n",
              "      <td>1.118349</td>\n",
              "      <td>1.962747</td>\n",
              "      <td>0.087794</td>\n",
              "      <td>0.817163</td>\n",
              "      <td>0.991044</td>\n",
              "      <td>0.088577</td>\n",
              "      <td>1.163580</td>\n",
              "      <td>0.031705</td>\n",
              "      <td>0.357973</td>\n",
              "      <td>0.184074</td>\n",
              "      <td>0.235285</td>\n",
              "      <td>1.104112</td>\n",
              "      <td>1.670154</td>\n",
              "      <td>1.243121</td>\n",
              "      <td>0.937903</td>\n",
              "      <td>2.318648</td>\n",
              "      <td>1.430361</td>\n",
              "      <td>0.327358</td>\n",
              "      <td>0.088897</td>\n",
              "      <td>0.297574</td>\n",
              "      <td>0.170906</td>\n",
              "      <td>0.045117</td>\n",
              "      <td>0.051557</td>\n",
              "      <td>0.252483</td>\n",
              "      <td>0.283709</td>\n",
              "      <td>0.264781</td>\n",
              "      <td>1.000004</td>\n",
              "      <td>139.185746</td>\n",
              "      <td>408.585703</td>\n",
              "      <td>229.801314</td>\n",
              "      <td>11.043251</td>\n",
              "      <td>118.096039</td>\n",
              "      <td>4.299015</td>\n",
              "      <td>39.261609</td>\n",
              "      <td>21.391813</td>\n",
              "      <td>43.172440</td>\n",
              "      <td>26.792160</td>\n",
              "      <td>109.272638</td>\n",
              "      <td>247.806641</td>\n",
              "      <td>161.608498</td>\n",
              "      <td>18.242533</td>\n",
              "      <td>41.854071</td>\n",
              "      <td>28.154157</td>\n",
              "      <td>6.172346</td>\n",
              "      <td>13.021971</td>\n",
              "      <td>9.118206</td>\n",
              "      <td>0.058626</td>\n",
              "      <td>0.843518</td>\n",
              "      <td>0.294553</td>\n",
              "      <td>0.33498</td>\n",
              "      <td>1.302705</td>\n",
              "      <td>0.770649</td>\n",
              "      <td>717.371506</td>\n",
              "      <td>1369.215320</td>\n",
              "      <td>1008.861322</td>\n",
              "      <td>10.173960</td>\n",
              "      <td>59.177881</td>\n",
              "      <td>28.717916</td>\n",
              "      <td>55.487174</td>\n",
              "      <td>150.920290</td>\n",
              "      <td>100.760998</td>\n",
              "      <td>-10.178682</td>\n",
              "      <td>174752.397685</td>\n",
              "      <td>0.061156</td>\n",
              "      <td>-0.059821</td>\n",
              "      <td>1.612855</td>\n",
              "      <td>-6.687789</td>\n",
              "      <td>13.372387</td>\n",
              "      <td>-38.516529</td>\n",
              "      <td>0.089557</td>\n",
              "      <td>-0.306425</td>\n",
              "      <td>99.743676</td>\n",
              "      <td>48.070461</td>\n",
              "      <td>-344.615696</td>\n",
              "      <td>189.469915</td>\n",
              "      <td>14.239647</td>\n",
              "      <td>352.662408</td>\n",
              "      <td>403.676054</td>\n",
              "      <td>371.726633</td>\n",
              "      <td>15.950315</td>\n",
              "      <td>12.792776</td>\n",
              "      <td>328.958313</td>\n",
              "      <td>149.121058</td>\n",
              "      <td>26.516920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.704469e+05</td>\n",
              "      <td>0.183753</td>\n",
              "      <td>4.616510e+06</td>\n",
              "      <td>241.371497</td>\n",
              "      <td>4902.685441</td>\n",
              "      <td>157.783396</td>\n",
              "      <td>11.353198</td>\n",
              "      <td>41.21739</td>\n",
              "      <td>101.785679</td>\n",
              "      <td>2.709423</td>\n",
              "      <td>371.935971</td>\n",
              "      <td>530.961675</td>\n",
              "      <td>132.403910</td>\n",
              "      <td>153.286836</td>\n",
              "      <td>0.141592</td>\n",
              "      <td>68.312944</td>\n",
              "      <td>25.731393</td>\n",
              "      <td>70.983085</td>\n",
              "      <td>61.099606</td>\n",
              "      <td>94.517683</td>\n",
              "      <td>16.637458</td>\n",
              "      <td>94.760417</td>\n",
              "      <td>93.546109</td>\n",
              "      <td>85.789475</td>\n",
              "      <td>128.712688</td>\n",
              "      <td>49.233935</td>\n",
              "      <td>157.580267</td>\n",
              "      <td>177.240248</td>\n",
              "      <td>62.242703</td>\n",
              "      <td>191.026108</td>\n",
              "      <td>89.022043</td>\n",
              "      <td>143.456867</td>\n",
              "      <td>99.928586</td>\n",
              "      <td>231.821386</td>\n",
              "      <td>0.316786</td>\n",
              "      <td>182.744118</td>\n",
              "      <td>186.155725</td>\n",
              "      <td>124.102784</td>\n",
              "      <td>67.093694</td>\n",
              "      <td>135.987939</td>\n",
              "      <td>202.729060</td>\n",
              "      <td>0.007502</td>\n",
              "      <td>0.240037</td>\n",
              "      <td>0.321103</td>\n",
              "      <td>0.439820</td>\n",
              "      <td>0.475907</td>\n",
              "      <td>0.239543</td>\n",
              "      <td>0.304999</td>\n",
              "      <td>0.186218</td>\n",
              "      <td>0.226492</td>\n",
              "      <td>0.521544</td>\n",
              "      <td>0.552247</td>\n",
              "      <td>0.510389</td>\n",
              "      <td>0.531891</td>\n",
              "      <td>0.022851</td>\n",
              "      <td>0.332787</td>\n",
              "      <td>0.342085</td>\n",
              "      <td>0.364560</td>\n",
              "      <td>0.371654</td>\n",
              "      <td>0.425479</td>\n",
              "      <td>0.458769</td>\n",
              "      <td>0.339752</td>\n",
              "      <td>0.359792</td>\n",
              "      <td>0.248966</td>\n",
              "      <td>0.306040</td>\n",
              "      <td>0.185509</td>\n",
              "      <td>0.207378</td>\n",
              "      <td>0.028901</td>\n",
              "      <td>0.031436</td>\n",
              "      <td>0.510507</td>\n",
              "      <td>0.553574</td>\n",
              "      <td>0.356318</td>\n",
              "      <td>0.367834</td>\n",
              "      <td>0.341203</td>\n",
              "      <td>0.356876</td>\n",
              "      <td>0.516015</td>\n",
              "      <td>0.539235</td>\n",
              "      <td>0.693882</td>\n",
              "      <td>0.862675</td>\n",
              "      <td>0.453426</td>\n",
              "      <td>0.506937</td>\n",
              "      <td>0.027655</td>\n",
              "      <td>0.383964</td>\n",
              "      <td>0.434360</td>\n",
              "      <td>0.647636</td>\n",
              "      <td>0.738306</td>\n",
              "      <td>0.166645</td>\n",
              "      <td>0.231641</td>\n",
              "      <td>0.507784</td>\n",
              "      <td>0.542471</td>\n",
              "      <td>0.374739</td>\n",
              "      <td>0.404220</td>\n",
              "      <td>0.439467</td>\n",
              "      <td>0.511402</td>\n",
              "      <td>0.534515</td>\n",
              "      <td>0.394029</td>\n",
              "      <td>0.674774</td>\n",
              "      <td>0.349482</td>\n",
              "      <td>0.374611</td>\n",
              "      <td>0.380377</td>\n",
              "      <td>...</td>\n",
              "      <td>1304.395428</td>\n",
              "      <td>2251.429647</td>\n",
              "      <td>1596.621628</td>\n",
              "      <td>225.991041</td>\n",
              "      <td>638.130103</td>\n",
              "      <td>318.872244</td>\n",
              "      <td>225.304837</td>\n",
              "      <td>66.283284</td>\n",
              "      <td>75.350497</td>\n",
              "      <td>70.841693</td>\n",
              "      <td>912.198953</td>\n",
              "      <td>1233.851264</td>\n",
              "      <td>1048.212356</td>\n",
              "      <td>634.164242</td>\n",
              "      <td>747.043020</td>\n",
              "      <td>680.276486</td>\n",
              "      <td>20.934257</td>\n",
              "      <td>27.790722</td>\n",
              "      <td>0.513986</td>\n",
              "      <td>0.923735</td>\n",
              "      <td>1.568529</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>3.257427</td>\n",
              "      <td>0.191634</td>\n",
              "      <td>1.076463</td>\n",
              "      <td>0.430966</td>\n",
              "      <td>0.598261</td>\n",
              "      <td>0.790309</td>\n",
              "      <td>16.579363</td>\n",
              "      <td>3.868017</td>\n",
              "      <td>20.503040</td>\n",
              "      <td>39.608404</td>\n",
              "      <td>25.906506</td>\n",
              "      <td>3.255640</td>\n",
              "      <td>0.626812</td>\n",
              "      <td>3.168491</td>\n",
              "      <td>1.719834</td>\n",
              "      <td>0.289040</td>\n",
              "      <td>0.317049</td>\n",
              "      <td>0.482676</td>\n",
              "      <td>0.624290</td>\n",
              "      <td>0.528128</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>2340.366681</td>\n",
              "      <td>4394.257176</td>\n",
              "      <td>3015.639763</td>\n",
              "      <td>123.164461</td>\n",
              "      <td>355.508258</td>\n",
              "      <td>111.391074</td>\n",
              "      <td>177.550832</td>\n",
              "      <td>96.323808</td>\n",
              "      <td>173.127457</td>\n",
              "      <td>116.922643</td>\n",
              "      <td>2260.182139</td>\n",
              "      <td>3983.003265</td>\n",
              "      <td>2786.397337</td>\n",
              "      <td>333.129270</td>\n",
              "      <td>474.271828</td>\n",
              "      <td>383.439267</td>\n",
              "      <td>55.743839</td>\n",
              "      <td>106.467772</td>\n",
              "      <td>73.374424</td>\n",
              "      <td>0.303183</td>\n",
              "      <td>3.929171</td>\n",
              "      <td>1.358688</td>\n",
              "      <td>1.57068</td>\n",
              "      <td>8.743791</td>\n",
              "      <td>4.711790</td>\n",
              "      <td>6197.946391</td>\n",
              "      <td>11147.950514</td>\n",
              "      <td>7937.940219</td>\n",
              "      <td>265.961322</td>\n",
              "      <td>404.746249</td>\n",
              "      <td>294.103054</td>\n",
              "      <td>700.321813</td>\n",
              "      <td>1114.146312</td>\n",
              "      <td>841.480465</td>\n",
              "      <td>14.352676</td>\n",
              "      <td>159604.598061</td>\n",
              "      <td>0.597383</td>\n",
              "      <td>0.709789</td>\n",
              "      <td>5.254521</td>\n",
              "      <td>16.472918</td>\n",
              "      <td>11.410702</td>\n",
              "      <td>26.080732</td>\n",
              "      <td>0.982185</td>\n",
              "      <td>2.888210</td>\n",
              "      <td>1.131255</td>\n",
              "      <td>11.769504</td>\n",
              "      <td>93.435337</td>\n",
              "      <td>30.392523</td>\n",
              "      <td>1.573547</td>\n",
              "      <td>141.276876</td>\n",
              "      <td>152.056911</td>\n",
              "      <td>200.853603</td>\n",
              "      <td>6.823112</td>\n",
              "      <td>2.346845</td>\n",
              "      <td>97.406803</td>\n",
              "      <td>32.192881</td>\n",
              "      <td>3.739222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.987000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.640000e+04</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-33.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-193.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>-13.000000</td>\n",
              "      <td>-28.000000</td>\n",
              "      <td>-72.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-46.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-36.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-660.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.134756e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.028537e+06</td>\n",
              "      <td>43.140000</td>\n",
              "      <td>6019.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>166.00000</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>67963.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>-360.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.282400e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.309639e+06</td>\n",
              "      <td>68.911000</td>\n",
              "      <td>9689.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>226.00000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.916664</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>125988.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>-34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>472.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.429918e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.124764e+07</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>14203.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>226.00000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>276.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>187.291672</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>198.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.835201</td>\n",
              "      <td>21.200001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>36.374399</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>107.949997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>228757.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>-23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>427.000000</td>\n",
              "      <td>533.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>366.750000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.577539e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.581113e+07</td>\n",
              "      <td>31937.391000</td>\n",
              "      <td>18396.000000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>237.00000</td>\n",
              "      <td>540.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>10286.000000</td>\n",
              "      <td>11623.000000</td>\n",
              "      <td>4685.000000</td>\n",
              "      <td>5691.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>349.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>2255.000000</td>\n",
              "      <td>3331.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>3257.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>1429.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>864.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>873.000000</td>\n",
              "      <td>843.000000</td>\n",
              "      <td>1707.791626</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>876.000000</td>\n",
              "      <td>670.000000</td>\n",
              "      <td>648.000000</td>\n",
              "      <td>847.000000</td>\n",
              "      <td>878.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>153600.000000</td>\n",
              "      <td>153600.000000</td>\n",
              "      <td>153600.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>51200.000000</td>\n",
              "      <td>66000.000000</td>\n",
              "      <td>51200.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>975.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1055.000000</td>\n",
              "      <td>323.000000</td>\n",
              "      <td>868.000000</td>\n",
              "      <td>1286.000000</td>\n",
              "      <td>928.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>108800.000000</td>\n",
              "      <td>145765.000000</td>\n",
              "      <td>108800.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>4817.470215</td>\n",
              "      <td>7519.870117</td>\n",
              "      <td>4817.470215</td>\n",
              "      <td>93630.000000</td>\n",
              "      <td>134021.000000</td>\n",
              "      <td>98476.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>1411.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>999595.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>229.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>671.000000</td>\n",
              "      <td>661.000000</td>\n",
              "      <td>854.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>548.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 403 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4dc5381-cfde-482d-91ab-5060e3ca8ef6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4dc5381-cfde-482d-91ab-5060e3ca8ef6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4dc5381-cfde-482d-91ab-5060e3ca8ef6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-34605f74-884e-4cbc-949f-cfba911cac05\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34605f74-884e-4cbc-949f-cfba911cac05')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-34605f74-884e-4cbc-949f-cfba911cac05 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns.to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6oTNeNeb95y",
        "outputId": "20f34f02-28d2-47b7-cd30-a2d801b4a1ef"
      },
      "id": "z6oTNeNeb95y",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TransactionID',\n",
              " 'isFraud',\n",
              " 'TransactionDT',\n",
              " 'TransactionAmt',\n",
              " 'ProductCD',\n",
              " 'card1',\n",
              " 'card2',\n",
              " 'card3',\n",
              " 'card4',\n",
              " 'card5',\n",
              " 'card6',\n",
              " 'addr1',\n",
              " 'addr2',\n",
              " 'dist1',\n",
              " 'dist2',\n",
              " 'P_emaildomain',\n",
              " 'R_emaildomain',\n",
              " 'C1',\n",
              " 'C2',\n",
              " 'C3',\n",
              " 'C4',\n",
              " 'C5',\n",
              " 'C6',\n",
              " 'C7',\n",
              " 'C8',\n",
              " 'C9',\n",
              " 'C10',\n",
              " 'C11',\n",
              " 'C12',\n",
              " 'C13',\n",
              " 'C14',\n",
              " 'D1',\n",
              " 'D2',\n",
              " 'D3',\n",
              " 'D4',\n",
              " 'D5',\n",
              " 'D6',\n",
              " 'D7',\n",
              " 'D8',\n",
              " 'D9',\n",
              " 'D10',\n",
              " 'D11',\n",
              " 'D12',\n",
              " 'D13',\n",
              " 'D14',\n",
              " 'D15',\n",
              " 'M1',\n",
              " 'M2',\n",
              " 'M3',\n",
              " 'M4',\n",
              " 'M5',\n",
              " 'M6',\n",
              " 'M7',\n",
              " 'M8',\n",
              " 'M9',\n",
              " 'V1',\n",
              " 'V2',\n",
              " 'V3',\n",
              " 'V4',\n",
              " 'V5',\n",
              " 'V6',\n",
              " 'V7',\n",
              " 'V8',\n",
              " 'V9',\n",
              " 'V10',\n",
              " 'V11',\n",
              " 'V12',\n",
              " 'V13',\n",
              " 'V14',\n",
              " 'V15',\n",
              " 'V16',\n",
              " 'V17',\n",
              " 'V18',\n",
              " 'V19',\n",
              " 'V20',\n",
              " 'V21',\n",
              " 'V22',\n",
              " 'V23',\n",
              " 'V24',\n",
              " 'V25',\n",
              " 'V26',\n",
              " 'V27',\n",
              " 'V28',\n",
              " 'V29',\n",
              " 'V30',\n",
              " 'V31',\n",
              " 'V32',\n",
              " 'V33',\n",
              " 'V34',\n",
              " 'V35',\n",
              " 'V36',\n",
              " 'V37',\n",
              " 'V38',\n",
              " 'V39',\n",
              " 'V40',\n",
              " 'V41',\n",
              " 'V42',\n",
              " 'V43',\n",
              " 'V44',\n",
              " 'V45',\n",
              " 'V46',\n",
              " 'V47',\n",
              " 'V48',\n",
              " 'V49',\n",
              " 'V50',\n",
              " 'V51',\n",
              " 'V52',\n",
              " 'V53',\n",
              " 'V54',\n",
              " 'V55',\n",
              " 'V56',\n",
              " 'V57',\n",
              " 'V58',\n",
              " 'V59',\n",
              " 'V60',\n",
              " 'V61',\n",
              " 'V62',\n",
              " 'V63',\n",
              " 'V64',\n",
              " 'V65',\n",
              " 'V66',\n",
              " 'V67',\n",
              " 'V68',\n",
              " 'V69',\n",
              " 'V70',\n",
              " 'V71',\n",
              " 'V72',\n",
              " 'V73',\n",
              " 'V74',\n",
              " 'V75',\n",
              " 'V76',\n",
              " 'V77',\n",
              " 'V78',\n",
              " 'V79',\n",
              " 'V80',\n",
              " 'V81',\n",
              " 'V82',\n",
              " 'V83',\n",
              " 'V84',\n",
              " 'V85',\n",
              " 'V86',\n",
              " 'V87',\n",
              " 'V88',\n",
              " 'V89',\n",
              " 'V90',\n",
              " 'V91',\n",
              " 'V92',\n",
              " 'V93',\n",
              " 'V94',\n",
              " 'V95',\n",
              " 'V96',\n",
              " 'V97',\n",
              " 'V98',\n",
              " 'V99',\n",
              " 'V100',\n",
              " 'V101',\n",
              " 'V102',\n",
              " 'V103',\n",
              " 'V104',\n",
              " 'V105',\n",
              " 'V106',\n",
              " 'V107',\n",
              " 'V108',\n",
              " 'V109',\n",
              " 'V110',\n",
              " 'V111',\n",
              " 'V112',\n",
              " 'V113',\n",
              " 'V114',\n",
              " 'V115',\n",
              " 'V116',\n",
              " 'V117',\n",
              " 'V118',\n",
              " 'V119',\n",
              " 'V120',\n",
              " 'V121',\n",
              " 'V122',\n",
              " 'V123',\n",
              " 'V124',\n",
              " 'V125',\n",
              " 'V126',\n",
              " 'V127',\n",
              " 'V128',\n",
              " 'V129',\n",
              " 'V130',\n",
              " 'V131',\n",
              " 'V132',\n",
              " 'V133',\n",
              " 'V134',\n",
              " 'V135',\n",
              " 'V136',\n",
              " 'V137',\n",
              " 'V138',\n",
              " 'V139',\n",
              " 'V140',\n",
              " 'V141',\n",
              " 'V142',\n",
              " 'V143',\n",
              " 'V144',\n",
              " 'V145',\n",
              " 'V146',\n",
              " 'V147',\n",
              " 'V148',\n",
              " 'V149',\n",
              " 'V150',\n",
              " 'V151',\n",
              " 'V152',\n",
              " 'V153',\n",
              " 'V154',\n",
              " 'V155',\n",
              " 'V156',\n",
              " 'V157',\n",
              " 'V158',\n",
              " 'V159',\n",
              " 'V160',\n",
              " 'V161',\n",
              " 'V162',\n",
              " 'V163',\n",
              " 'V164',\n",
              " 'V165',\n",
              " 'V166',\n",
              " 'V167',\n",
              " 'V168',\n",
              " 'V169',\n",
              " 'V170',\n",
              " 'V171',\n",
              " 'V172',\n",
              " 'V173',\n",
              " 'V174',\n",
              " 'V175',\n",
              " 'V176',\n",
              " 'V177',\n",
              " 'V178',\n",
              " 'V179',\n",
              " 'V180',\n",
              " 'V181',\n",
              " 'V182',\n",
              " 'V183',\n",
              " 'V184',\n",
              " 'V185',\n",
              " 'V186',\n",
              " 'V187',\n",
              " 'V188',\n",
              " 'V189',\n",
              " 'V190',\n",
              " 'V191',\n",
              " 'V192',\n",
              " 'V193',\n",
              " 'V194',\n",
              " 'V195',\n",
              " 'V196',\n",
              " 'V197',\n",
              " 'V198',\n",
              " 'V199',\n",
              " 'V200',\n",
              " 'V201',\n",
              " 'V202',\n",
              " 'V203',\n",
              " 'V204',\n",
              " 'V205',\n",
              " 'V206',\n",
              " 'V207',\n",
              " 'V208',\n",
              " 'V209',\n",
              " 'V210',\n",
              " 'V211',\n",
              " 'V212',\n",
              " 'V213',\n",
              " 'V214',\n",
              " 'V215',\n",
              " 'V216',\n",
              " 'V217',\n",
              " 'V218',\n",
              " 'V219',\n",
              " 'V220',\n",
              " 'V221',\n",
              " 'V222',\n",
              " 'V223',\n",
              " 'V224',\n",
              " 'V225',\n",
              " 'V226',\n",
              " 'V227',\n",
              " 'V228',\n",
              " 'V229',\n",
              " 'V230',\n",
              " 'V231',\n",
              " 'V232',\n",
              " 'V233',\n",
              " 'V234',\n",
              " 'V235',\n",
              " 'V236',\n",
              " 'V237',\n",
              " 'V238',\n",
              " 'V239',\n",
              " 'V240',\n",
              " 'V241',\n",
              " 'V242',\n",
              " 'V243',\n",
              " 'V244',\n",
              " 'V245',\n",
              " 'V246',\n",
              " 'V247',\n",
              " 'V248',\n",
              " 'V249',\n",
              " 'V250',\n",
              " 'V251',\n",
              " 'V252',\n",
              " 'V253',\n",
              " 'V254',\n",
              " 'V255',\n",
              " 'V256',\n",
              " 'V257',\n",
              " 'V258',\n",
              " 'V259',\n",
              " 'V260',\n",
              " 'V261',\n",
              " 'V262',\n",
              " 'V263',\n",
              " 'V264',\n",
              " 'V265',\n",
              " 'V266',\n",
              " 'V267',\n",
              " 'V268',\n",
              " 'V269',\n",
              " 'V270',\n",
              " 'V271',\n",
              " 'V272',\n",
              " 'V273',\n",
              " 'V274',\n",
              " 'V275',\n",
              " 'V276',\n",
              " 'V277',\n",
              " 'V278',\n",
              " 'V279',\n",
              " 'V280',\n",
              " 'V281',\n",
              " 'V282',\n",
              " 'V283',\n",
              " 'V284',\n",
              " 'V285',\n",
              " 'V286',\n",
              " 'V287',\n",
              " 'V288',\n",
              " 'V289',\n",
              " 'V290',\n",
              " 'V291',\n",
              " 'V292',\n",
              " 'V293',\n",
              " 'V294',\n",
              " 'V295',\n",
              " 'V296',\n",
              " 'V297',\n",
              " 'V298',\n",
              " 'V299',\n",
              " 'V300',\n",
              " 'V301',\n",
              " 'V302',\n",
              " 'V303',\n",
              " 'V304',\n",
              " 'V305',\n",
              " 'V306',\n",
              " 'V307',\n",
              " 'V308',\n",
              " 'V309',\n",
              " 'V310',\n",
              " 'V311',\n",
              " 'V312',\n",
              " 'V313',\n",
              " 'V314',\n",
              " 'V315',\n",
              " 'V316',\n",
              " 'V317',\n",
              " 'V318',\n",
              " 'V319',\n",
              " 'V320',\n",
              " 'V321',\n",
              " 'V322',\n",
              " 'V323',\n",
              " 'V324',\n",
              " 'V325',\n",
              " 'V326',\n",
              " 'V327',\n",
              " 'V328',\n",
              " 'V329',\n",
              " 'V330',\n",
              " 'V331',\n",
              " 'V332',\n",
              " 'V333',\n",
              " 'V334',\n",
              " 'V335',\n",
              " 'V336',\n",
              " 'V337',\n",
              " 'V338',\n",
              " 'V339',\n",
              " 'id_01',\n",
              " 'id_02',\n",
              " 'id_03',\n",
              " 'id_04',\n",
              " 'id_05',\n",
              " 'id_06',\n",
              " 'id_07',\n",
              " 'id_08',\n",
              " 'id_09',\n",
              " 'id_10',\n",
              " 'id_11',\n",
              " 'id_12',\n",
              " 'id_13',\n",
              " 'id_14',\n",
              " 'id_15',\n",
              " 'id_16',\n",
              " 'id_17',\n",
              " 'id_18',\n",
              " 'id_19',\n",
              " 'id_20',\n",
              " 'id_21',\n",
              " 'id_22',\n",
              " 'id_23',\n",
              " 'id_24',\n",
              " 'id_25',\n",
              " 'id_26',\n",
              " 'id_27',\n",
              " 'id_28',\n",
              " 'id_29',\n",
              " 'id_30',\n",
              " 'id_31',\n",
              " 'id_32',\n",
              " 'id_33',\n",
              " 'id_34',\n",
              " 'id_35',\n",
              " 'id_36',\n",
              " 'id_37',\n",
              " 'id_38',\n",
              " 'DeviceType',\n",
              " 'DeviceInfo']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data.isna().sum()/train_data.shape[0]).sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "kw_UTytum-ho",
        "outputId": "a1788fab-38b9-436d-f1cb-6b0419915fe9"
      },
      "id": "kw_UTytum-ho",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id_24             0.991971\n",
              "id_25             0.991317\n",
              "id_07             0.991292\n",
              "id_08             0.991292\n",
              "id_21             0.991281\n",
              "                    ...   \n",
              "ProductCD         0.000000\n",
              "TransactionAmt    0.000000\n",
              "TransactionDT     0.000000\n",
              "isFraud           0.000000\n",
              "TransactionID     0.000000\n",
              "Length: 434, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id_24</th>\n",
              "      <td>0.991971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_25</th>\n",
              "      <td>0.991317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_07</th>\n",
              "      <td>0.991292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_08</th>\n",
              "      <td>0.991292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_21</th>\n",
              "      <td>0.991281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ProductCD</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionAmt</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionDT</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>434 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['id_24'].isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_4NwgfQtj6k",
        "outputId": "26b50c8b-10ba-47a3-b3da-08993c55da7b"
      },
      "id": "o_4NwgfQtj6k",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(468639)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data[:50000]"
      ],
      "metadata": {
        "id": "sN2wZF2pc8hg"
      },
      "id": "sN2wZF2pc8hg",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEWFXwd-de1O",
        "outputId": "8d86c305-fbd5-41b1-c74c-1d7b903a7a88"
      },
      "id": "eEWFXwd-de1O",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 434)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import time\n",
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='medium_quality',tuning_data=val_data, time_limit=600, num_gpus=1\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWRUVCjpax8u",
        "outputId": "897ebcbb-4a60-4d3d-9b11-63eb032941fa"
      },
      "id": "FWRUVCjpax8u",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          8\n",
            "GPU Count:          1\n",
            "Memory Avail:       43.41 GB / 50.99 GB (85.1%)\n",
            "Disk Space Avail:   188.69 GB / 235.68 GB (80.1%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': False}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"/content/AutoGluonModels\"\n",
            "Train Data Rows:    50000\n",
            "Train Data Columns: 433\n",
            "Tuning Data Rows:    59054\n",
            "Tuning Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44166.66 MB\n",
            "\tTrain Data (Original)  Memory Usage: 463.42 MB (1.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.1s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.0s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.3s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t8 duplicate columns removed: ['V113', 'V119', 'V147', 'V149', 'V154', 'V156', 'V198', 'V241']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t4.2s = Fit runtime\n",
            "\t\t\t425 features in original data used to generate 425 features in processed data.\n",
            "\tUnused Original Features (Count: 8): ['V113', 'V119', 'V147', 'V149', 'V154', 'V156', 'V198', 'V241']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 8 | ['V113', 'V119', 'V147', 'V149', 'V154', ...]\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t8.4s = Fit runtime\n",
            "\t425 features in original data used to generate 425 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 331.16 MB (0.8% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 9.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Saving /content/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/X_val.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 590.77s of the 590.76s of remaining time.\n",
            "\tFitting LightGBMXT with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=0.9/43.0 GB\n",
            "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.100802\n",
            "[100]\tvalid_set's binary_logloss: 0.0941106\n",
            "[150]\tvalid_set's binary_logloss: 0.0911806\n",
            "[200]\tvalid_set's binary_logloss: 0.0899854\n",
            "[250]\tvalid_set's binary_logloss: 0.0890797\n",
            "[300]\tvalid_set's binary_logloss: 0.0884217\n",
            "[350]\tvalid_set's binary_logloss: 0.0878923\n",
            "[400]\tvalid_set's binary_logloss: 0.0875531\n",
            "[450]\tvalid_set's binary_logloss: 0.0874072\n",
            "[500]\tvalid_set's binary_logloss: 0.0874161\n",
            "[550]\tvalid_set's binary_logloss: 0.0873722\n",
            "[600]\tvalid_set's binary_logloss: 0.0874271\n",
            "[650]\tvalid_set's binary_logloss: 0.0875873\n",
            "[700]\tvalid_set's binary_logloss: 0.0878167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "\t0.9028\t = Validation score   (roc_auc)\n",
            "\t19.31s\t = Training   runtime\n",
            "\t1.44s\t = Validation runtime\n",
            "\t40905.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM ... Training model for up to 569.97s of the 569.97s of remaining time.\n",
            "\tFitting LightGBM with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=0.9/42.9 GB\n",
            "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0966024\n",
            "[100]\tvalid_set's binary_logloss: 0.0912068\n",
            "[150]\tvalid_set's binary_logloss: 0.0888308\n",
            "[200]\tvalid_set's binary_logloss: 0.0877212\n",
            "[250]\tvalid_set's binary_logloss: 0.0867231\n",
            "[300]\tvalid_set's binary_logloss: 0.0864542\n",
            "[350]\tvalid_set's binary_logloss: 0.0862715\n",
            "[400]\tvalid_set's binary_logloss: 0.0863471\n",
            "[450]\tvalid_set's binary_logloss: 0.0865789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "\t0.9069\t = Validation score   (roc_auc)\n",
            "\t8.97s\t = Training   runtime\n",
            "\t0.99s\t = Validation runtime\n",
            "\t59556.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini ... Training model for up to 559.98s of the 559.97s of remaining time.\n",
            "\tFitting RandomForestGini with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.9 GB\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "\t0.8802\t = Validation score   (roc_auc)\n",
            "\t15.79s\t = Training   runtime\n",
            "\t1.26s\t = Validation runtime\n",
            "\t46815.8\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr ... Training model for up to 542.84s of the 542.83s of remaining time.\n",
            "\tFitting RandomForestEntr with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.8 GB\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "\t0.8833\t = Validation score   (roc_auc)\n",
            "\t12.2s\t = Training   runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "\t54337.0\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost ... Training model for up to 529.47s of the 529.46s of remaining time.\n",
            "\tFitting CatBoost with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.6/42.8 GB\n",
            "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 4, 'task_type': 'GPU'}\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6106130\ttest: 0.6110667\tbest: 0.6110667 (0)\ttotal: 24.1ms\tremaining: 216ms\n",
            "9:\tlearn: 0.2458242\ttest: 0.2465552\tbest: 0.2465552 (9)\ttotal: 185ms\tremaining: 0us\n",
            "bestTest = 0.2465552251\n",
            "bestIteration = 9\n",
            "0:\tlearn: 0.6082405\ttest: 0.6080876\tbest: 0.6080876 (0)\ttotal: 39.7ms\tremaining: 2m 47s\n",
            "20:\tlearn: 0.1458957\ttest: 0.1472668\tbest: 0.1472668 (20)\ttotal: 729ms\tremaining: 2m 25s\n",
            "40:\tlearn: 0.1115550\ttest: 0.1145953\tbest: 0.1145953 (40)\ttotal: 1.42s\tremaining: 2m 24s\n",
            "60:\tlearn: 0.1033405\ttest: 0.1078201\tbest: 0.1078201 (60)\ttotal: 2.13s\tremaining: 2m 25s\n",
            "80:\tlearn: 0.0990221\ttest: 0.1044875\tbest: 0.1044875 (80)\ttotal: 2.82s\tremaining: 2m 24s\n",
            "100:\tlearn: 0.0970006\ttest: 0.1031563\tbest: 0.1031563 (100)\ttotal: 3.51s\tremaining: 2m 23s\n",
            "120:\tlearn: 0.0953476\ttest: 0.1020479\tbest: 0.1020479 (120)\ttotal: 4.18s\tremaining: 2m 21s\n",
            "140:\tlearn: 0.0936412\ttest: 0.1008461\tbest: 0.1008461 (140)\ttotal: 4.88s\tremaining: 2m 21s\n",
            "160:\tlearn: 0.0923089\ttest: 0.1000622\tbest: 0.1000622 (160)\ttotal: 5.57s\tremaining: 2m 20s\n",
            "180:\tlearn: 0.0913430\ttest: 0.0994953\tbest: 0.0994953 (180)\ttotal: 6.25s\tremaining: 2m 19s\n",
            "200:\tlearn: 0.0902623\ttest: 0.0988596\tbest: 0.0988596 (200)\ttotal: 6.96s\tremaining: 2m 19s\n",
            "220:\tlearn: 0.0891800\ttest: 0.0983091\tbest: 0.0983091 (220)\ttotal: 7.62s\tremaining: 2m 17s\n",
            "240:\tlearn: 0.0884166\ttest: 0.0979484\tbest: 0.0979484 (240)\ttotal: 8.31s\tremaining: 2m 17s\n",
            "260:\tlearn: 0.0876671\ttest: 0.0975794\tbest: 0.0975794 (260)\ttotal: 8.99s\tremaining: 2m 16s\n",
            "280:\tlearn: 0.0868882\ttest: 0.0972811\tbest: 0.0972811 (280)\ttotal: 9.65s\tremaining: 2m 15s\n",
            "300:\tlearn: 0.0861909\ttest: 0.0969416\tbest: 0.0969416 (300)\ttotal: 10.3s\tremaining: 2m 14s\n",
            "320:\tlearn: 0.0854554\ttest: 0.0966069\tbest: 0.0966069 (320)\ttotal: 11s\tremaining: 2m 13s\n",
            "340:\tlearn: 0.0846833\ttest: 0.0962509\tbest: 0.0962509 (340)\ttotal: 11.7s\tremaining: 2m 13s\n",
            "360:\tlearn: 0.0838325\ttest: 0.0958463\tbest: 0.0958463 (360)\ttotal: 12.4s\tremaining: 2m 12s\n",
            "380:\tlearn: 0.0832743\ttest: 0.0956359\tbest: 0.0956359 (380)\ttotal: 13.1s\tremaining: 2m 11s\n",
            "400:\tlearn: 0.0825602\ttest: 0.0953929\tbest: 0.0953929 (400)\ttotal: 13.8s\tremaining: 2m 11s\n",
            "420:\tlearn: 0.0819680\ttest: 0.0952079\tbest: 0.0952079 (420)\ttotal: 14.5s\tremaining: 2m 10s\n",
            "440:\tlearn: 0.0813191\ttest: 0.0949804\tbest: 0.0949804 (440)\ttotal: 15.2s\tremaining: 2m 10s\n",
            "460:\tlearn: 0.0806700\ttest: 0.0947329\tbest: 0.0947329 (460)\ttotal: 15.9s\tremaining: 2m 9s\n",
            "480:\tlearn: 0.0800504\ttest: 0.0944866\tbest: 0.0944866 (480)\ttotal: 16.6s\tremaining: 2m 8s\n",
            "500:\tlearn: 0.0794311\ttest: 0.0942736\tbest: 0.0942736 (500)\ttotal: 17.2s\tremaining: 2m 8s\n",
            "520:\tlearn: 0.0789084\ttest: 0.0940763\tbest: 0.0940763 (520)\ttotal: 17.9s\tremaining: 2m 7s\n",
            "540:\tlearn: 0.0783830\ttest: 0.0938732\tbest: 0.0938732 (540)\ttotal: 18.6s\tremaining: 2m 6s\n",
            "560:\tlearn: 0.0778949\ttest: 0.0937148\tbest: 0.0937148 (560)\ttotal: 19.3s\tremaining: 2m 6s\n",
            "580:\tlearn: 0.0774402\ttest: 0.0936077\tbest: 0.0935926 (579)\ttotal: 20s\tremaining: 2m 5s\n",
            "600:\tlearn: 0.0769437\ttest: 0.0933972\tbest: 0.0933972 (600)\ttotal: 20.7s\tremaining: 2m 4s\n",
            "620:\tlearn: 0.0764861\ttest: 0.0932503\tbest: 0.0932503 (620)\ttotal: 21.4s\tremaining: 2m 4s\n",
            "640:\tlearn: 0.0760139\ttest: 0.0930774\tbest: 0.0930765 (637)\ttotal: 22.1s\tremaining: 2m 3s\n",
            "660:\tlearn: 0.0755055\ttest: 0.0929201\tbest: 0.0929201 (660)\ttotal: 22.8s\tremaining: 2m 2s\n",
            "680:\tlearn: 0.0750519\ttest: 0.0927704\tbest: 0.0927704 (680)\ttotal: 23.6s\tremaining: 2m 2s\n",
            "700:\tlearn: 0.0746161\ttest: 0.0925721\tbest: 0.0925721 (700)\ttotal: 24.2s\tremaining: 2m 1s\n",
            "720:\tlearn: 0.0741858\ttest: 0.0924389\tbest: 0.0924389 (720)\ttotal: 24.9s\tremaining: 2m 1s\n",
            "740:\tlearn: 0.0737981\ttest: 0.0923839\tbest: 0.0923820 (739)\ttotal: 25.6s\tremaining: 2m\n",
            "760:\tlearn: 0.0733387\ttest: 0.0922781\tbest: 0.0922781 (760)\ttotal: 26.3s\tremaining: 1m 59s\n",
            "780:\tlearn: 0.0729212\ttest: 0.0921652\tbest: 0.0921652 (780)\ttotal: 27s\tremaining: 1m 59s\n",
            "800:\tlearn: 0.0725432\ttest: 0.0920901\tbest: 0.0920863 (799)\ttotal: 27.8s\tremaining: 1m 58s\n",
            "820:\tlearn: 0.0720405\ttest: 0.0919953\tbest: 0.0919953 (820)\ttotal: 28.5s\tremaining: 1m 57s\n",
            "840:\tlearn: 0.0716789\ttest: 0.0919028\tbest: 0.0919028 (840)\ttotal: 29.2s\tremaining: 1m 57s\n",
            "860:\tlearn: 0.0712315\ttest: 0.0917164\tbest: 0.0917164 (860)\ttotal: 29.8s\tremaining: 1m 56s\n",
            "880:\tlearn: 0.0708381\ttest: 0.0915882\tbest: 0.0915882 (880)\ttotal: 30.5s\tremaining: 1m 55s\n",
            "900:\tlearn: 0.0704576\ttest: 0.0915088\tbest: 0.0915088 (900)\ttotal: 31.2s\tremaining: 1m 55s\n",
            "920:\tlearn: 0.0701648\ttest: 0.0914542\tbest: 0.0914542 (920)\ttotal: 31.9s\tremaining: 1m 54s\n",
            "940:\tlearn: 0.0697173\ttest: 0.0913699\tbest: 0.0913699 (940)\ttotal: 32.6s\tremaining: 1m 53s\n",
            "960:\tlearn: 0.0692958\ttest: 0.0912768\tbest: 0.0912735 (957)\ttotal: 33.3s\tremaining: 1m 53s\n",
            "980:\tlearn: 0.0688324\ttest: 0.0911586\tbest: 0.0911586 (980)\ttotal: 34s\tremaining: 1m 52s\n",
            "1000:\tlearn: 0.0683869\ttest: 0.0910458\tbest: 0.0910458 (1000)\ttotal: 34.7s\tremaining: 1m 51s\n",
            "1020:\tlearn: 0.0680054\ttest: 0.0909249\tbest: 0.0909249 (1020)\ttotal: 35.4s\tremaining: 1m 51s\n",
            "1040:\tlearn: 0.0675896\ttest: 0.0908340\tbest: 0.0908330 (1039)\ttotal: 36.1s\tremaining: 1m 50s\n",
            "1060:\tlearn: 0.0672066\ttest: 0.0907500\tbest: 0.0907498 (1059)\ttotal: 36.8s\tremaining: 1m 49s\n",
            "1080:\tlearn: 0.0668486\ttest: 0.0906881\tbest: 0.0906871 (1079)\ttotal: 37.5s\tremaining: 1m 49s\n",
            "1100:\tlearn: 0.0665356\ttest: 0.0906071\tbest: 0.0906071 (1100)\ttotal: 38.2s\tremaining: 1m 48s\n",
            "1120:\tlearn: 0.0662360\ttest: 0.0905620\tbest: 0.0905620 (1120)\ttotal: 39s\tremaining: 1m 47s\n",
            "1140:\tlearn: 0.0658879\ttest: 0.0905170\tbest: 0.0905117 (1138)\ttotal: 39.7s\tremaining: 1m 47s\n",
            "1160:\tlearn: 0.0655095\ttest: 0.0904427\tbest: 0.0904427 (1160)\ttotal: 40.4s\tremaining: 1m 46s\n",
            "1180:\tlearn: 0.0652053\ttest: 0.0903840\tbest: 0.0903834 (1179)\ttotal: 41.1s\tremaining: 1m 45s\n",
            "1200:\tlearn: 0.0648734\ttest: 0.0902883\tbest: 0.0902883 (1200)\ttotal: 41.8s\tremaining: 1m 45s\n",
            "1220:\tlearn: 0.0645251\ttest: 0.0902223\tbest: 0.0902223 (1220)\ttotal: 42.4s\tremaining: 1m 44s\n",
            "1240:\tlearn: 0.0642630\ttest: 0.0901789\tbest: 0.0901789 (1240)\ttotal: 43.1s\tremaining: 1m 43s\n",
            "1260:\tlearn: 0.0638605\ttest: 0.0901069\tbest: 0.0901069 (1260)\ttotal: 43.8s\tremaining: 1m 42s\n",
            "1280:\tlearn: 0.0635302\ttest: 0.0900619\tbest: 0.0900616 (1279)\ttotal: 44.5s\tremaining: 1m 42s\n",
            "1300:\tlearn: 0.0631579\ttest: 0.0900250\tbest: 0.0900250 (1300)\ttotal: 45.2s\tremaining: 1m 41s\n",
            "1320:\tlearn: 0.0627041\ttest: 0.0899115\tbest: 0.0899089 (1318)\ttotal: 45.9s\tremaining: 1m 40s\n",
            "1340:\tlearn: 0.0623430\ttest: 0.0898482\tbest: 0.0898482 (1340)\ttotal: 46.6s\tremaining: 1m 40s\n",
            "1360:\tlearn: 0.0619091\ttest: 0.0897408\tbest: 0.0897408 (1360)\ttotal: 47.3s\tremaining: 1m 39s\n",
            "1380:\tlearn: 0.0616087\ttest: 0.0896797\tbest: 0.0896797 (1380)\ttotal: 48s\tremaining: 1m 38s\n",
            "1400:\tlearn: 0.0612965\ttest: 0.0896246\tbest: 0.0896246 (1400)\ttotal: 48.7s\tremaining: 1m 38s\n",
            "1420:\tlearn: 0.0610037\ttest: 0.0895692\tbest: 0.0895692 (1420)\ttotal: 49.4s\tremaining: 1m 37s\n",
            "1440:\tlearn: 0.0607502\ttest: 0.0895382\tbest: 0.0895304 (1438)\ttotal: 50.1s\tremaining: 1m 36s\n",
            "1460:\tlearn: 0.0604536\ttest: 0.0894696\tbest: 0.0894672 (1459)\ttotal: 50.8s\tremaining: 1m 36s\n",
            "1480:\tlearn: 0.0601987\ttest: 0.0894264\tbest: 0.0894264 (1480)\ttotal: 51.6s\tremaining: 1m 35s\n",
            "1500:\tlearn: 0.0598845\ttest: 0.0893779\tbest: 0.0893773 (1498)\ttotal: 52.3s\tremaining: 1m 34s\n",
            "1520:\tlearn: 0.0595753\ttest: 0.0892754\tbest: 0.0892754 (1520)\ttotal: 53s\tremaining: 1m 34s\n",
            "1540:\tlearn: 0.0592616\ttest: 0.0892591\tbest: 0.0892591 (1540)\ttotal: 53.7s\tremaining: 1m 33s\n",
            "1560:\tlearn: 0.0589467\ttest: 0.0891952\tbest: 0.0891939 (1559)\ttotal: 54.4s\tremaining: 1m 32s\n",
            "1580:\tlearn: 0.0586638\ttest: 0.0891630\tbest: 0.0891630 (1580)\ttotal: 55.1s\tremaining: 1m 32s\n",
            "1600:\tlearn: 0.0583972\ttest: 0.0891069\tbest: 0.0891050 (1597)\ttotal: 55.8s\tremaining: 1m 31s\n",
            "1620:\tlearn: 0.0581041\ttest: 0.0890828\tbest: 0.0890810 (1618)\ttotal: 56.5s\tremaining: 1m 30s\n",
            "1640:\tlearn: 0.0577527\ttest: 0.0890175\tbest: 0.0890173 (1639)\ttotal: 57.2s\tremaining: 1m 29s\n",
            "1660:\tlearn: 0.0574715\ttest: 0.0889688\tbest: 0.0889688 (1660)\ttotal: 57.9s\tremaining: 1m 29s\n",
            "1680:\tlearn: 0.0572585\ttest: 0.0889551\tbest: 0.0889551 (1680)\ttotal: 58.6s\tremaining: 1m 28s\n",
            "1700:\tlearn: 0.0569835\ttest: 0.0889268\tbest: 0.0889268 (1700)\ttotal: 59.3s\tremaining: 1m 27s\n",
            "1720:\tlearn: 0.0566480\ttest: 0.0889035\tbest: 0.0888995 (1714)\ttotal: 60s\tremaining: 1m 27s\n",
            "1740:\tlearn: 0.0564016\ttest: 0.0888408\tbest: 0.0888393 (1738)\ttotal: 1m\tremaining: 1m 26s\n",
            "1760:\tlearn: 0.0561126\ttest: 0.0888039\tbest: 0.0888039 (1760)\ttotal: 1m 1s\tremaining: 1m 25s\n",
            "1780:\tlearn: 0.0558425\ttest: 0.0887888\tbest: 0.0887855 (1779)\ttotal: 1m 2s\tremaining: 1m 25s\n",
            "1800:\tlearn: 0.0556494\ttest: 0.0887599\tbest: 0.0887559 (1798)\ttotal: 1m 2s\tremaining: 1m 24s\n",
            "1820:\tlearn: 0.0553568\ttest: 0.0887465\tbest: 0.0887406 (1813)\ttotal: 1m 3s\tremaining: 1m 23s\n",
            "1840:\tlearn: 0.0550819\ttest: 0.0886904\tbest: 0.0886857 (1838)\ttotal: 1m 4s\tremaining: 1m 23s\n",
            "1860:\tlearn: 0.0548582\ttest: 0.0886315\tbest: 0.0886307 (1858)\ttotal: 1m 4s\tremaining: 1m 22s\n",
            "1880:\tlearn: 0.0546249\ttest: 0.0885842\tbest: 0.0885815 (1879)\ttotal: 1m 5s\tremaining: 1m 21s\n",
            "1900:\tlearn: 0.0543779\ttest: 0.0885614\tbest: 0.0885568 (1893)\ttotal: 1m 6s\tremaining: 1m 20s\n",
            "1920:\tlearn: 0.0541324\ttest: 0.0885476\tbest: 0.0885476 (1920)\ttotal: 1m 7s\tremaining: 1m 20s\n",
            "1940:\tlearn: 0.0538531\ttest: 0.0885008\tbest: 0.0884989 (1938)\ttotal: 1m 7s\tremaining: 1m 19s\n",
            "1960:\tlearn: 0.0535984\ttest: 0.0884579\tbest: 0.0884517 (1955)\ttotal: 1m 8s\tremaining: 1m 18s\n",
            "1980:\tlearn: 0.0533654\ttest: 0.0884597\tbest: 0.0884512 (1973)\ttotal: 1m 9s\tremaining: 1m 18s\n",
            "2000:\tlearn: 0.0531044\ttest: 0.0884596\tbest: 0.0884509 (1992)\ttotal: 1m 9s\tremaining: 1m 17s\n",
            "2020:\tlearn: 0.0528795\ttest: 0.0884314\tbest: 0.0884237 (2007)\ttotal: 1m 10s\tremaining: 1m 16s\n",
            "2040:\tlearn: 0.0526562\ttest: 0.0884262\tbest: 0.0884221 (2039)\ttotal: 1m 11s\tremaining: 1m 16s\n",
            "2060:\tlearn: 0.0524325\ttest: 0.0884104\tbest: 0.0884104 (2060)\ttotal: 1m 11s\tremaining: 1m 15s\n",
            "2080:\tlearn: 0.0521912\ttest: 0.0883996\tbest: 0.0883901 (2075)\ttotal: 1m 12s\tremaining: 1m 14s\n",
            "2100:\tlearn: 0.0519167\ttest: 0.0883666\tbest: 0.0883548 (2093)\ttotal: 1m 13s\tremaining: 1m 14s\n",
            "2120:\tlearn: 0.0516621\ttest: 0.0883536\tbest: 0.0883456 (2113)\ttotal: 1m 14s\tremaining: 1m 13s\n",
            "2140:\tlearn: 0.0514442\ttest: 0.0883446\tbest: 0.0883364 (2138)\ttotal: 1m 14s\tremaining: 1m 12s\n",
            "2160:\tlearn: 0.0512090\ttest: 0.0882938\tbest: 0.0882931 (2159)\ttotal: 1m 15s\tremaining: 1m 11s\n",
            "2180:\tlearn: 0.0509393\ttest: 0.0882730\tbest: 0.0882730 (2180)\ttotal: 1m 16s\tremaining: 1m 11s\n",
            "2200:\tlearn: 0.0507044\ttest: 0.0882340\tbest: 0.0882340 (2200)\ttotal: 1m 16s\tremaining: 1m 10s\n",
            "2220:\tlearn: 0.0504683\ttest: 0.0882257\tbest: 0.0882200 (2217)\ttotal: 1m 17s\tremaining: 1m 9s\n",
            "2240:\tlearn: 0.0502389\ttest: 0.0882162\tbest: 0.0882142 (2235)\ttotal: 1m 18s\tremaining: 1m 9s\n",
            "2260:\tlearn: 0.0499627\ttest: 0.0881970\tbest: 0.0881947 (2258)\ttotal: 1m 19s\tremaining: 1m 8s\n",
            "2280:\tlearn: 0.0497540\ttest: 0.0881711\tbest: 0.0881613 (2275)\ttotal: 1m 19s\tremaining: 1m 8s\n",
            "2300:\tlearn: 0.0495112\ttest: 0.0880919\tbest: 0.0880919 (2300)\ttotal: 1m 20s\tremaining: 1m 7s\n",
            "2320:\tlearn: 0.0492654\ttest: 0.0880877\tbest: 0.0880812 (2314)\ttotal: 1m 21s\tremaining: 1m 6s\n",
            "2340:\tlearn: 0.0490072\ttest: 0.0880723\tbest: 0.0880674 (2334)\ttotal: 1m 22s\tremaining: 1m 6s\n",
            "2360:\tlearn: 0.0487713\ttest: 0.0880168\tbest: 0.0880168 (2360)\ttotal: 1m 22s\tremaining: 1m 5s\n",
            "2380:\tlearn: 0.0485478\ttest: 0.0879946\tbest: 0.0879880 (2378)\ttotal: 1m 23s\tremaining: 1m 4s\n",
            "2400:\tlearn: 0.0483615\ttest: 0.0879944\tbest: 0.0879823 (2384)\ttotal: 1m 24s\tremaining: 1m 4s\n",
            "2420:\tlearn: 0.0481197\ttest: 0.0879495\tbest: 0.0879460 (2419)\ttotal: 1m 25s\tremaining: 1m 3s\n",
            "2440:\tlearn: 0.0478923\ttest: 0.0879188\tbest: 0.0879188 (2440)\ttotal: 1m 25s\tremaining: 1m 2s\n",
            "2460:\tlearn: 0.0476936\ttest: 0.0879087\tbest: 0.0879023 (2458)\ttotal: 1m 26s\tremaining: 1m 1s\n",
            "2480:\tlearn: 0.0474621\ttest: 0.0878744\tbest: 0.0878744 (2480)\ttotal: 1m 27s\tremaining: 1m 1s\n",
            "2500:\tlearn: 0.0472631\ttest: 0.0878532\tbest: 0.0878532 (2500)\ttotal: 1m 27s\tremaining: 1m\n",
            "2520:\tlearn: 0.0469988\ttest: 0.0878774\tbest: 0.0878426 (2503)\ttotal: 1m 28s\tremaining: 59.9s\n",
            "2540:\tlearn: 0.0467246\ttest: 0.0878428\tbest: 0.0878426 (2503)\ttotal: 1m 29s\tremaining: 59.2s\n",
            "2560:\tlearn: 0.0464735\ttest: 0.0878122\tbest: 0.0878090 (2549)\ttotal: 1m 30s\tremaining: 58.5s\n",
            "2580:\tlearn: 0.0462782\ttest: 0.0877946\tbest: 0.0877946 (2580)\ttotal: 1m 30s\tremaining: 57.8s\n",
            "2600:\tlearn: 0.0460595\ttest: 0.0877828\tbest: 0.0877753 (2588)\ttotal: 1m 31s\tremaining: 57.1s\n",
            "2620:\tlearn: 0.0458317\ttest: 0.0877808\tbest: 0.0877634 (2609)\ttotal: 1m 32s\tremaining: 56.4s\n",
            "2640:\tlearn: 0.0456116\ttest: 0.0877662\tbest: 0.0877634 (2609)\ttotal: 1m 33s\tremaining: 55.7s\n",
            "2660:\tlearn: 0.0453521\ttest: 0.0877082\tbest: 0.0876959 (2655)\ttotal: 1m 33s\tremaining: 55s\n",
            "2680:\tlearn: 0.0451450\ttest: 0.0877081\tbest: 0.0876959 (2655)\ttotal: 1m 34s\tremaining: 54.3s\n",
            "2700:\tlearn: 0.0449257\ttest: 0.0876996\tbest: 0.0876959 (2655)\ttotal: 1m 35s\tremaining: 53.6s\n",
            "2720:\tlearn: 0.0447095\ttest: 0.0876658\tbest: 0.0876635 (2718)\ttotal: 1m 35s\tremaining: 52.9s\n",
            "2740:\tlearn: 0.0445096\ttest: 0.0876245\tbest: 0.0876245 (2740)\ttotal: 1m 36s\tremaining: 52.2s\n",
            "2760:\tlearn: 0.0443360\ttest: 0.0876286\tbest: 0.0876191 (2743)\ttotal: 1m 37s\tremaining: 51.5s\n",
            "2780:\tlearn: 0.0441236\ttest: 0.0876314\tbest: 0.0876121 (2767)\ttotal: 1m 38s\tremaining: 50.8s\n",
            "2800:\tlearn: 0.0439279\ttest: 0.0876147\tbest: 0.0876121 (2767)\ttotal: 1m 38s\tremaining: 50.1s\n",
            "2820:\tlearn: 0.0437581\ttest: 0.0876032\tbest: 0.0875974 (2816)\ttotal: 1m 39s\tremaining: 49.4s\n",
            "2840:\tlearn: 0.0435603\ttest: 0.0876050\tbest: 0.0875903 (2829)\ttotal: 1m 40s\tremaining: 48.7s\n",
            "2860:\tlearn: 0.0433231\ttest: 0.0875900\tbest: 0.0875900 (2860)\ttotal: 1m 40s\tremaining: 48s\n",
            "2880:\tlearn: 0.0431334\ttest: 0.0875823\tbest: 0.0875777 (2877)\ttotal: 1m 41s\tremaining: 47.3s\n",
            "2900:\tlearn: 0.0429290\ttest: 0.0875683\tbest: 0.0875683 (2900)\ttotal: 1m 42s\tremaining: 46.6s\n",
            "2920:\tlearn: 0.0427381\ttest: 0.0875110\tbest: 0.0875110 (2920)\ttotal: 1m 43s\tremaining: 45.9s\n",
            "2940:\tlearn: 0.0425749\ttest: 0.0875091\tbest: 0.0874944 (2934)\ttotal: 1m 43s\tremaining: 45.2s\n",
            "2960:\tlearn: 0.0423561\ttest: 0.0875147\tbest: 0.0874944 (2934)\ttotal: 1m 44s\tremaining: 44.5s\n",
            "2980:\tlearn: 0.0421695\ttest: 0.0875442\tbest: 0.0874944 (2934)\ttotal: 1m 45s\tremaining: 43.8s\n",
            "bestTest = 0.0874944453\n",
            "bestIteration = 2934\n",
            "Shrink model to first 2935 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
            "\t0.9\t = Validation score   (roc_auc)\n",
            "\t109.35s\t = Training   runtime\n",
            "\t0.85s\t = Validation runtime\n",
            "\t69289.6\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 419.21s of the 419.20s of remaining time.\n",
            "\tFitting ExtraTreesGini with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.2 GB\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "\t0.8771\t = Validation score   (roc_auc)\n",
            "\t12.0s\t = Training   runtime\n",
            "\t1.55s\t = Validation runtime\n",
            "\t38194.9\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 405.54s of the 405.53s of remaining time.\n",
            "\tFitting ExtraTreesEntr with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.0 GB\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "\t0.88\t = Validation score   (roc_auc)\n",
            "\t10.69s\t = Training   runtime\n",
            "\t1.46s\t = Validation runtime\n",
            "\t40439.0\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 393.27s of the 393.26s of remaining time.\n",
            "\tFitting NeuralNetFastAI with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.5/42.0 GB\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 31/31 categorical features\n",
            "Using 393 cont features\n",
            "Automated batch size selection: 256\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0-2): 3 x Embedding(6, 4)\n",
            "    (3-4): 2 x Embedding(61, 16)\n",
            "    (5-7): 3 x Embedding(4, 3)\n",
            "    (8): Embedding(5, 4)\n",
            "    (9-14): 6 x Embedding(4, 3)\n",
            "    (15): Embedding(5, 4)\n",
            "    (16): Embedding(4, 3)\n",
            "    (17): Embedding(5, 4)\n",
            "    (18-20): 3 x Embedding(4, 3)\n",
            "    (21): Embedding(71, 17)\n",
            "    (22): Embedding(105, 22)\n",
            "    (23): Embedding(90, 20)\n",
            "    (24): Embedding(6, 4)\n",
            "    (25-29): 5 x Embedding(4, 3)\n",
            "    (30): Embedding(607, 58)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(393, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): LinBnDrop(\n",
            "      (0): Linear(in_features=624, out_features=200, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): LinBnDrop(\n",
            "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): LinBnDrop(\n",
            "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Automated epochs selection: training for 30 epoch(s). Estimated time budget use 193.39 / 389.85 sec\n",
            "Better model found at epoch 0 with valid_loss value: 0.23255150020122528.\n",
            "Better model found at epoch 1 with valid_loss value: 0.12507060170173645.\n",
            "Better model found at epoch 2 with valid_loss value: 0.12104953080415726.\n",
            "Better model found at epoch 3 with valid_loss value: 0.11818386614322662.\n",
            "Better model found at epoch 8 with valid_loss value: 0.11801112443208694.\n",
            "No improvement since epoch 8: early stopping\n",
            "Model validation metrics: 0.11801112443208694\n",
            "Saving /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Saving /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "\t0.8388\t = Validation score   (roc_auc)\n",
            "\t121.37s\t = Training   runtime\n",
            "\t2.18s\t = Validation runtime\n",
            "\t27101.2\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: XGBoost ... Training model for up to 269.65s of the 269.64s of remaining time.\n",
            "\tFitting XGBoost with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.3/41.9 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.13363\n",
            "[50]\tvalidation_0-logloss:0.09315\n",
            "[100]\tvalidation_0-logloss:0.09009\n",
            "[150]\tvalidation_0-logloss:0.08843\n",
            "[200]\tvalidation_0-logloss:0.08729\n",
            "[250]\tvalidation_0-logloss:0.08703\n",
            "[300]\tvalidation_0-logloss:0.08702\n",
            "[350]\tvalidation_0-logloss:0.08693\n",
            "[393]\tvalidation_0-logloss:0.08713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [06:39:27] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n",
            "Saving /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "\t0.9026\t = Validation score   (roc_auc)\n",
            "\t7.1s\t = Training   runtime\n",
            "\t1.75s\t = Validation runtime\n",
            "\t33780.0\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 260.78s of the 260.77s of remaining time.\n",
            "\tFitting NeuralNetTorch with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=0.7/41.8 GB\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"TransactionID\",\n",
            "        \"TransactionDT\",\n",
            "        \"card1\",\n",
            "        \"card2\",\n",
            "        \"addr1\",\n",
            "        \"D9\",\n",
            "        \"D15\",\n",
            "        \"V4\",\n",
            "        \"V5\",\n",
            "        \"V10\",\n",
            "        \"V11\",\n",
            "        \"V12\",\n",
            "        \"V13\",\n",
            "        \"V19\",\n",
            "        \"V20\",\n",
            "        \"V29\",\n",
            "        \"V35\",\n",
            "        \"V36\",\n",
            "        \"V48\",\n",
            "        \"V53\",\n",
            "        \"V54\",\n",
            "        \"V61\",\n",
            "        \"V62\",\n",
            "        \"V69\",\n",
            "        \"V75\",\n",
            "        \"V76\",\n",
            "        \"V82\",\n",
            "        \"V83\",\n",
            "        \"V90\",\n",
            "        \"V194\",\n",
            "        \"id_07\",\n",
            "        \"id_08\",\n",
            "        \"id_17\",\n",
            "        \"id_19\",\n",
            "        \"id_20\",\n",
            "        \"id_25\",\n",
            "        \"id_26\",\n",
            "        \"id_32\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"TransactionAmt\",\n",
            "        \"card3\",\n",
            "        \"card5\",\n",
            "        \"addr2\",\n",
            "        \"dist1\",\n",
            "        \"dist2\",\n",
            "        \"C1\",\n",
            "        \"C2\",\n",
            "        \"C3\",\n",
            "        \"C4\",\n",
            "        \"C5\",\n",
            "        \"C6\",\n",
            "        \"C7\",\n",
            "        \"C8\",\n",
            "        \"C9\",\n",
            "        \"C10\",\n",
            "        \"C11\",\n",
            "        \"C12\",\n",
            "        \"C13\",\n",
            "        \"C14\",\n",
            "        \"D1\",\n",
            "        \"D2\",\n",
            "        \"D3\",\n",
            "        \"D4\",\n",
            "        \"D5\",\n",
            "        \"D6\",\n",
            "        \"D7\",\n",
            "        \"D8\",\n",
            "        \"D10\",\n",
            "        \"D11\",\n",
            "        \"D12\",\n",
            "        \"D13\",\n",
            "        \"D14\",\n",
            "        \"V1\",\n",
            "        \"V2\",\n",
            "        \"V3\",\n",
            "        \"V6\",\n",
            "        \"V7\",\n",
            "        \"V8\",\n",
            "        \"V9\",\n",
            "        \"V14\",\n",
            "        \"V15\",\n",
            "        \"V16\",\n",
            "        \"V17\",\n",
            "        \"V18\",\n",
            "        \"V21\",\n",
            "        \"V22\",\n",
            "        \"V23\",\n",
            "        \"V24\",\n",
            "        \"V25\",\n",
            "        \"V26\",\n",
            "        \"V27\",\n",
            "        \"V28\",\n",
            "        \"V30\",\n",
            "        \"V31\",\n",
            "        \"V32\",\n",
            "        \"V33\",\n",
            "        \"V34\",\n",
            "        \"V37\",\n",
            "        \"V38\",\n",
            "        \"V39\",\n",
            "        \"V40\",\n",
            "        \"V41\",\n",
            "        \"V42\",\n",
            "        \"V43\",\n",
            "        \"V44\",\n",
            "        \"V45\",\n",
            "        \"V46\",\n",
            "        \"V47\",\n",
            "        \"V49\",\n",
            "        \"V50\",\n",
            "        \"V51\",\n",
            "        \"V52\",\n",
            "        \"V55\",\n",
            "        \"V56\",\n",
            "        \"V57\",\n",
            "        \"V58\",\n",
            "        \"V59\",\n",
            "        \"V60\",\n",
            "        \"V63\",\n",
            "        \"V64\",\n",
            "        \"V65\",\n",
            "        \"V66\",\n",
            "        \"V67\",\n",
            "        \"V68\",\n",
            "        \"V70\",\n",
            "        \"V71\",\n",
            "        \"V72\",\n",
            "        \"V73\",\n",
            "        \"V74\",\n",
            "        \"V77\",\n",
            "        \"V78\",\n",
            "        \"V79\",\n",
            "        \"V80\",\n",
            "        \"V81\",\n",
            "        \"V84\",\n",
            "        \"V85\",\n",
            "        \"V86\",\n",
            "        \"V87\",\n",
            "        \"V88\",\n",
            "        \"V89\",\n",
            "        \"V91\",\n",
            "        \"V92\",\n",
            "        \"V93\",\n",
            "        \"V94\",\n",
            "        \"V95\",\n",
            "        \"V96\",\n",
            "        \"V97\",\n",
            "        \"V98\",\n",
            "        \"V99\",\n",
            "        \"V100\",\n",
            "        \"V101\",\n",
            "        \"V102\",\n",
            "        \"V103\",\n",
            "        \"V104\",\n",
            "        \"V105\",\n",
            "        \"V106\",\n",
            "        \"V107\",\n",
            "        \"V108\",\n",
            "        \"V109\",\n",
            "        \"V110\",\n",
            "        \"V111\",\n",
            "        \"V112\",\n",
            "        \"V114\",\n",
            "        \"V115\",\n",
            "        \"V116\",\n",
            "        \"V117\",\n",
            "        \"V118\",\n",
            "        \"V120\",\n",
            "        \"V121\",\n",
            "        \"V122\",\n",
            "        \"V123\",\n",
            "        \"V124\",\n",
            "        \"V125\",\n",
            "        \"V126\",\n",
            "        \"V127\",\n",
            "        \"V128\",\n",
            "        \"V129\",\n",
            "        \"V130\",\n",
            "        \"V131\",\n",
            "        \"V132\",\n",
            "        \"V133\",\n",
            "        \"V134\",\n",
            "        \"V135\",\n",
            "        \"V136\",\n",
            "        \"V137\",\n",
            "        \"V138\",\n",
            "        \"V139\",\n",
            "        \"V140\",\n",
            "        \"V141\",\n",
            "        \"V142\",\n",
            "        \"V143\",\n",
            "        \"V144\",\n",
            "        \"V145\",\n",
            "        \"V146\",\n",
            "        \"V148\",\n",
            "        \"V150\",\n",
            "        \"V151\",\n",
            "        \"V152\",\n",
            "        \"V153\",\n",
            "        \"V155\",\n",
            "        \"V157\",\n",
            "        \"V158\",\n",
            "        \"V159\",\n",
            "        \"V160\",\n",
            "        \"V161\",\n",
            "        \"V162\",\n",
            "        \"V163\",\n",
            "        \"V164\",\n",
            "        \"V165\",\n",
            "        \"V166\",\n",
            "        \"V167\",\n",
            "        \"V168\",\n",
            "        \"V169\",\n",
            "        \"V170\",\n",
            "        \"V171\",\n",
            "        \"V172\",\n",
            "        \"V173\",\n",
            "        \"V174\",\n",
            "        \"V175\",\n",
            "        \"V176\",\n",
            "        \"V177\",\n",
            "        \"V178\",\n",
            "        \"V179\",\n",
            "        \"V180\",\n",
            "        \"V181\",\n",
            "        \"V182\",\n",
            "        \"V183\",\n",
            "        \"V184\",\n",
            "        \"V185\",\n",
            "        \"V186\",\n",
            "        \"V187\",\n",
            "        \"V188\",\n",
            "        \"V189\",\n",
            "        \"V190\",\n",
            "        \"V191\",\n",
            "        \"V192\",\n",
            "        \"V193\",\n",
            "        \"V195\",\n",
            "        \"V196\",\n",
            "        \"V197\",\n",
            "        \"V199\",\n",
            "        \"V200\",\n",
            "        \"V201\",\n",
            "        \"V202\",\n",
            "        \"V203\",\n",
            "        \"V204\",\n",
            "        \"V205\",\n",
            "        \"V206\",\n",
            "        \"V207\",\n",
            "        \"V208\",\n",
            "        \"V209\",\n",
            "        \"V210\",\n",
            "        \"V211\",\n",
            "        \"V212\",\n",
            "        \"V213\",\n",
            "        \"V214\",\n",
            "        \"V215\",\n",
            "        \"V216\",\n",
            "        \"V217\",\n",
            "        \"V218\",\n",
            "        \"V219\",\n",
            "        \"V220\",\n",
            "        \"V221\",\n",
            "        \"V222\",\n",
            "        \"V223\",\n",
            "        \"V224\",\n",
            "        \"V225\",\n",
            "        \"V226\",\n",
            "        \"V227\",\n",
            "        \"V228\",\n",
            "        \"V229\",\n",
            "        \"V230\",\n",
            "        \"V231\",\n",
            "        \"V232\",\n",
            "        \"V233\",\n",
            "        \"V234\",\n",
            "        \"V235\",\n",
            "        \"V236\",\n",
            "        \"V237\",\n",
            "        \"V238\",\n",
            "        \"V239\",\n",
            "        \"V240\",\n",
            "        \"V242\",\n",
            "        \"V243\",\n",
            "        \"V244\",\n",
            "        \"V245\",\n",
            "        \"V246\",\n",
            "        \"V247\",\n",
            "        \"V248\",\n",
            "        \"V249\",\n",
            "        \"V250\",\n",
            "        \"V251\",\n",
            "        \"V252\",\n",
            "        \"V253\",\n",
            "        \"V254\",\n",
            "        \"V255\",\n",
            "        \"V256\",\n",
            "        \"V257\",\n",
            "        \"V258\",\n",
            "        \"V259\",\n",
            "        \"V260\",\n",
            "        \"V261\",\n",
            "        \"V262\",\n",
            "        \"V263\",\n",
            "        \"V264\",\n",
            "        \"V265\",\n",
            "        \"V266\",\n",
            "        \"V267\",\n",
            "        \"V268\",\n",
            "        \"V269\",\n",
            "        \"V270\",\n",
            "        \"V271\",\n",
            "        \"V272\",\n",
            "        \"V273\",\n",
            "        \"V274\",\n",
            "        \"V275\",\n",
            "        \"V276\",\n",
            "        \"V277\",\n",
            "        \"V278\",\n",
            "        \"V279\",\n",
            "        \"V280\",\n",
            "        \"V281\",\n",
            "        \"V282\",\n",
            "        \"V283\",\n",
            "        \"V284\",\n",
            "        \"V285\",\n",
            "        \"V286\",\n",
            "        \"V287\",\n",
            "        \"V288\",\n",
            "        \"V289\",\n",
            "        \"V290\",\n",
            "        \"V291\",\n",
            "        \"V292\",\n",
            "        \"V293\",\n",
            "        \"V294\",\n",
            "        \"V295\",\n",
            "        \"V296\",\n",
            "        \"V297\",\n",
            "        \"V298\",\n",
            "        \"V299\",\n",
            "        \"V300\",\n",
            "        \"V301\",\n",
            "        \"V302\",\n",
            "        \"V303\",\n",
            "        \"V304\",\n",
            "        \"V306\",\n",
            "        \"V307\",\n",
            "        \"V308\",\n",
            "        \"V309\",\n",
            "        \"V310\",\n",
            "        \"V311\",\n",
            "        \"V312\",\n",
            "        \"V313\",\n",
            "        \"V314\",\n",
            "        \"V315\",\n",
            "        \"V316\",\n",
            "        \"V317\",\n",
            "        \"V318\",\n",
            "        \"V319\",\n",
            "        \"V320\",\n",
            "        \"V321\",\n",
            "        \"V322\",\n",
            "        \"V323\",\n",
            "        \"V324\",\n",
            "        \"V325\",\n",
            "        \"V326\",\n",
            "        \"V327\",\n",
            "        \"V328\",\n",
            "        \"V329\",\n",
            "        \"V330\",\n",
            "        \"V331\",\n",
            "        \"V332\",\n",
            "        \"V333\",\n",
            "        \"V334\",\n",
            "        \"V335\",\n",
            "        \"V336\",\n",
            "        \"V337\",\n",
            "        \"V338\",\n",
            "        \"V339\",\n",
            "        \"id_01\",\n",
            "        \"id_02\",\n",
            "        \"id_03\",\n",
            "        \"id_04\",\n",
            "        \"id_05\",\n",
            "        \"id_06\",\n",
            "        \"id_09\",\n",
            "        \"id_10\",\n",
            "        \"id_11\",\n",
            "        \"id_13\",\n",
            "        \"id_14\",\n",
            "        \"id_18\",\n",
            "        \"id_21\",\n",
            "        \"id_22\",\n",
            "        \"id_24\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"M1\",\n",
            "        \"M2\",\n",
            "        \"M3\",\n",
            "        \"M5\",\n",
            "        \"M6\",\n",
            "        \"M7\",\n",
            "        \"M8\",\n",
            "        \"M9\",\n",
            "        \"id_12\",\n",
            "        \"id_16\",\n",
            "        \"id_27\",\n",
            "        \"id_28\",\n",
            "        \"id_29\",\n",
            "        \"id_35\",\n",
            "        \"id_36\",\n",
            "        \"id_37\",\n",
            "        \"id_38\",\n",
            "        \"DeviceType\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"ProductCD\",\n",
            "        \"card4\",\n",
            "        \"card6\",\n",
            "        \"P_emaildomain\",\n",
            "        \"R_emaildomain\",\n",
            "        \"M4\",\n",
            "        \"id_15\",\n",
            "        \"id_23\",\n",
            "        \"id_30\",\n",
            "        \"id_31\",\n",
            "        \"id_33\",\n",
            "        \"id_34\",\n",
            "        \"DeviceInfo\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 50000 examples, 424 features (411 vector, 13 embedding)\n",
            "Training on GPU (CUDA)\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0-2): 3 x Embedding(6, 4)\n",
            "    (3): Embedding(61, 15)\n",
            "    (4): Embedding(60, 15)\n",
            "    (5-7): 3 x Embedding(5, 3)\n",
            "    (8): Embedding(72, 17)\n",
            "    (9): Embedding(102, 21)\n",
            "    (10): Embedding(82, 18)\n",
            "    (11): Embedding(6, 4)\n",
            "    (12): Embedding(102, 21)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=579, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.1, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 1000 epochs...\n",
            "Epoch 1 (Update 390).\tTrain loss: 0.1321, Val roc_auc: 0.8316, Best Epoch: 1\n",
            "Epoch 2 (Update 780).\tTrain loss: 0.1112, Val roc_auc: 0.851, Best Epoch: 2\n",
            "Epoch 3 (Update 1170).\tTrain loss: 0.1062, Val roc_auc: 0.8589, Best Epoch: 3\n",
            "Epoch 4 (Update 1560).\tTrain loss: 0.1026, Val roc_auc: 0.86, Best Epoch: 4\n",
            "Epoch 5 (Update 1950).\tTrain loss: 0.1012, Val roc_auc: 0.8657, Best Epoch: 5\n",
            "Epoch 6 (Update 2340).\tTrain loss: 0.1, Val roc_auc: 0.8671, Best Epoch: 6\n",
            "Epoch 7 (Update 2730).\tTrain loss: 0.0983, Val roc_auc: 0.8653, Best Epoch: 6\n",
            "Epoch 8 (Update 3120).\tTrain loss: 0.0969, Val roc_auc: 0.8678, Best Epoch: 8\n",
            "Epoch 9 (Update 3510).\tTrain loss: 0.0953, Val roc_auc: 0.8664, Best Epoch: 8\n",
            "Epoch 10 (Update 3900).\tTrain loss: 0.0942, Val roc_auc: 0.8693, Best Epoch: 10\n",
            "Epoch 11 (Update 4290).\tTrain loss: 0.0938, Val roc_auc: 0.8644, Best Epoch: 10\n",
            "Epoch 12 (Update 4680).\tTrain loss: 0.0928, Val roc_auc: 0.8689, Best Epoch: 10\n",
            "Epoch 13 (Update 5070).\tTrain loss: 0.092, Val roc_auc: 0.8682, Best Epoch: 10\n",
            "Epoch 14 (Update 5460).\tTrain loss: 0.0911, Val roc_auc: 0.8694, Best Epoch: 14\n",
            "Epoch 15 (Update 5850).\tTrain loss: 0.0899, Val roc_auc: 0.8669, Best Epoch: 14\n",
            "Epoch 16 (Update 6240).\tTrain loss: 0.0893, Val roc_auc: 0.8712, Best Epoch: 16\n",
            "Epoch 17 (Update 6630).\tTrain loss: 0.0886, Val roc_auc: 0.866, Best Epoch: 16\n",
            "Epoch 18 (Update 7020).\tTrain loss: 0.0884, Val roc_auc: 0.8693, Best Epoch: 16\n",
            "Epoch 19 (Update 7410).\tTrain loss: 0.0871, Val roc_auc: 0.8625, Best Epoch: 16\n",
            "Epoch 20 (Update 7800).\tTrain loss: 0.0866, Val roc_auc: 0.8661, Best Epoch: 16\n",
            "Epoch 21 (Update 8190).\tTrain loss: 0.0866, Val roc_auc: 0.8617, Best Epoch: 16\n",
            "Epoch 22 (Update 8580).\tTrain loss: 0.0848, Val roc_auc: 0.865, Best Epoch: 16\n",
            "Epoch 23 (Update 8970).\tTrain loss: 0.0844, Val roc_auc: 0.8649, Best Epoch: 16\n",
            "Epoch 24 (Update 9360).\tTrain loss: 0.0841, Val roc_auc: 0.861, Best Epoch: 16\n",
            "Epoch 25 (Update 9750).\tTrain loss: 0.0833, Val roc_auc: 0.8617, Best Epoch: 16\n",
            "Epoch 26 (Update 10140).\tTrain loss: 0.0814, Val roc_auc: 0.8571, Best Epoch: 16\n",
            "Epoch 27 (Update 10530).\tTrain loss: 0.0828, Val roc_auc: 0.8639, Best Epoch: 16\n",
            "Epoch 28 (Update 10920).\tTrain loss: 0.0805, Val roc_auc: 0.8645, Best Epoch: 16\n",
            "Epoch 29 (Update 11310).\tTrain loss: 0.0811, Val roc_auc: 0.8468, Best Epoch: 16\n",
            "Epoch 30 (Update 11700).\tTrain loss: 0.0807, Val roc_auc: 0.858, Best Epoch: 16\n",
            "Epoch 31 (Update 12090).\tTrain loss: 0.0816, Val roc_auc: 0.8644, Best Epoch: 16\n",
            "Epoch 32 (Update 12480).\tTrain loss: 0.0793, Val roc_auc: 0.8526, Best Epoch: 16\n",
            "Epoch 33 (Update 12870).\tTrain loss: 0.0791, Val roc_auc: 0.8463, Best Epoch: 16\n",
            "Epoch 34 (Update 13260).\tTrain loss: 0.0778, Val roc_auc: 0.8549, Best Epoch: 16\n",
            "Epoch 35 (Update 13650).\tTrain loss: 0.0774, Val roc_auc: 0.835, Best Epoch: 16\n",
            "Epoch 36 (Update 14040).\tTrain loss: 0.0784, Val roc_auc: 0.8539, Best Epoch: 16\n",
            "Epoch 37 (Update 14430).\tTrain loss: 0.0761, Val roc_auc: 0.8446, Best Epoch: 16\n",
            "Epoch 38 (Update 14820).\tTrain loss: 0.0772, Val roc_auc: 0.8406, Best Epoch: 16\n",
            "Epoch 39 (Update 15210).\tTrain loss: 0.0756, Val roc_auc: 0.8523, Best Epoch: 16\n",
            "Epoch 40 (Update 15600).\tTrain loss: 0.0755, Val roc_auc: 0.8376, Best Epoch: 16\n",
            "Epoch 41 (Update 15990).\tTrain loss: 0.075, Val roc_auc: 0.8544, Best Epoch: 16\n",
            "Epoch 42 (Update 16380).\tTrain loss: 0.0736, Val roc_auc: 0.8353, Best Epoch: 16\n",
            "Epoch 43 (Update 16770).\tTrain loss: 0.0749, Val roc_auc: 0.836, Best Epoch: 16\n",
            "Epoch 44 (Update 17160).\tTrain loss: 0.0737, Val roc_auc: 0.8354, Best Epoch: 16\n",
            "Best model found on Epoch 16 (Update 6240). Val roc_auc: 0.8712098642597333\n",
            "Saving /content/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "\t0.8712\t = Validation score   (roc_auc)\n",
            "\t101.04s\t = Training   runtime\n",
            "\t2.8s\t = Validation runtime\n",
            "\t21098.1\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBMLarge ... Training model for up to 156.92s of the 156.91s of remaining time.\n",
            "\tFitting LightGBMLarge with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.1/42.0 GB\n",
            "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0986082\n",
            "[100]\tvalid_set's binary_logloss: 0.0913039\n",
            "[150]\tvalid_set's binary_logloss: 0.0891291\n",
            "[200]\tvalid_set's binary_logloss: 0.0892942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "\t0.9055\t = Validation score   (roc_auc)\n",
            "\t14.6s\t = Training   runtime\n",
            "\t0.74s\t = Validation runtime\n",
            "\t80010.6\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 141.52s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 1, 'num_cpus': 8\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 15\n",
            "Ensemble weights: \n",
            "[0.06666667 0.33333333 0.         0.         0.2        0.\n",
            " 0.06666667 0.         0.13333333 0.         0.2       ]\n",
            "\t0.26s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBM': 0.333, 'CatBoost': 0.2, 'LightGBMLarge': 0.2, 'XGBoost': 0.133, 'LightGBMXT': 0.067, 'ExtraTreesEntr': 0.067}\n",
            "\t0.9136\t = Validation score   (roc_auc)\n",
            "\t2.32s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t8152.7\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 461.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 8152.7 rows/s (59054 batch size)\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Saving /content/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels\")\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2   0.913633     roc_auc       7.243525  172.344859                0.009417           2.319381            2       True         12\n",
            "1              LightGBM   0.906880     roc_auc       0.991565    8.970043                0.991565           8.970043            1       True          2\n",
            "2         LightGBMLarge   0.905513     roc_auc       0.738077   14.600927                0.738077          14.600927            1       True         11\n",
            "3            LightGBMXT   0.902809     roc_auc       1.443673   19.313227                1.443673          19.313227            1       True          1\n",
            "4               XGBoost   0.902599     roc_auc       1.748194    7.098324                1.748194           7.098324            1       True          9\n",
            "5              CatBoost   0.900021     roc_auc       0.852278  109.353353                0.852278         109.353353            1       True          5\n",
            "6      RandomForestEntr   0.883320     roc_auc       1.086809   12.203449                1.086809          12.203449            1       True          4\n",
            "7      RandomForestGini   0.880236     roc_auc       1.261413   15.792927                1.261413          15.792927            1       True          3\n",
            "8        ExtraTreesEntr   0.879973     roc_auc       1.460321   10.689603                1.460321          10.689603            1       True          7\n",
            "9        ExtraTreesGini   0.877093     roc_auc       1.546123   12.001462                1.546123          12.001462            1       True          6\n",
            "10       NeuralNetTorch   0.871210     roc_auc       2.799021  101.036460                2.799021         101.036460            1       True         10\n",
            "11      NeuralNetFastAI   0.838762     roc_auc       2.179018  121.366855                2.179018         121.366855            1       True          8\n",
            "Number of models trained: 12\n",
            "Types of models trained:\n",
            "{'XGBoostModel', 'LGBModel', 'RFModel', 'NNFastAiTabularModel', 'CatBoostModel', 'WeightedEnsembleModel', 'TabularNeuralNetTorchModel', 'XTModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "Plot summary of models saved to file: /content/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "782_DHP4LEkR",
        "outputId": "c4990d97-fae5-440e-bf9f-e4863ee5d5e5"
      },
      "id": "782_DHP4LEkR",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model  score_val eval_metric  pred_time_val    fit_time  \\\n",
              "0   WeightedEnsemble_L2   0.913633     roc_auc       7.243525  172.344859   \n",
              "1              LightGBM   0.906880     roc_auc       0.991565    8.970043   \n",
              "2         LightGBMLarge   0.905513     roc_auc       0.738077   14.600927   \n",
              "3            LightGBMXT   0.902809     roc_auc       1.443673   19.313227   \n",
              "4               XGBoost   0.902599     roc_auc       1.748194    7.098324   \n",
              "5              CatBoost   0.900021     roc_auc       0.852278  109.353353   \n",
              "6      RandomForestEntr   0.883320     roc_auc       1.086809   12.203449   \n",
              "7      RandomForestGini   0.880236     roc_auc       1.261413   15.792927   \n",
              "8        ExtraTreesEntr   0.879973     roc_auc       1.460321   10.689603   \n",
              "9        ExtraTreesGini   0.877093     roc_auc       1.546123   12.001462   \n",
              "10       NeuralNetTorch   0.871210     roc_auc       2.799021  101.036460   \n",
              "11      NeuralNetFastAI   0.838762     roc_auc       2.179018  121.366855   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.009417           2.319381            2       True   \n",
              "1                 0.991565           8.970043            1       True   \n",
              "2                 0.738077          14.600927            1       True   \n",
              "3                 1.443673          19.313227            1       True   \n",
              "4                 1.748194           7.098324            1       True   \n",
              "5                 0.852278         109.353353            1       True   \n",
              "6                 1.086809          12.203449            1       True   \n",
              "7                 1.261413          15.792927            1       True   \n",
              "8                 1.460321          10.689603            1       True   \n",
              "9                 1.546123          12.001462            1       True   \n",
              "10                2.799021         101.036460            1       True   \n",
              "11                2.179018         121.366855            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          12  \n",
              "1           2  \n",
              "2          11  \n",
              "3           1  \n",
              "4           9  \n",
              "5           5  \n",
              "6           4  \n",
              "7           3  \n",
              "8           7  \n",
              "9           6  \n",
              "10         10  \n",
              "11          8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f35a1f8-dafb-4536-98ee-0e3344ebb89f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.913633</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>7.243525</td>\n",
              "      <td>172.344859</td>\n",
              "      <td>0.009417</td>\n",
              "      <td>2.319381</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.906880</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.991565</td>\n",
              "      <td>8.970043</td>\n",
              "      <td>0.991565</td>\n",
              "      <td>8.970043</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.905513</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.738077</td>\n",
              "      <td>14.600927</td>\n",
              "      <td>0.738077</td>\n",
              "      <td>14.600927</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.902809</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.443673</td>\n",
              "      <td>19.313227</td>\n",
              "      <td>1.443673</td>\n",
              "      <td>19.313227</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.902599</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.748194</td>\n",
              "      <td>7.098324</td>\n",
              "      <td>1.748194</td>\n",
              "      <td>7.098324</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.900021</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.852278</td>\n",
              "      <td>109.353353</td>\n",
              "      <td>0.852278</td>\n",
              "      <td>109.353353</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.883320</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.086809</td>\n",
              "      <td>12.203449</td>\n",
              "      <td>1.086809</td>\n",
              "      <td>12.203449</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.880236</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.261413</td>\n",
              "      <td>15.792927</td>\n",
              "      <td>1.261413</td>\n",
              "      <td>15.792927</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.879973</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.460321</td>\n",
              "      <td>10.689603</td>\n",
              "      <td>1.460321</td>\n",
              "      <td>10.689603</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.877093</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.546123</td>\n",
              "      <td>12.001462</td>\n",
              "      <td>1.546123</td>\n",
              "      <td>12.001462</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.871210</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>2.799021</td>\n",
              "      <td>101.036460</td>\n",
              "      <td>2.799021</td>\n",
              "      <td>101.036460</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.838762</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>2.179018</td>\n",
              "      <td>121.366855</td>\n",
              "      <td>2.179018</td>\n",
              "      <td>121.366855</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f35a1f8-dafb-4536-98ee-0e3344ebb89f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f35a1f8-dafb-4536-98ee-0e3344ebb89f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f35a1f8-dafb-4536-98ee-0e3344ebb89f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-996c1c16-9e57-4654-8924-72812213b04d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-996c1c16-9e57-4654-8924-72812213b04d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-996c1c16-9e57-4654-8924-72812213b04d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"NeuralNetTorch\",\n          \"ExtraTreesGini\",\n          \"WeightedEnsemble_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0210324325722982,\n        \"min\": 0.8387616258065165,\n        \"max\": 0.9136325026494598,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.8712098642597333,\n          0.8770933526808279,\n          0.9136325026494598\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roc_auc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7659939708657222,\n        \"min\": 0.7380771636962891,\n        \"max\": 7.243525266647339,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.7990214824676514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.38260841674838,\n        \"min\": 7.098324298858643,\n        \"max\": 172.34485864639282,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          101.03645968437195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7153668296602005,\n        \"min\": 0.009416580200195312,\n        \"max\": 2.7990214824676514,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.7990214824676514\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.25197413603625,\n        \"min\": 2.3193812370300293,\n        \"max\": 121.36685490608215,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          101.03645968437195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "y_true = test_data[label].astype(int)\n",
        "y_pred = predictor.predict(test_data.drop(columns=[label]),model='LightGBM')\n",
        "AUC = roc_auc_score(y_true, y_pred)\n",
        "print(AUC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmwQfUAoLb22",
        "outputId": "dfd89728-509f-4dd1-a720-04f59519c7b2"
      },
      "id": "tmwQfUAoLb22",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7002225377894307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.value_counts(),y_true.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqnEoUy5NKZ4",
        "outputId": "9fd0c824-85ef-4f66-c532-4253d3c21446"
      },
      "id": "sqnEoUy5NKZ4",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(isFraud\n",
              " 0    58104\n",
              " 1      950\n",
              " Name: count, dtype: int64,\n",
              " isFraud\n",
              " 0    56987\n",
              " 1     2067\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M0CW-HNyq3iS",
        "outputId": "3214824b-287e-404c-be88-607e970757b8"
      },
      "id": "M0CW-HNyq3iS",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "These features in provided data are not utilized by the predictor and will be ignored: ['V113', 'V119', 'V147', 'V149', 'V154', 'V156', 'V198', 'V241']\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Computing feature importance via permutation shuffling for 425 features using 5000 rows with 5 shuffle sets...\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\t1889.75s\t= Expected runtime (377.95s per shuffle set)\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\t1338.64s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                importance    stddev   p_value  n  p99_high   p99_low\n",
              "C1                0.008112  0.002089  0.000484  5  0.012414  0.003810\n",
              "C13               0.007806  0.001399  0.000119  5  0.010686  0.004926\n",
              "TransactionAmt    0.007158  0.004687  0.013453  5  0.016808 -0.002493\n",
              "card6             0.006856  0.002663  0.002258  5  0.012340  0.001373\n",
              "C11               0.005920  0.002093  0.001600  5  0.010230  0.001610\n",
              "...                    ...       ...       ... ..       ...       ...\n",
              "D13              -0.000370  0.000452  0.929549  5  0.000560 -0.001301\n",
              "V51              -0.000463  0.000357  0.977910  5  0.000273 -0.001199\n",
              "D5               -0.000491  0.000415  0.971434  5  0.000363 -0.001345\n",
              "V258             -0.000546  0.001069  0.841413  5  0.001655 -0.002747\n",
              "V65              -0.000674  0.001372  0.833165  5  0.002150 -0.003498\n",
              "\n",
              "[425 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06bf32f5-7467-4c1a-903a-a125a6314796\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1</th>\n",
              "      <td>0.008112</td>\n",
              "      <td>0.002089</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012414</td>\n",
              "      <td>0.003810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C13</th>\n",
              "      <td>0.007806</td>\n",
              "      <td>0.001399</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>5</td>\n",
              "      <td>0.010686</td>\n",
              "      <td>0.004926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionAmt</th>\n",
              "      <td>0.007158</td>\n",
              "      <td>0.004687</td>\n",
              "      <td>0.013453</td>\n",
              "      <td>5</td>\n",
              "      <td>0.016808</td>\n",
              "      <td>-0.002493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card6</th>\n",
              "      <td>0.006856</td>\n",
              "      <td>0.002663</td>\n",
              "      <td>0.002258</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012340</td>\n",
              "      <td>0.001373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C11</th>\n",
              "      <td>0.005920</td>\n",
              "      <td>0.002093</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>5</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.001610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D13</th>\n",
              "      <td>-0.000370</td>\n",
              "      <td>0.000452</td>\n",
              "      <td>0.929549</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>-0.001301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V51</th>\n",
              "      <td>-0.000463</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.977910</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>-0.001199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D5</th>\n",
              "      <td>-0.000491</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.971434</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>-0.001345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V258</th>\n",
              "      <td>-0.000546</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>0.841413</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>-0.002747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V65</th>\n",
              "      <td>-0.000674</td>\n",
              "      <td>0.001372</td>\n",
              "      <td>0.833165</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002150</td>\n",
              "      <td>-0.003498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>425 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06bf32f5-7467-4c1a-903a-a125a6314796')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06bf32f5-7467-4c1a-903a-a125a6314796 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06bf32f5-7467-4c1a-903a-a125a6314796');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4f41df48-cfea-479c-b329-c616187ce738\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f41df48-cfea-479c-b329-c616187ce738')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4f41df48-cfea-479c-b329-c616187ce738 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 425,\n  \"fields\": [\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009523277234564249,\n        \"min\": -0.0006738432901697511,\n        \"max\": 0.008111899157343361,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          7.688691179021933e-05,\n          -2.0418997510929238e-05,\n          4.848386567395391e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stddev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.000509091548917533,\n        \"min\": 0.0,\n        \"max\": 0.004686770992924465,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          0.00013613108697289246,\n          0.00017241922962317528,\n          2.995174645957802e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3002943835419956,\n        \"min\": 1.915809172626782e-05,\n        \"max\": 0.9973512942420946,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          0.1376086219197207,\n          0.59787906534649,\n          0.011182607781451893\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018562399439497408,\n        \"min\": -1.377273342466905e-05,\n        \"max\": 0.01680764233808016,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          0.0003571827013989789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007521882717406786,\n        \"min\": -0.005364011960878554,\n        \"max\": 0.004925707366768491,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          -0.00020340887781854024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "id": "oQgwNpCNa1ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339c90b6-c581-4acc-fe46-de2004dc6d9f"
      },
      "id": "oQgwNpCNa1ia",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "id": "e3jdxESRa3Kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e32857-3ce7-4171-cb72-64e1d0bb65c2"
      },
      "id": "e3jdxESRa3Kt",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "id": "Vez_9GNza4vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6405e3df-3731-460d-af33-5e18e113e6dc"
      },
      "id": "Vez_9GNza4vC",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "ot_fBRgJbCxN"
      },
      "id": "ot_fBRgJbCxN",
      "execution_count": 48,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}